[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Advanced biostatistics and Open science",
    "section": "",
    "text": "Note\n\n\n\n\n\n\nWork in progress. New chapters are going to appears regularly meaning that if you download the pdf it might be incomplete by the time we do the practical in class.\n\n\n\nif you see a dragon in a section, it means it is under development\n\n\n\n\nDream pet dragon\n\n\n\n\nLicence\nThe document is available follwoing the license License Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International.\n\n\nLicense Creative Commons",
    "crumbs": [
      "Note"
    ]
  },
  {
    "objectID": "01_01-open_science.html",
    "href": "01_01-open_science.html",
    "title": "\n1¬† Introduction to open Science\n",
    "section": "",
    "text": "1.1 Why do we need it?",
    "crumbs": [
      "Open Science",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introduction to open Science</span>"
    ]
  },
  {
    "objectID": "01_01-open_science.html#lecture",
    "href": "01_01-open_science.html#lecture",
    "title": "\n1¬† Introduction to open Science\n",
    "section": "\n1.2 Lecture",
    "text": "1.2 Lecture\n\n\n\n\nDream pet dragon",
    "crumbs": [
      "Open Science",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introduction to open Science</span>"
    ]
  },
  {
    "objectID": "01_01-open_science.html#what-it-is",
    "href": "01_01-open_science.html#what-it-is",
    "title": "\n1¬† Introduction to open Science\n",
    "section": "\n1.3 What it is?",
    "text": "1.3 What it is?",
    "crumbs": [
      "Open Science",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introduction to open Science</span>"
    ]
  },
  {
    "objectID": "01_01-open_science.html#reproducible-code-and-analysis",
    "href": "01_01-open_science.html#reproducible-code-and-analysis",
    "title": "\n1¬† Introduction to open Science\n",
    "section": "\n1.4 Reproducible code and analysis",
    "text": "1.4 Reproducible code and analysis",
    "crumbs": [
      "Open Science",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introduction to open Science</span>"
    ]
  },
  {
    "objectID": "01_02-rmarkdown.html",
    "href": "01_02-rmarkdown.html",
    "title": "\n2¬† Introduction to Rmarkdown\n",
    "section": "",
    "text": "2.1 Lecture\nDream pet dragon",
    "crumbs": [
      "Open Science",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Introduction to Rmarkdown</span>"
    ]
  },
  {
    "objectID": "01_02-rmarkdown.html#practical",
    "href": "01_02-rmarkdown.html#practical",
    "title": "\n2¬† Introduction to Rmarkdown\n",
    "section": "\n2.2 Practical",
    "text": "2.2 Practical\nWe will create a new Rmarkdown document and edit it using basic R and Rmarkdown functions.\n\n2.2.1 Context\nWe will use the awesome palmerpenguins dataset üêß to explore and visualize data.\nThese data have been collected and shared by Dr.¬†Kristen Gorman and Palmer Station, Antarctica LTER.\nThe package was built by Drs Allison Horst and Alison Hill, check out the official website.\nThe package palmerpenguins has two datasets:\n\n\npenguins_raw has the raw data of penguins observations (see ?penguins_raw for more info)\n\npenguins is a simplified version of the raw data (see ?penguins for more info)\n\nFor this exercise, we‚Äôre gonna use the penguins dataset.\n\nlibrary(palmerpenguins)\nhead(penguins)\n\n# A tibble: 6 √ó 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           NA            NA                  NA          NA\n5 Adelie  Torgersen           36.7          19.3               193        3450\n6 Adelie  Torgersen           39.3          20.6               190        3650\n# ‚Ñπ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\n\n2.2.2 Questions\n1) Install the package palmerpenguins.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ninstall.packages(\"palmerpenguins\")\n\n\n\n\n2)\n\nCreate a new R Markdown document, name it and save it.\nDelete everything after line 12.\nAdd a new section title, simple text and text in bold font.\nCompile (‚ÄúKnit‚Äù).\n\n3)\n\nAdd a chunk in which you load the palmerpenguins. The corresponding line of code should be hidden in the output.\nLoad also the tidyverse suite of packages. Modify the defaults to suppress all messages.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n```{r, echo = FALSE, message = FALSE}\nlibrary(palmerpenguins)\nlibrary(tidyverse)\n```\n\n\n\n4) Add another chunk in which you build a table with the 10 first rows of the dataset.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n```{r}\npenguins %&gt;%\n  slice(1:10) %&gt;%\n  knitr::kable()\n```\n\n\n\n5) In a new section, display how many individuals, penguins species and islands we have in the dataset. This info should appear directly in the text, you need to use inline code üòÑ. Calculate the mean of the (numeric) traits measured on the penguins.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n## Numerical exploration\n\nThere are `r nrow(penguins)` penguins in the dataset,\nand `r length(unique(penguins$species))` different species.\nThe data were collected in `r length(unique(penguins$island))`\nislands of the Palmer archipelago in Antarctica.\n\nThe mean of all traits that were measured on the penguins are:\n\n```{r echo = FALSE}\npenguins %&gt;%\n  group_by(species) %&gt;%\n  summarize(across(where(is.numeric), mean, na.rm = TRUE))\n```\n\n\n\n6) In another section, entitled ‚ÄòGraphical exploration‚Äô, build a figure with 3 superimposed histograms, each one corresponding to the body mass of a species.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n## Graphical exploration\n\nA histogram of body mass per species:\n\n```{r, fig.cap = \"Distribution of body mass by species of penguins\"}\n  ggplot(data = penguins) +\n  aes(x = body_mass_g) +\n  geom_histogram(aes(fill = species),\n                 alpha = 0.5,\n                 position = \"identity\") +\n  scale_fill_manual(values = c(\"darkorange\",\"purple\",\"cyan4\")) +\n  theme_minimal() +\n  labs(x = \"Body mass (g)\",\n       y = \"Frequency\",\n       title = \"Penguin body mass\")\n```\n\n\n\n7) In another section, entitled Linear regression, fit a model of bill length as a function of body size (flipper length), body mass and sex. Obtain the output and graphically evaluate the assumptions of the model. As reminder here is how you fit a linear regression.\n```{r}\nmodel &lt;- lm(Y ~  X1 + X2, data = data)\nsummary(model)\nplot(model)\n```\n\n\n\n\n\n\nSolution\n\n\n\n\n\n## Linear regression\n\nAnd here is a nice model with graphical output\n\n```{r, fig.cap = \"Checking assumptions of the model\"}\nm1 &lt;- lm(bill_length_mm ~  flipper_length_mm + body_mass_g + sex, data = penguins)\nsummary(m1)\npar(mfrow= c(2,2))\nplot(m1)\n```\n\n\n\n8) Add references manually or using citr in RStudio.\n\nPick a recent publication from the researcher who shared the data, Dr Kristen Gorman. Import this publication in your favorite references manager (we use Zotero, no hard feeling), and create a bibtex reference that you will add to to the file mabiblio.bib.\nAdd bibliography: mabiblio.bib at the beginning of your R Markdown document (YAML).\nCite the reference iin the text using either typing the reference manually or using citr. To use citr, instal it first; if everything goes well, you should see it in the pulldown menu Addins üí™. Then simply use Insert citations in the pull-down menu Addins.\nCompile.\n\n9) Change the default citation format (Chicago style) into the The American Naturalist format. It can be found here https://www.zotero.org/styles. To do soo, add csl: the-american-naturalist.csl in the YAML.\n10) Build your report in html, pdf and docx format. üéâ\nExample of output\nYou can see an example of the Rmarkdown source file and pdf output\n\n\n\n\nHappy coding",
    "crumbs": [
      "Open Science",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Introduction to Rmarkdown</span>"
    ]
  },
  {
    "objectID": "01_03-github.html",
    "href": "01_03-github.html",
    "title": "\n3¬† Introduction to github with R\n",
    "section": "",
    "text": "3.1 Lecture\nDream pet dragon",
    "crumbs": [
      "Open Science",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Introduction to github with R</span>"
    ]
  },
  {
    "objectID": "01_03-github.html#git_practical",
    "href": "01_03-github.html#git_practical",
    "title": "\n3¬† Introduction to github with R\n",
    "section": "\n3.2 Practical",
    "text": "3.2 Practical\n\n3.2.1 Context\nWe will configure Rstudio to work with our github account, then create a new project and start using github. To have some data I suggest to use the awesome palmerpenguins dataset üêß.\n\n3.2.2 Information of the data\nThese data have been collected and shared by Dr.¬†Kristen Gorman and Palmer Station, Antarctica LTER.\nThe package was built by Drs Allison Horst and Alison Hill, check out the official website.\nThe package palmerpenguins has two datasets.\n\nlibrary(palmerpenguins)\n\nThe dataset penguins is a simplified version of the raw data; see ?penguins for more info:\n\nhead(penguins)\n\n# A tibble: 6 √ó 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           NA            NA                  NA          NA\n5 Adelie  Torgersen           36.7          19.3               193        3450\n6 Adelie  Torgersen           39.3          20.6               190        3650\n# ‚Ñπ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\nThe other dataset penguins_raw has the raw data; see ?penguins_raw for more info:\n\nhead(penguins_raw)\n\n# A tibble: 6 √ó 17\n  studyName `Sample Number` Species          Region Island Stage `Individual ID`\n  &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;          \n1 PAL0708                 1 Adelie Penguin ‚Ä¶ Anvers Torge‚Ä¶ Adul‚Ä¶ N1A1           \n2 PAL0708                 2 Adelie Penguin ‚Ä¶ Anvers Torge‚Ä¶ Adul‚Ä¶ N1A2           \n3 PAL0708                 3 Adelie Penguin ‚Ä¶ Anvers Torge‚Ä¶ Adul‚Ä¶ N2A1           \n4 PAL0708                 4 Adelie Penguin ‚Ä¶ Anvers Torge‚Ä¶ Adul‚Ä¶ N2A2           \n5 PAL0708                 5 Adelie Penguin ‚Ä¶ Anvers Torge‚Ä¶ Adul‚Ä¶ N3A1           \n6 PAL0708                 6 Adelie Penguin ‚Ä¶ Anvers Torge‚Ä¶ Adul‚Ä¶ N3A2           \n# ‚Ñπ 10 more variables: `Clutch Completion` &lt;chr&gt;, `Date Egg` &lt;date&gt;,\n#   `Culmen Length (mm)` &lt;dbl&gt;, `Culmen Depth (mm)` &lt;dbl&gt;,\n#   `Flipper Length (mm)` &lt;dbl&gt;, `Body Mass (g)` &lt;dbl&gt;, Sex &lt;chr&gt;,\n#   `Delta 15 N (o/oo)` &lt;dbl&gt;, `Delta 13 C (o/oo)` &lt;dbl&gt;, Comments &lt;chr&gt;\n\n\nFor this exercise, we‚Äôre gonna use the penguins dataset.\n\n3.2.3 Questions\n1) Create a github account if not done yet.\n2) Configure Rstudio with your github account using the usethis package.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nusethis::git_sitrep()\nusethis::use_git_config(\n  user.name = \"your_username\",\n  user.email = \"your_email@address.com\"\n)\n\n\n\n\n3) Create and Store your GITHUB Personal Authorisation Token\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nusethis::create_github_token()\ngitcreds::gitcreds_set()\n\n\n\n\n4) Create a new R Markdown project, initialize it for git, and create a new git repository\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n#create R project\nusethis::use_git()\n\n#restart R\nusethis::use_github()\nusethis::git_vaccinate()\n\n\n\n\n5) Create a new Rmarkdown document, in your project. Then save the file and stage it.\n6) Create a new commit including the new file and push it to github (Check on github that it works).\n7) Edit the file. Delete everything after line 12. Add a new section title, simple text and text in bold font. Then knit and compile.\n8) Make a new commit (with a meaningful message), and push to github.\n9) Create a new branch, and add a new section to the rmarkdown file in this branch. Whatever you want. I would suggest a graph of the data.\n10) Create a commit and push it to the branch.\n11) On github, create a pull request to merge the 2 different branches.\n12) Check and accept the pull request to merge the 2 branches.\nYou have successfully used all the essential tools of git üéâ . You are really to explore üïµ and discover its power üí™\n\n\n\n\nHappy git(hub)-ing",
    "crumbs": [
      "Open Science",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Introduction to github with R</span>"
    ]
  },
  {
    "objectID": "02_01-glm.html",
    "href": "02_01-glm.html",
    "title": "\n4¬† Generalized linear model, glm\n",
    "section": "",
    "text": "4.1 Lecture\nDream pet dragon\nm1 &lt;- glm(fish ~ french_captain, data = dads_joke, family = poisson)",
    "crumbs": [
      "Statistics",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Generalized linear model, `glm`</span>"
    ]
  },
  {
    "objectID": "02_01-glm.html#lecture",
    "href": "02_01-glm.html#lecture",
    "title": "\n4¬† Generalized linear model, glm\n",
    "section": "",
    "text": "4.1.1 Distributions\n\n4.1.1.1 Continuous linear\n\nGaussian\n\n4.1.1.2 Count data\n\npoisson\nnegative binomial\nquasi-poisson\ngeneralized poisson\nconway-maxwell poisson\n\n4.1.1.3 censored distribution\n\n4.1.1.4 zero-inflated / hurdle distribution\n\nzero-inflated/zero-truncated poisson\ncensored poisson\n\n4.1.1.5 zero-truncated distribution\n\n4.1.1.6 zero-one-inflated distribution\nsee https://cran.r-project.org/web/packages/brms/vignettes/brms_families.html see alo MCMCglmm coursenotes\nfor help on description and to add some plots about those distribution",
    "crumbs": [
      "Statistics",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Generalized linear model, `glm`</span>"
    ]
  },
  {
    "objectID": "02_01-glm.html#practical",
    "href": "02_01-glm.html#practical",
    "title": "\n4¬† Generalized linear model, glm\n",
    "section": "\n4.2 Practical",
    "text": "4.2 Practical\n\n\n\n\n\n\nThis section need to be severely updated\n\n\n\n\n4.2.1 Logistic regression\n\nlibrary(tidyverse)\nlibrary(DHARMa)\nlibrary(performance)\n\nmouflon &lt;- read.csv(\"data/mouflon.csv\")\nmouflonc &lt;- mouflon[order(mouflon$age),]\n\nmouflonc$reproduction &lt;- ifelse(mouflonc$age &lt; 13, mouflonc$reproduction, 0)\nmouflonc$reproduction &lt;- ifelse(mouflonc$age &gt; 4, mouflonc$reproduction, 1)\n\nplot(reproduction ~ age, mouflonc)\n\n\n\n\n\n\nplot(jitter(reproduction) ~ jitter(age), mouflonc)\n\n\n\n\n\n\nbubble &lt;- data.frame(age = rep(2:16, 2),\n                     reproduction = rep(0:1, each = 15),\n                     size = c(table(mouflonc$age, mouflonc$reproduction)))\nbubble$size &lt;- ifelse(bubble$size == 0 , NA, bubble$size)\n ggplot(data = bubble, aes(x = age, y = reproduction))+\n geom_point(aes(size = size*10))\n\nWarning: Removed 7 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\nm1 &lt;- glm(reproduction ~ age,\n    data = mouflonc,\n    family = binomial)\nsummary(m1)\n\n\nCall:\nglm(formula = reproduction ~ age, family = binomial, data = mouflonc)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  3.19921    0.25417   12.59   &lt;2e-16 ***\nage         -0.36685    0.03287  -11.16   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 928.86  on 715  degrees of freedom\nResidual deviance: 767.51  on 714  degrees of freedom\n  (4 observations deleted due to missingness)\nAIC: 771.51\n\nNumber of Fisher Scoring iterations: 4\n\nsimulationOutput &lt;- simulateResiduals(m1)\nplot(simulationOutput)\n\n\n\n\n\n\n\nplotting the model prediction on the link (latent) scale\n\nmouflonc$logit_ypred &lt;- 3.19921 -0.36685 * mouflonc$age\nplot(logit_ypred ~  jitter(age), mouflonc)\npoints(mouflonc$age, mouflonc$logit_ypred, col=\"red\", type = \"l\", lwd = 2)\n\n\n\n\n\n\n\nplotting on the observed scale\n\nmouflonc$ypred &lt;- exp(mouflonc$logit_ypred) / (1 + exp(mouflonc$logit_ypred)) # inverse of logit \n\nplot(reproduction ~  jitter(age), mouflonc)\npoints(mouflonc$age, mouflonc$ypred, col=\"red\", type = \"l\", lwd = 2)\n\n\n\n\n\n\n\nEnfin, pour se simplifier la vie, il est aussi possible de r√©cup√©rer les valeurs pr√©dites de y directement\n\nplot(x,y)\nmyreg &lt;- glm(y~x, family=binomial(link=logit))\nypredit &lt;- myreg$fitted\no=order(x)\npoints(x[o],ypredit[o], col=\"red\", type=\"l\", lwd=2)\n\n\nm2 &lt;- glm(reproduction ~ age + mass_sept + as.factor(sex_lamb) + mass_gain + density + temp,\n    data = mouflon,\n    family = binomial)\n\nsummary(m2)\n\n\nCall:\nglm(formula = reproduction ~ age + mass_sept + as.factor(sex_lamb) + \n    mass_gain + density + temp, family = binomial, data = mouflon)\n\nCoefficients:\n                      Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)           1.622007   1.943242   0.835 0.403892    \nage                  -0.148567   0.033597  -4.422 9.78e-06 ***\nmass_sept             0.029878   0.016815   1.777 0.075590 .  \nas.factor(sex_lamb)1 -0.428169   0.166156  -2.577 0.009969 ** \nmass_gain            -0.094828   0.026516  -3.576 0.000348 ***\ndensity              -0.018132   0.003518  -5.154 2.55e-07 ***\ntemp                  0.037244   0.138712   0.269 0.788313    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 916.06  on 674  degrees of freedom\nResidual deviance: 845.82  on 668  degrees of freedom\n  (45 observations deleted due to missingness)\nAIC: 859.82\n\nNumber of Fisher Scoring iterations: 4\n\ncheck_model(m2)\n\n\n\n\n\n\nsimulationOutput &lt;- simulateResiduals(m2)\nplot(simulationOutput)\n\n\n\n\n\n\n\n\n4.2.1.1 previous offspring sex effect\n\npred.data &lt;- data.frame(\n  age = mean(mouflon$age),\n  mass_sept = mean(mouflon$mass_sept),\n  sex_lamb = c(0,1),\n  mass_gain = mean(mouflon$mass_gain),\n  density = mean(mouflon$density),\n  temp = mean(mouflon$temp, na.rm =TRUE))\n\n  predict(m2, newdata = pred.data)\n\n        1         2 \n0.6225895 0.1944205 \n\n\n\n4.2.2 Poisson regression\ndata on galapagos islands species richness model of total number of species model of proportion of native model of density of species\nFit 3 models - model of total number of species - model of proportion of endemics to total - model of species density\n\n  hist(rpois(10000,3))\n\n\n\n\n\n\n#\n gala &lt;- read.delim2(\"data/gala.txt\")\n plot(Species ~ Area, gala)\n\n\n\n\n\n\n plot(Species ~ log(Area), gala)\n\n\n\n\n\n\n hist(gala$Species)\n\n\n\n\n\n\n modpl &lt;- glm(Species ~ Area + Elevation + Nearest, family=poisson, gala)\nres &lt;- simulateResiduals(modpl)\ntestDispersion(res)\n\n\n\n\n\n\n\n\n    DHARMa nonparametric dispersion test via sd of residuals fitted vs.\n    simulated\n\ndata:  simulationOutput\ndispersion = 110.32, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\ntestZeroInflation(res)\n\n\n\n\n\n\n\n\n    DHARMa zero-inflation test via comparison to expected zeros with\n    simulation under H0 = fitted model\n\ndata:  simulationOutput\nratioObsSim = NaN, p-value = 1\nalternative hypothesis: two.sided\n\n mean(gala$Species)\n\n[1] 85.23333\n\n var(gala$Species)\n\n[1] 13140.74\n\n hist(rpois(nrow(gala),mean(gala$Species)))\n\n\n\n\n\n\n plot(modpl)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWarning in sqrt(crit * p * (1 - hh)/hh): NaNs produced\n\nWarning in sqrt(crit * p * (1 - hh)/hh): NaNs produced",
    "crumbs": [
      "Statistics",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Generalized linear model, `glm`</span>"
    ]
  },
  {
    "objectID": "02_02-lmm.html",
    "href": "02_02-lmm.html",
    "title": "\n5¬† Introduction to linear mixed models\n",
    "section": "",
    "text": "5.1 Lecture",
    "crumbs": [
      "Statistics",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Introduction to linear mixed models</span>"
    ]
  },
  {
    "objectID": "02_02-lmm.html#lecture",
    "href": "02_02-lmm.html#lecture",
    "title": "\n5¬† Introduction to linear mixed models\n",
    "section": "",
    "text": "5.1.1 Testing fixed effects\nmaking a note that LRT on fixed effects should not be the preferred method and more inportantly should eb done using ML and not REML Fitsee pinheiro & Bates 2000 p76\n\n5.1.2 Shrinkage\nThe following is an example of shrinkage, sometimes called partial-pooling, as it occurs in mixed effects models. \nIt is often the case that we have data such that observations are clustered in some way (e.g.¬†repeated observations for units over time, students within schools, etc.). In mixed models, we obtain cluster-specific effects in addition to those for standard coefficients of our regression model. The former are called random effects, while the latter are typically referred to as fixed effects or population-average effects.\nIn other circumstances, we could ignore the clustering, and run a basic regression model. Unfortunately this assumes that all observations behave in the same way, i.e.¬†that there are no cluster-specific effects, which would often be an untenable assumption. Another approach would be to run separate models for each cluster. However, aside from being problematic due to potentially small cluster sizes in common data settings, this ignores the fact that clusters are not isolated and potentially have some commonality.\nMixed models provide an alternative where we have cluster specific effects, but ‚Äòborrow strength‚Äô from the population-average effects. In general, this borrowing is more apparent for what would otherwise be more extreme clusters, and those that have less data. The following will demonstrate how shrinkage arises in different data situations.\n\n5.1.2.1 Analysis\nFor the following we run a basic mixed model with a random intercept and random slopes for a single predictor variable. There are a number of ways to write such models, and the following does so for a single cluster \\(c\\) and observation \\(i\\). \\(y\\) is a function of the covariate \\(x\\), and otherwise we have a basic linear regression model. In this formulation, the random effects for a given cluster (\\(u_{* c}\\)) are added to each fixed effect (intercept \\(b_0\\) and the effect of \\(x\\), \\(b_1\\)). The random effects are multivariate normally distributed with some covariance. The per observation noise \\(\\sigma\\) is assumed constant across observations.\n\\[\\mu_{ic} = (b_0 + \\mathrm{u}_{0c})+ (b_1+\\mathrm{u}_{1c}) * x_{ic}\\] \\[\\mathrm{u}_{0}, \\mathrm{u}_{1} \\sim \\mathcal{N}(0, \\Sigma)\\] \\[y \\sim \\mathcal{N}(\\mu, \\sigma^2)\\]\nSuch models are highly flexible and have many extensions, but this simple model is enough for our purposes.\n\n5.1.2.2 Data\nDefault settings for data creation are as follows:\n\n\nobs_per_cluster (observations per cluster) = 10\n\nn_cluster (number of clusters) = 100\n\nintercept (intercept) = 1\n\nbeta (coefficient for x) = .5\n\nsigma (observation level standard deviation) = 1\n\nsd_int (standard deviation for intercept random effect)= .5\n\nsd_slope (standard deviation for x random effect)= .25\n\ncor (correlation of random effect) = 0\n\nbalanced (fraction of overall sample size) = 1\n\nseed (for reproducibility) = 1024\n\nIn this setting, \\(x\\) is a standardized variable with mean zero and standard deviation of 1. Unless a fraction is provided for balanced, the \\(N\\), i.e.¬†the total sample size, is equal to n_cluster * obs_per_cluster. The following is the function that will be used to create the data, which tries to follow the model depiction above. It requires the tidyverse package to work.\n\n5.1.2.3 Run the baseline model\nWe will use lme4 to run the analysis. We can see that the model recovers the parameters fairly well, even with the default of only 1000 observations.\n\ndf &lt;- create_data()\n\nlibrary(lme4)\nmod &lt;- lmer(y ~ x + (x | cluster), df)\nsummary(mod, cor = F)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: y ~ x + (x | cluster)\n   Data: df\n\nREML criterion at convergence: 3012.2\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.9392 -0.6352 -0.0061  0.6156  2.8721 \n\nRandom effects:\n Groups   Name        Variance Std.Dev. Corr\n cluster  (Intercept) 0.29138  0.5398       \n          x           0.05986  0.2447   0.30\n Residual             0.99244  0.9962       \nNumber of obs: 1000, groups:  cluster, 100\n\nFixed effects:\n            Estimate Std. Error       df t value Pr(&gt;|t|)    \n(Intercept)  0.93647    0.06282 98.38512   14.91   &lt;2e-16 ***\nx            0.54405    0.04270 91.69469   12.74   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n5.1.2.4 Visualize the baseline model\nNow it is time to visualize the results. We will use gganimate to bring the shrinkage into focus. We start with the estimates that would be obtained by a ‚Äòregression-by-cluster‚Äô approach or a linear regression for each cluster. The movement shown will be of those cluster-specific estimates toward the mixed model estimates. On the x axis is the estimate for the intercepts, on the y axis are the estimated slopes of the x covariate.\n\n\n\n\n\n\n\n\nWe see more clearly what the mixed model does. The general result is that cluster-specific effects (lighter color) are shrunk back toward the population-average effects (the ‚Äòblack hole‚Äô), as the imposed normal distribution for the random effects makes the extreme values less probable. Likewise, those more extreme cluster-specific effects, some of which are not displayed as they are so far from the population average, will generally have the most shrinkage imposed. In terms of prediction, it is akin to introducing bias for the cluster specific effects while lowering variance for prediction of new data, and allows us to make predictions on new categories we have not previously seen - we just assume an ‚Äòaverage‚Äô cluster effect, i.e.¬†a random effect of 0.\n\n5.1.2.5 Summary\nMixed models incorporate some amount of shrinkage for cluster-specific effects. Data nuances will determine the relative amount of ‚Äòstrength borrowed‚Äô, but in general, such models provide a good way for the data to speak for itself when it should, and reflect an ‚Äòaverage‚Äô when there is little information. An additional benefit is that thinking about models in this way can be seen as a precursor to Bayesian approaches, which can allow for even more flexibility via priors, and more control over how shrinkage is added to the model.",
    "crumbs": [
      "Statistics",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Introduction to linear mixed models</span>"
    ]
  },
  {
    "objectID": "02_02-lmm.html#practical",
    "href": "02_02-lmm.html#practical",
    "title": "\n5¬† Introduction to linear mixed models\n",
    "section": "\n5.2 Practical",
    "text": "5.2 Practical\n\n5.2.1 Overview\nThis practical is intended to get you started fitting some simple mixed models with so called random intercepts. The tutorial is derived from one that accompanied the paper (Houslay and Wilson 2017), ‚ÄúAvoiding the misuse of BLUP in behavioral ecology‚Äù. Here, you will be working through a simplified version in which I have taken more time to cover the basic mixed models and don‚Äôt cover multivariate models which were really the main point of that paper. So if you find this material interesting don‚Äôt worry we will go through a more advanced version of the original paper on multivariate models in chapter XX. The original version will be worth a work through to help you break into multivariate mixed models anyway! Here we will:\n\nLearn how to fit - and interpret the results of - a simple univariate mixed effect model\nSee how to add fixed and random effects to your model, and to test their significance in the normal frequentists sense\n\nWe are going to use the üì¶ lme4 (Bates et al. 2015) which is widely used and great for simple mixed models. However, since, for philosophical reasons, lme4 does not provide any p-values for either fixed or random effects, we are going to use the üì¶ lmerTest (Kuznetsova et al. 2017), which add a bunch a nice goodies to lme4 For slightly more complex models, including multivariate ones, generalised models, and random effects of things like shared space, pedigree, phylogeny I tend to use different üì¶ like MCMCglmm (Hadfield 2010) (which is Bayesian, look at Jarrod Hadfield‚Äôs excellent course notes (Hadfield 2010)) or ASReml-R (Butler 2022) (which is likelihood based/frequentist but sadly is not free).\n\n\n5.2.2 R packages needed\nFirst we load required libraries\n\nlibrary(lmerTest)\nlibrary(performance)\nlibrary(tidyverse)\nlibrary(rptR)\n\n\n5.2.3 The superb wild unicorns of the Scottish Highlands\nUnicorns, a legendary animal and also symbol or Scotland, are frequently described as extremely wild woodland creature but also a symbol of purity and grace. Here is one of most accurate representation of the lengendary animal.\n\n\n\n\nThe superb unicorn of the Scottish Highlands\n\n\n\nDespite their image of purity and grace, unicorns (Unicornus legendaricus) are raging fighter when it comes to compete for the best sweets you can find at the bottom of rainbows (unicorn favourite source of food).\nWe want to know:\n\nIf aggressiveness differs among individuals\nIf aggressive behaviour is plastic (change with the environment)\nIf aggressive behaviour depends on body condition of focal animal \n\n\nWith respect to plasticity, we will focus on rival size as an ‚Äòenvironment‚Äô. Common sense, and animal-contest theory, suggest a small animal would be wise not to escalate an aggressive contest against a larger, stronger rival. However, there are reports in the legendary beasty literature that they get more aggressive as rival size increases. Those reports are based on small sample sizes and uncontrolled field observations by foreigners Munro baggers enjoying their whisky after a long day in the hills.\n\n5.2.3.1 Experimental design\nHere, we have measured aggression in a population of wild unicorns. We brought some (n=80) individual into the lab, tagged them so they were individually identifiable, then repeatedly observed their aggression when presented with model ‚Äòintruders‚Äô (animal care committe approved). There were three models; one of average unicorn (calculated as the population mean body length), one that was build to be 1 standard deviation below the population mean, and one that was 1 standard deviation above.\nData were collected on all individuals in two block of lab work. Within each block, each animal was tested 3 times, once against an ‚Äòintruder‚Äô of each size. The test order in which each animal experienced the three instruder sizes was randomised in each block. The body size of all focal individuals was measured at the beginning of each block so we know that too (and have two separate measures per individual).\n\n5.2.3.2 looking at the data\nLet‚Äôs load the data file unicorns_aggression.csv in a R object named unicorns and make sure we understand what it contains\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nunicorns &lt;- read.csv(\"data/unicorns_aggression.csv\")\n\nYou can use summary(unicorns) to get an overview of the data and/or str(unicorns) to see the structure in the first few lines. This data frame has 6 variables:\n\nstr(unicorns)\n\n'data.frame':   480 obs. of  6 variables:\n $ ID        : chr  \"ID_1\" \"ID_1\" \"ID_1\" \"ID_1\" ...\n $ block     : num  -0.5 -0.5 -0.5 0.5 0.5 0.5 -0.5 -0.5 -0.5 0.5 ...\n $ assay_rep : int  1 2 3 1 2 3 1 2 3 1 ...\n $ opp_size  : int  -1 1 0 0 1 -1 1 -1 0 1 ...\n $ aggression: num  7.02 10.67 10.22 8.95 10.51 ...\n $ body_size : num  206 206 206 207 207 ...\n\nsummary(unicorns)\n\n      ID                block        assay_rep    opp_size    aggression    \n Length:480         Min.   :-0.5   Min.   :1   Min.   :-1   Min.   : 5.900  \n Class :character   1st Qu.:-0.5   1st Qu.:1   1st Qu.:-1   1st Qu.: 8.158  \n Mode  :character   Median : 0.0   Median :2   Median : 0   Median : 8.950  \n                    Mean   : 0.0   Mean   :2   Mean   : 0   Mean   : 9.002  \n                    3rd Qu.: 0.5   3rd Qu.:3   3rd Qu.: 1   3rd Qu.: 9.822  \n                    Max.   : 0.5   Max.   :3   Max.   : 1   Max.   :12.170  \n   body_size    \n Min.   :192.0  \n 1st Qu.:229.7  \n Median :250.0  \n Mean   :252.5  \n 3rd Qu.:272.0  \n Max.   :345.2  \n\n\n\n\n\nSo the different columns in the data set are:\n\nIndividual ID\n\nExperimental Block, denoted for now as a continuous variable with possible values of -0.5 (first block) or +0.5 (second block)\nIndividual body_size, as measured at the start of each block in kg\nThe repeat number for each behavioural test, assay_rep\n\nOpponent size (opp_size), in standard deviations from the mean (i.e., -1,0,1)\n\naggression, our behavioural trait, measured 6 times in total per individual (2 blocks of 3 tests)\n\nmaybe add something on how to look at data structure closely using tables\n\n5.2.4 Do unicorns differ in aggressiveness? Your first mixed model\nFit a first mixed model with lmer that have only individual identity as a random effect and only a population mean.\nWhy, so simple? Because we simply want to partition variance around the mean into a component that among-individual variance and one that is within-individual variance.\n\n\n\n\n\n\nWe are going to use the function lmer() from the üì¶ lme4 package. The notation of the model formula is similar as the notation for a linear model but now we also add random effects using the notation (1 | r_effect) which indicates that we want to fit the variable r_effect as a random effect for the intercept. Thus, in lmer notation a simploe model would be :\nlmer(Y ~ x1 + x2 + (1 | r_effect), data = data)\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nA sensible researcher would probably take the time to do some exploratory data plots here. So let‚Äôs write a mixed model. This one is going to have no fixed effects except the mean, and just one random effect - individual identity.\n\nm_1 &lt;- lmer(aggression ~ 1 + (1 | ID), data = unicorns)\n\nboundary (singular) fit: see help('isSingular')\n\n\nThere is a warning‚Ä¶ something about ‚Äúsingularities‚Äù. Ignore that for a moment.\n\n\n\nNow you need to get the model output. By that I just mean use summary(model_name).\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nsummary(m_1)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: aggression ~ 1 + (1 | ID)\n   Data: unicorns\n\nREML criterion at convergence: 1503.7\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-2.68530 -0.73094 -0.04486  0.71048  2.74276 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n ID       (Intercept) 0.000    0.000   \n Residual             1.334    1.155   \nNumber of obs: 480, groups:  ID, 80\n\nFixed effects:\n             Estimate Std. Error        df t value Pr(&gt;|t|)    \n(Intercept)   9.00181    0.05272 479.00000   170.7   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\noptimizer (nloptwrap) convergence code: 0 (OK)\nboundary (singular) fit: see help('isSingular')\n\n\n\n\n\nIn the summary you will find a table of fixed effects.\nFixed effects:\n             Estimate Std. Error        df t value Pr(&gt;|t|)    \n(Intercept)   9.00181    0.05272 479.00000   170.7   &lt;2e-16 ***\nThe intercept (here the mean) is about 9 and is significantly &gt;0 - fine, but not very interesting to us.\nYou will also find a random effect table that contains estimates of the among individual (ID) and residual variances.\nRandom effects:\n Groups   Name        Variance Std.Dev.\n ID       (Intercept) 0.000    0.000   \n Residual             1.334    1.155   \nNumber of obs: 480, groups:  ID, 80\nThe among individual (ID) is estimated as zero. In fact this is what the cryptic warning was about: in most situations the idea of a random effect explaining less than zero variance is not sensible (strangely there are exception!). So by default the variance estimates are constrained to lie in positive parameter space. Here in trying to find the maximum likelihood solution for among-individual variance, our model has run up against this constraint.\n\n5.2.4.1 Testing for random effects\nWe can test the statistical significance of the random effect using the ranova() command in lmerTest. This function is actually doing a likelihood ratio test (LRT) of the random effect. The premise of which is that twice the difference in log-likelihood of the full and reduced (i.e.¬†with the random effect dropped) is itself distributed as \\(\\chi^2\\)$ with DF equal to the number of parameters dropped (here 1). Actually, there is a good argument that this is too conservative, but we can discuss that later. So let‚Äôs do the LRT for the random effect using ranova()\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nranova(m_1)\n\nANOVA-like table for random-effects: Single term deletions\n\nModel:\naggression ~ (1 | ID)\n         npar  logLik    AIC LRT Df Pr(&gt;Chisq)\n&lt;none&gt;      3 -751.83 1509.7                  \n(1 | ID)    2 -751.83 1507.7   0  1          1\n\n\n\n\n\nThere is apparently no among-individual variance in aggressiveness.\nSo this is a fairly rubbish and underwhelming model. Let‚Äôs improve it.\n\n5.2.5 Do unicorns differ in aggressiveness? A better mixed model\nThe answer we got from our first model is not wrong, it estimated the parameters we asked for and that might be informative or not and that might be representative or not of the true biology. Anyway all models are wrong but as models go this one is fairly rubbish. In fact we have explained no variation at all as we have no fixed effects (except the mean) and our random effect variance is zero. We woud have seen just how pointless this model was if we‚Äôd plotted it\n\nplot(m_1)\n\n\n\nFitted values vs residuals for a simple mixed model of unicorn aggression\n\n\n\nSo we can probably do better at modelling the data, which may or may not change our view on whether there is any real variation among unicorns in aggressiveness.\nFor instance, we can (and should have started with) an initial plot of the phenotypic data against opponent size indicates to have a look at our prediction.\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe code below uses the excellent üì¶ ggplot2 but the same figure can be done using base R code.\n\nggplot(unicorns, aes(x = opp_size, y = aggression)) +\n  geom_jitter(\n    alpha = 0.5,\n    width = 0.05\n  ) +\n  scale_x_continuous(breaks = c(-1, 0, 1)) +\n  labs(\n    x = \"Opponent size (SD)\",\n    y = \"Aggression\"\n  ) +\n  theme_classic()\n\n\n\n\n\nggplot(unicorns, aes(x = opp_size, y = aggression)) +\n  geom_jitter(\n    alpha = 0.5,\n    width = 0.05\n  ) +\n  scale_x_continuous(breaks = c(-1, 0, 1)) +\n  labs(\n    x = \"Opponent size (SD)\",\n    y = \"Aggression\"\n  ) +\n  theme_classic()\n\n\n\nUnicorn aggressivity as a function of opponent size when fighting for sweets\n\n\n\nAs predicted, there is a general increase in aggression with opponent size (points are lightly jittered on the x-axis to show the spread of data a little better)\nYou can see the same thing from a quick look at the population means for aggression at opponent size. Here we do it with the kable function that makes nice tables in rmarkdown documents.\n\nunicorns %&gt;%\n  group_by(opp_size) %&gt;%\n  summarise(mean_aggr = mean(aggression)) %&gt;%\n  knitr::kable(digits = 2)\n\n\n\nopp_size\nmean_aggr\n\n\n\n-1\n8.00\n\n\n0\n8.91\n\n\n1\n10.09\n\n\n\n\n\nSo, there does appear to be plasticity of aggression with changing size of the model opponent. But other things may explain variation in aggressiveness too - what about block for instance? Block effects may not be the subject of any biologically interesting hypotheses, but accounting for any differences between blocks could remove noise.\nThere may also be systematic change in behaviour as an individual experiences more repeat observations (i.e.¬†exposure to the model). Do they get sensitised or habituated to the model intruder for example?\nSo let‚Äôs run a mixed model with the same random effect of individual, but with a fixed effects of opponent size (our predictor of interest) and experimental block.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nm_2 &lt;- lmer(aggression ~ opp_size + block + (1 | ID), data = unicorns)\n\n\n\n\n\n5.2.5.1 Diagnostic plots\nRun a few diagnostic plots before we look at the answers. In diagnostic plots, we want to check the condition of applications of the linear mixed model which are the same 4 as the linear model plus 2 extra:\n\nLinearity of the relation between covariates and the response\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nDone with data exploration graph (i.e.¬†just plot the data see if it is linear) - see previous graph @ref(fig:rplotaggr).\n\n\n\n\nNo error on measurement of covariates\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nassumed to be correct if measurement error is lower than 10% of variance in the variable - I know this sounds pretty bad\n\n\n\n\nResidual have a Gaussian distribution\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nusing quantile-quantile plot or histogram of residuals\n\npar(mfrow = c(1, 2)) # multiple graphs in a window\nqqnorm(residuals(m_2)) # a q-q plot\nqqline(residuals(m_2))\nhist(resid(m_2)) # are the residuals roughly Gaussian?\n\n\n\nChecking residuals have Gaussian distribution\n\n\n\n\n\n\n\nHomoscedasticty (variance of residuals is constant across covariates)\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nUsing plot of residuals by fitted values\n\nplot(m_2)\n\n\n\nResiduals by fitted values for model m_2 to check homoscedasticity\n\n\n\n\n\n\n\nRandom effects have a Gaussian distribution\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nhistogram of the predictions for the random effects (BLUPs)\n\n# extracting blups\nr1 &lt;- as.data.frame(ranef(m_2, condVar = TRUE))\npar(mfrow = c(1, 2))\nhist(r1$condval)\nqqnorm(r1$condval)\nqqline(r1$condval)\n\n\n\nChecking random effects are gaussian\n\n\n\n\n\n\n\nResidual variance is constant across all levels of a random effect\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nNo straightforward solution to deal with that. We can just do a plot is absolutely not-informative for that problem but I always like to look at. It is the plot of the sorted BLUPs with their associated errors.\n\nr1 &lt;- r1[order(r1$condval), ] # sorting the BLUPs\nggplot(r1, aes(y = grp, x = condval)) +\n  geom_point() +\n  geom_pointrange(\n    aes(xmin = condval - condsd * 1.96, xmax = condval + condsd * 1.96)\n  ) +\n  geom_vline(aes(xintercept = 0, color = \"red\")) +\n  theme_classic() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\nHere is a great magic trick üéá because 3-5 and more can be done in one step\n\n\n\n\n\n\nSolution\n\n\n\n\n\nYou need to use the function check_model() from the üì¶ performance package.\n\ncheck_model(m_2)\n\n\n\nGraphical check of model assumptions\n\n\n\n\n\n\n\n5.2.5.2 Inferences\nNow summarise this model. We will pause here for you to think about and discuss a few things: * What can you take from the fixed effect table? * How do you interpret the intercept now that there are other effects in the model? * What would happen if we scaled our fixed covariates differently? Why?\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nsummary(m_2)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: aggression ~ opp_size + block + (1 | ID)\n   Data: unicorns\n\nREML criterion at convergence: 1129.9\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-2.79296 -0.64761  0.00155  0.67586  2.71456 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n ID       (Intercept) 0.02478  0.1574  \n Residual             0.58166  0.7627  \nNumber of obs: 480, groups:  ID, 80\n\nFixed effects:\n             Estimate Std. Error        df t value Pr(&gt;|t|)    \n(Intercept)   9.00181    0.03901  79.00000 230.778   &lt;2e-16 ***\nopp_size      1.04562    0.04263 398.00000  24.525   &lt;2e-16 ***\nblock        -0.02179    0.06962 398.00000  -0.313    0.754    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n         (Intr) opp_sz\nopp_size 0.000        \nblock    0.000  0.000 \n\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nTry tweaking the fixed part of your model:\n\nWhat happens if you add more fixed effects? Try it!\nCould focal body size also matter? If so, should you rescale before adding it to the model?\nShould you add interactions (e.g.¬†block:opp_size)?\nShould you drop non-significant fixed effects?\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nHaving changed the fixed part of your model, do the variance estimates change at all?\n\nIs among-individual variance always estimated as zero regardless of fixed effects?\nIs among-individual variance significant with some fixed effets structures but not others?\n\n\n\n\n5.2.6 What is the repeatability?\nAs a reminder, repeatability is the proportion of variance explained by a random effect and it is estimate as the ratio of the variance associated to a random effect by the total variance, or the sum of the residual variance and the different variance compoentn associated with the random effects. In our first model among-individual variance was zero, so R was zero. If we have a different model of aggression and get a non-zero value of the random effect variance, we can obviously calculate a repeatability estimate (R). So we are all working from the same starting point, let‚Äôs all stick with a common set of fixed effects from here on:\n\nm_3 &lt;- lmer(\n  aggression ~ opp_size + scale(body_size, center = TRUE, scale = TRUE)\n    + scale(assay_rep, scale = FALSE) + block\n    + (1 | ID),\n  data = unicorns\n)\nsummary(m_3)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: \naggression ~ opp_size + scale(body_size, center = TRUE, scale = TRUE) +  \n    scale(assay_rep, scale = FALSE) + block + (1 | ID)\n   Data: unicorns\n\nREML criterion at convergence: 1136.5\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-2.85473 -0.62831  0.02545  0.68998  2.74064 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n ID       (Intercept) 0.02538  0.1593  \n Residual             0.58048  0.7619  \nNumber of obs: 480, groups:  ID, 80\n\nFixed effects:\n                                               Estimate Std. Error        df\n(Intercept)                                     9.00181    0.03907  78.07315\nopp_size                                        1.05141    0.04281 396.99857\nscale(body_size, center = TRUE, scale = TRUE)   0.03310    0.03896  84.21144\nscale(assay_rep, scale = FALSE)                -0.05783    0.04281 396.99857\nblock                                          -0.02166    0.06955 397.00209\n                                              t value Pr(&gt;|t|)    \n(Intercept)                                   230.395   &lt;2e-16 ***\nopp_size                                       24.562   &lt;2e-16 ***\nscale(body_size, center = TRUE, scale = TRUE)   0.850    0.398    \nscale(assay_rep, scale = FALSE)                -1.351    0.177    \nblock                                          -0.311    0.756    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) opp_sz sc=Ts=T s(_s=F\nopp_size     0.000                      \ns(_,c=TRs=T  0.000  0.000               \ns(_,s=FALSE  0.000 -0.100  0.000        \nblock        0.000  0.000  0.002   0.000\n\n\nSo we‚Äôd probably calculate R using the individual and residual variance simply as:\n\n0.02538 / (0.02538 + 0.58048)\n\n[1] 0.04189087\n\n\n\n\n\n\n\n\nExercise\n\n\n\nDo you see where I took the numbers ?\n\n\nWe can use some more fancy coding to extract the estimates and plugged them in a formula to estimate the repeatbility\n\nv_id &lt;- VarCorr(m_3)$ID[1, 1]\nv_r &lt;- attr(VarCorr(m_3), \"sc\")^2\nr_man &lt;- v_id / (v_id + v_r)\nr_man\n\n[1] 0.04188879\n\n\nWhich yields an estimate of approximately R=4%. Strictly speaking we should make clear this a conditional repeatability estimate.\nConditional on what you might ask‚Ä¶ on the fixed effects in your model. So our best estimate of 4% refers to the proportion of variance in aggressiveness not explained by fixed effects that is explained by individual identity. This isn‚Äôt much and still won‚Äôt be significant, but illustrates the point that conditional repeatabilities often have a tendency to go up as people explain more of the residual variance by adding fixed effects. This is fine and proper, but can mislead the unwary reader. It also means that decisions about which fixed effects to include in your model need to be based on how you want to interpret R not just on, for instance, whether fixed effects are deemed significant.\n\n5.2.7 A quick note on uncertainty\nUsing lmer in the üì¶ lme4 üì¶ there isn‚Äôt a really simple way to put some measure of uncertainty (SE or CI) on derived parameters like repeatabilities. This is a bit annoying. Such things are more easily done with other mixed model üì¶ like MCMCglmm and asreml which are a bit more specialist. If you are using lmer for models you want to publish then you could look into the üì¶ rptR (Stoffel et al. 2017). This acts as a ‚Äòwrapper‚Äô for lmer models and adds some nice functionality including options to boostrap confidence intervals. Regardless, of how you do it, if you want to put a repeatability in one of your papers as a key result - it really should be accompanied by a measure of uncertainty just like any other effect size estimate.\nHere I am estimating the repeatability and using bootstrap to estimate a confidence interval and a probability associated with the repeatability with the rptR üì¶. For more information about the use of the package and the theory behind it suggest the excellent paper associated with the package (Stoffel et al. 2017)\n\nr_rpt &lt;- rptGaussian(\n  aggression ~ opp_size + block + (1 | ID),\n  grname = \"ID\", data = unicorns\n)\n\nBootstrap Progress:\n\nr_rpt\n\n\n\nRepeatability estimation using the lmm method \n\nRepeatability for ID\nR  = 0.041\nSE = 0.03\nCI = [0, 0.103]\nP  = 0.0966 [LRT]\n     NA [Permutation]\n\n\n\n5.2.8 An easy way to mess up your mixed models\nWe will try some more advanced mixed models in a moment to explore plasticity in aggressiveness a bit more. First let‚Äôs quickly look for among-individual variance in focal body size. Why not? We have the data handy, everyone says morphological traits are very repeatable and - lets be honest - who wouldn‚Äôt like to see a small P value after striking out with aggressiveness.\nInclude a random effect of ID as before and maybe a fixed effect of block, just to see if the beasties were growing a bit between data collection periods.\n\nlmer_size &lt;- lmer(body_size ~ block + (1 | ID),\n  data = unicorns\n)\n\nSummarise and test the random effect.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nsummary(lmer_size)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: body_size ~ block + (1 | ID)\n   Data: unicorns\n\nREML criterion at convergence: 3460.7\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-1.80452 -0.71319  0.00718  0.70280  1.81747 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n ID       (Intercept) 936.01   30.594  \n Residual              34.32    5.858  \nNumber of obs: 480, groups:  ID, 80\n\nFixed effects:\n            Estimate Std. Error       df t value Pr(&gt;|t|)    \n(Intercept) 252.5031     3.4310  79.0000  73.595   &lt;2e-16 ***\nblock        -0.1188     0.5348 399.0000  -0.222    0.824    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n      (Intr)\nblock 0.000 \n\nranova(lmer_size)\n\nANOVA-like table for random-effects: Single term deletions\n\nModel:\nbody_size ~ block + (1 | ID)\n         npar  logLik    AIC    LRT Df Pr(&gt;Chisq)    \n&lt;none&gt;      4 -1730.4 3468.7                         \n(1 | ID)    3 -2325.6 4657.1 1190.4  1  &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nWhat might you conclude, and why would this be foolish?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nHopefully you spotted the problem here. You have fed in a data set with 6 records per individual (with 2 sets of 3 identical values per unicorns), when you know size was only measured twice in reality. This means you‚Äôd expect to get a (potentially very) upwardly biased estimate of R and a (potentially very) downwardly biased P value when testing among-individual variance.\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nHow can we do it properly?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe can prune the data to the two actual observations per unicorns by just selecting the first assay in each block.\n\nunicorns2 &lt;- unicorns[unicorns$assay_rep == 1, ]\n\nlmer_size2 &lt;- lmer(body_size ~ block + (1 | ID),\n  data = unicorns2\n)\nsummary(lmer_size2)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: body_size ~ block + (1 | ID)\n   Data: unicorns2\n\nREML criterion at convergence: 1373.4\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-1.54633 -0.56198  0.01319  0.56094  1.42095 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n ID       (Intercept) 912.84   30.213  \n Residual              57.78    7.601  \nNumber of obs: 160, groups:  ID, 80\n\nFixed effects:\n            Estimate Std. Error       df t value Pr(&gt;|t|)    \n(Intercept) 252.5031     3.4310  79.0000  73.595   &lt;2e-16 ***\nblock        -0.1188     1.2019  79.0000  -0.099    0.922    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n      (Intr)\nblock 0.000 \n\nranova(lmer_size2)\n\nANOVA-like table for random-effects: Single term deletions\n\nModel:\nbody_size ~ block + (1 | ID)\n         npar  logLik    AIC    LRT Df Pr(&gt;Chisq)    \n&lt;none&gt;      4 -686.68 1381.3                         \n(1 | ID)    3 -771.93 1549.9 170.51  1  &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSummarise and test your random effect and you‚Äôll see the qualitative conclusions will actually be very similar using the pruned data set. Of course this won‚Äôt generallty but be true, so just be careful. Mixed models are intended to help you model repeated measures data with non-independence, but they won‚Äôt get you out of trouble if you mis-represent the true structure of observations on your dependent variable.\n\n\n\n\n5.2.9 Happy mixed-modelling\n\n\n\n\nThe superb unicorn\n\n\n\n\n\n\n\nBates, D., M. M√§chler, B. Bolker, and S. Walker. 2015. Fitting linear mixed-effects models using lme4. Journal of Statistical Software 67:1‚Äì48.\n\n\nButler, D. 2022. asreml: Fits the linear mixed model.\n\n\nHadfield, J. D. 2010. MCMC methods for multi-response generalized linear mixed models: The MCMCglmm R package. Journal of Statistical Software 33:1‚Äì22.\n\n\nHouslay, T. M., and A. J. Wilson. 2017. Avoiding the misuse of BLUP in behavioural ecology. Behavioral Ecology 28:948‚Äì952.\n\n\nKuznetsova, A., P. B. Brockhoff, and R. H. B. Christensen. 2017. lmerTest package: Tests in linear mixed effects models. Journal of Statistical Software 82:1‚Äì26.\n\n\nStoffel, M. A., S. Nakagawa, and H. Schielzeth. 2017. rptR: Repeatability estimation and variance decomposition by generalized linear mixed-effects models. Methods in Ecology and Evolution 8:1639???1644.",
    "crumbs": [
      "Statistics",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Introduction to linear mixed models</span>"
    ]
  },
  {
    "objectID": "02_03-intro_glmm.html",
    "href": "02_03-intro_glmm.html",
    "title": "\n6¬† Introduction to GLMM\n",
    "section": "",
    "text": "6.1 Lecture\ntheoretical intro to glmm and introduce DHarma package to evaluate fit of glmm\nDream pet dragon",
    "crumbs": [
      "Statistics",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Introduction to `GLMM`</span>"
    ]
  },
  {
    "objectID": "02_03-intro_glmm.html#practical",
    "href": "02_03-intro_glmm.html#practical",
    "title": "\n6¬† Introduction to GLMM\n",
    "section": "\n6.2 Practical",
    "text": "6.2 Practical\nThis is an adapted version largely inspired by the tutorial in (Bolker et al. 2009). Spatial variation in nutrient availability and herbivory is likely to cause population differentiation and maintain genetic diversity in plant populations.Here we measure the extent to which mouse-ear cress (Arabidopsis thaliana)exhibits population and genotypic variation in their responses to these im-portant environmental factors. We are particularly interested in whether these populations exhibit nutrient mediated compensation, where higher nutrient levels allow genotypes to better tolerate herbivory (Banta et al. 2010). We use GLMMs to estimate the effect of nutrient levels, simulated herbivory, and their interaction on fruit production in Arabidopsis thaliana(fixed effects), and the extent to which populations vary in their responses(random effects, or variance components)\n\n6.2.1 Packages and functions\nYou need to download the ‚Äúextra_funs.R‚Äù script for some functions used in the Practical\n\nlibrary(lme4)\nlibrary(tidyverse)\nlibrary(patchwork)\nlibrary(lattice)\nlibrary(DHARMa)\nsource(\"data/extra_funs.R\")\n\n\n6.2.2 The data set\nIn this data set, the response variable is the number of fruits (i.e.¬†seed capsules) per plant. The number of fruits produced by an individual plant(the experimental unit) was hypothesized to be a function of fixed effects,including nutrient levels (low vs.¬†high), simulated herbivory (none vs.¬†apical meristem damage), region (Sweden, Netherlands, Spain), and interactions among these. Fruit number was also a function of random effects including both the population and individual genotype. Because Arabidopsis is highly selfing, seeds of a single individual served as replicates of that individual.There were also nuisance variables, including the placement of the plant in the greenhouse, and the method used to germinate seeds. These were estimated as fixed effects but interactions were excluded.\n\n\nX observation number (we will use this observation number later, when we are accounting for overdispersion)\n\nreg a factor for region (Netherlands, Spain, Sweden).\n\npopu a factor with a level for each population.\n\ngen a factor with a level for each genotype.\n\nrack a nuisance factor for one of two greenhouse racks.\n\nnutrient a factor with levels for minimal or additional nutrients.\n\namd a factor with levels for no damage or simulated herbivory (apical meristem damage; we will sometimes refer to this as ‚Äúclipping‚Äù)\n\nstatus a nuisance factor for germination method.\n\ntotal.fruits the response; an integer count of the number of fruits per plant.\n\n6.2.3 Specifying fixed and random Effects\nHere we need to select a realistic full model, based on the scientific questions and the data actually at hand. We first load the data set and make sure that each variable is appropriately designated as numeric or factor (i.e.categorical variable).\n\ndat_tf &lt;- read.csv(\"data/Banta_TotalFruits.csv\")\nstr(dat_tf)\n\n'data.frame':   625 obs. of  9 variables:\n $ X           : int  1 2 3 4 5 6 7 8 9 10 ...\n $ reg         : chr  \"NL\" \"NL\" \"NL\" \"NL\" ...\n $ popu        : chr  \"3.NL\" \"3.NL\" \"3.NL\" \"3.NL\" ...\n $ gen         : int  4 4 4 4 4 4 4 4 4 5 ...\n $ rack        : int  2 1 1 2 2 2 2 1 2 1 ...\n $ nutrient    : int  1 1 1 1 8 1 1 1 8 1 ...\n $ amd         : chr  \"clipped\" \"clipped\" \"clipped\" \"clipped\" ...\n $ status      : chr  \"Transplant\" \"Petri.Plate\" \"Normal\" \"Normal\" ...\n $ total.fruits: int  0 0 0 0 0 0 0 3 2 0 ...\n\n\nThe X, gen, rack and nutrient variables are coded as integers, but we want them to be factors. ¬à We use mutate() dplyr üì¶, which operates within the data set, to avoid typing lots of commands like dat_tf$rack &lt;- factor(dat_tf$rack) ¬à At the same time, we reorder the clipping variable so that \"unclipped\" is the reference level (we could also have used relevel(amd,\"unclipped\")).\n\ndat_tf &lt;- mutate(\n  dat_tf,\n  X = factor(X),\n  gen = factor(gen),\n  rack = factor(rack),\n  amd = factor(amd, levels = c(\"unclipped\", \"clipped\")),\n  nutrient = factor(nutrient, label = c(\"Low\", \"High\"))\n)\n\nNow we check replication for each genotype (columns) within each population (rows).\n\n(reptab &lt;- with(dat_tf, table(popu, gen)))\n\n      gen\npopu    4  5  6 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 27 28 30 34 35 36\n  1.SP  0  0  0  0  0 39 26 35  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n  1.SW  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 28 20  0  0  0  0  0\n  2.SW  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 18 14  0  0  0\n  3.NL 31 11 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n  5.NL  0  0  0 35 26  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n  5.SP  0  0  0  0  0  0  0  0 43 22 12  0  0  0  0  0  0  0  0  0  0  0  0  0\n  6.SP  0  0  0  0  0  0  0  0  0  0  0 13 24 14  0  0  0  0  0  0  0  0  0  0\n  7.SW  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 45 47 45\n  8.SP  0  0  0  0  0  0  0  0  0  0  0  0  0  0 13 16 35  0  0  0  0  0  0  0\n\n\n\n\n\n\n\n\nExercise\n\n\n\nExercise: this mode of inspection is OK for this data set but might fail for much larger data sets or for more levels of nesting. See if you can think of some other numerical or graphical methods for inspecting the structure of data sets.\n\nplot(reptab) gives a mosaic plot of the two-way table; examine this, see if you can figure out how to interpret it, and decide whether you think it might be useful\ntry the commands colSums(reptab&gt;0) (and the equivalent for rowSums) and figure out what they are telling you.\nUsing this recipe, how would you compute the range of number of genotypes per treatment combination?\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nDo you find the mosaic plot you obtained ugly and super hard to read? Me too üòÜ\n\n\nplot(reptab)\n\n\n\nA truly useless plot no one can understand\n\n\n\n\n\ncolSums() do the sum of all the rows for each columns of a table. So colSums(reptab&gt;0) gives you for each genotype the number of populations (lines) where you have at least 1 observations.\n\n\ncolSums(reptab &gt; 0)\n\n 4  5  6 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 27 28 30 34 35 36 \n 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 \n\nrowSums(reptab &gt; 0)\n\n1.SP 1.SW 2.SW 3.NL 5.NL 5.SP 6.SP 7.SW 8.SP \n   3    2    2    3    2    3    3    3    3 \n\n\n\nYou firts need to create a new table of number of observations per treatment and genotypes\n\n\nreptab2 &lt;- with(dat_tf, table(paste(amd, nutrient, sep = \"_\"), gen))\nrange(reptab2)\n\n[1]  2 13\n\n\n\n\n\nThis reveals that we have only 2‚Äì4 populations per region and 2‚Äì3 genotypes per population. However, we also have 2‚Äì13 replicates per genotype for each treatment combination (four unique treatment combinations: 2 levels of nutrients by 2 levels of simulated herbivory). Thus, even though this was a reasonably large experiment (625 plants), there were a very small number of replicates with which to estimate variance components, and many more potential interactions than our data can support. Therefore, judicious selection of model terms, based on both biology and the data, is warranted. We note that we don‚Äôt really have enough levels per random effect, nor enough replication per unique treatment combination. Therefore, we decide to omit the fixed effect of ‚Äúregion‚Äù, although we recognize that populations in different regions are widely geographically separated.\nHowever, as in all GLMMs where the scale parameter is treated as fixed and deviations from the fixed scale parameter would be identifiable (i.e.¬†Poisson and binomial (N &gt; 1), but not binary, models) we may have to deal with overdispersion.\n\n6.2.4 Look at overall patterns in data\nI usually like to start with a relatively simple overall plot of the data, disregarding the random factors, just to see what‚Äôs going on. For reasons to be discussed below, we choose to look at the data on the log (or log(1 + x) scale. Let‚Äôs plot either box-and-whisker plots (useful summaries) or dot plots (more detailed, good for seeing if we missed anything).\n\n\nWarning: `qplot()` was deprecated in ggplot2 3.4.0.\n\n\n\n\nNumber of fruits (log + 1) as a function of treatments\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nExercise generate these plots and figure out how they work before continuing. Try conditioning/faceting on population rather than region: for facet_wrap you might want to take out the nrow = 1 specification. If you want try reorder the subplots by overall mean fruit set and/or colour the points according to the region they come from.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\np1 &lt;- qplot(\n    interaction(nutrient, amd),\n    log(1 + total.fruits),\n    data = dat_tf, geom = \"boxplot\") +\n  facet_wrap(~reg, nrow = 1) +\n  theme(axis.text.x = element_text(angle = 45)) +\n  ggtitle(\"Boxplot\")\np2 &lt;- qplot(\n    interaction(nutrient, amd),\n    log(1 + total.fruits),\n    data = dat_tf) +\n  facet_wrap(~reg, nrow = 1) +\n  stat_sum() +\n  theme(axis.text.x = element_text(angle = 45)) +\n  ggtitle(\"Dot plot\")\np1 + p2\n\n\n\n\n\n6.2.5 Choose an error distribution\nThe data are non-normal in principle (i.e., count data, so our first guess would be a Poisson distribution). If we transform total fruits with the canonical link function (log), we hope to see relatively homogeneous variances across categories and groups.\nFirst we define a new factor that represents every combination of genotype and treatment (nutrient √ó clipping) treatment, and sort it in order of increasing mean fruit set.\n\ndat_tf &lt;- dat_tf %&gt;%\n  mutate(\n    gna = reorder(interaction(gen, nutrient, amd), total.fruits, mean)\n  )\n\nNow time to plot it\n\nggplot(dat_tf, aes(x = gna, y = log(1 + total.fruits))) +\n  geom_boxplot() +\n  theme_bw() +\n  theme(axis.text.x = element_text(angle = 90))\n\n\n\nBoxplot of total fruits (log + 1) per genotypes and treatments\n\n\n\nWe could also calculate the variance for each genotype √ó treatment combination and provide a statistical summary of these variances. This reveals substantial variation among the sample variances on the transformed data. In addition to heterogeneous variances across groups, Figure 1 reveals many zeroes in groups, and some groups with a mean and variance of zero, further suggesting we need a non-normal error distribution, and perhaps something other than a Poisson distribution.\nWe could calculate Œª(mean) for each genotype √ó treatment combination and provide a statistical summary of each group‚Äôs Œª.\n\ngrp_means &lt;- with(dat_tf, tapply(total.fruits, list(gna), mean))\nsummary(grp_means)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00   11.35   23.16   31.86   49.74  122.40 \n\n\nA core property of the Poisson distribution is that the variance is equal to the mean. A simple diagnostic is a plot of the group variances against the group means:\n\nPoisson-distributed data will result in a linear pattern with slope = 1\nas long as the variance is generally greater than the mean, we call the data overdispersed. Overdispersion comes in various forms:\n\na linear mean-variance relationship with Var = œÜ¬µ (a line through the origin) with œÜ &gt; 1 is called a quasi-Poisson pattern (this term describes the mean-variance relationship, not any particular proability distribution); we can implement it statistically via quasilikelihood (Venables and Ripley, 2002) or by using a particular parameterization of the negative binomial distribution (‚ÄúNB1‚Äù inthe terminology of Hardin and Hilbe (2007))\na semi-quadratic pattern, Var = ¬µ(1 + Œ±¬µ) or ¬µ(1 + ¬µ/k), is characteristic of overdispersed data that is driven by underlying heterogeneity among samples, either the negative binomial (gamma-Poisson) or the lognormal-Poisson (Elston et al. 2001)\n\n\n\n\nWe‚Äôve already calculated the group (genotype √ó treatment) means, we calculate the variances in the same way.\n\ngrp_vars &lt;- with(\n  dat_tf,\n  tapply(\n    total.fruits,\n    list(gna), var\n  )\n)\n\nWe can get approximate estimates of the quasi-Poisson (linear) and negative binomial (linear/quadratic) pattern using lm.\n\nlm1 &lt;- lm(grp_vars ~ grp_means - 1) ## `quasi-Poisson' fit\nphi_fit &lt;- coef(lm1)\nlm2 &lt;- lm((grp_vars - grp_means) ~ I(grp_means^2) - 1)\nk_fit &lt;- 1 / coef(lm2)\n\nNow we can plot them.\n\nplot(grp_vars ~ grp_means, xlab = \"group means\", ylab = \"group variances\")\nabline(c(0, 1), lty = 2)\ntext(105, 500, \"Poisson\")\ncurve(phi_fit * x, col = 2, add = TRUE)\n## bquote() is used to substitute numeric values\n## in equations with symbols\ntext(110, 3900,\n  bquote(paste(\"QP: \", sigma^2 == .(round(phi_fit, 1)) * mu)),\n  col = 2\n)\ncurve(x * (1 + x / k_fit), col = 4, add = TRUE)\ntext(104, 7200, paste(\"NB: k=\", round(k_fit, 1), sep = \"\"), col = 4)\nl_fit &lt;- loess(grp_vars ~ grp_means)\nmvec &lt;- 0:120\nlines(mvec, predict(l_fit, mvec), col = 5)\ntext(100, 2500, \"loess\", col = 5)\n\n\n\nGraphical evaluation of distribution to use\n\n\n\nSame with ggplot\n\nggplot(\n  data.frame(grp_means, grp_vars),\n  aes(x = grp_means, y = grp_vars)) +\n  geom_point() +\n  geom_smooth(\n    aes(colour = \"Loess\"), se = FALSE) +\n  geom_smooth(\n    method = \"lm\", formula = y ~ x - 1, se = FALSE,\n    aes(colour = \"Q_Pois\")) +\n  stat_function(\n    fun = function(x) x * (1 + x / k_fit),\n    aes(colour = \"Neg_bin\")\n  ) +\n  geom_abline(\n    aes(intercept = 0, slope = 1, colour = \"Poisson\")) +\n  scale_colour_manual(\n    name = \"legend\",\n    values = c(\"blue\", \"purple\", \"black\", \"red\")) +\n  scale_fill_manual(\n    name = \"legend\",\n    values = c(\"blue\", \"purple\", \"black\", \"red\")) +\n  guides(fill = FALSE)\n\nWarning: The `&lt;scale&gt;` argument of `guides()` cannot be `FALSE`. Use \"none\" instead as\nof ggplot2 3.3.4.\n\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\nGraphical evaluation of distribution to use with ggplot\n\n\n\n\nThese fits are not rigorous statistical tests ‚Äî they violate a variety of assumptions of linear regression (e.g.¬†constant variance, independence), but they are good enough to give us an initial guess about what distributions we should use.\nExercise\n\ncompare a simple quadratic fit to the data (i.e., without the linear part) with the negative binomial and quasipoisson fits \n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nlm3 &lt;- lm(grp_vars ~ I(grp_means)^2 - 1) ## quadratic fit\nquad_fit &lt;- coef(lm3)\n\nggplot(\n  data.frame(grp_means, grp_vars),\n  aes(x = grp_means, y = grp_vars)) +\n  geom_point() +\n  geom_smooth(\n    method = \"lm\", formula = y ~ x - 1, se = FALSE,\n    aes(colour = \"Q_Pois\")) +\n  stat_function(\n    fun = function(x) x * (1 + x / k_fit),\n    aes(colour = \"Neg_bin\")\n  ) +\n  geom_smooth(\n    method = \"lm\", formula = y ~ I(x^2) - 1, se = FALSE,\n    aes(colour = \"Quad\")) +\n  scale_colour_manual(\n    name = \"legend\",\n    values = c(\"blue\", \"purple\", \"black\")) +\n  scale_fill_manual(\n    name = \"legend\",\n    values = c(\"blue\", \"purple\", \"black\")) +\n  guides(fill = FALSE)\n\n\n\nGraphical evaluation of distribution to use including quadratic effect\n\n\n\n\n\n\n\n6.2.5.1 Plotting the response vs treatments\nJust to avoid surprises\n\nggplot(dat_tf, aes(x = amd, y = log(total.fruits + 1), colour = nutrient)) +\n  geom_point() +\n  ## need to use as.numeric(amd) to get lines\n  stat_summary(aes(x = as.numeric(amd)), fun = mean, geom = \"line\") +\n  theme_bw() +\n  theme(panel.spacing = unit(0, \"lines\")) +\n  facet_wrap(~popu)\n\n\n\nFruit production by treatments by population\n\n\n\n\nggplot(dat_tf, aes(x = amd, y = log(total.fruits + 1), colour = gen)) +\n  geom_point() +\n  stat_summary(aes(x = as.numeric(amd)), fun = mean, geom = \"line\") +\n  theme_bw() +\n  ## label_both adds variable name ('nutrient') to facet labels\n  facet_grid(. ~ nutrient, labeller = label_both)\n\n\n\nFruit production by genotype by treatments\n\n\n\n\n6.2.6 Fitting group-wise GLM\nAnother general starting approach is to fit GLMs to each group of data separately, equivalent to treating the grouping variables as fixed effects. This should result in reasonable variation among treatment effects. We first fit the models, and then examine the coefficients.\n\nglm_lis &lt;- lmList(\n  total.fruits ~ nutrient * amd | gen,\n  data = dat_tf,\n  family = \"poisson\")\nplot.lmList(glm_lis)\n\nLoading required package: reshape\n\n\n\nAttaching package: 'reshape'\n\n\nThe following object is masked from 'package:lubridate':\n\n    stamp\n\n\nThe following object is masked from 'package:dplyr':\n\n    rename\n\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, smiths\n\n\nThe following object is masked from 'package:Matrix':\n\n    expand\n\n\nUsing grp as id variables\n\n\n\n\nModel coefficients for GLM fits on each genotype\n\n\n\nThree genotypes (5, 6, 34) have extreme coefficients (Fig. 5). A mixed model assumes that the underlying random effects are normally distributed, although we shouldn‚Äôt take these outliers too seriously at this point ‚Äî we are not actually plotting the random effects, or even estimates of random effects (which are not themselves guaranteed to be normally distributed), but rather separate estimates for each group. Create a plotting function for Q-Q plots of these coefficients to visualize the departure from normality.\n\nqqmath.lmList(glm_lis)\n\nUsing  as id variables\n\n\n\n\nQ-Q plots of model coefficients for GLM fits on each genotype\n\n\n\nWe see that these extreme coefficients fall far outside a normal error distribution. We shouldn‚Äôt take these outliers too seriously at this point ‚Äî we are not actually plotting the random effects, or even estimates of random effects, but rather separate estimates for each group. Especially if these groups have relatively small sample sizes, the estimates may eventually be ‚Äúshrunk‚Äù closer to the mean when we do the mixed model. We should nonetheless take care to see if the coefficients for these genotypes from the GLMM are still outliers, and take the same precautions as we usually do for outliers. For example, we can look back at the original data to see if there is something weird about the way those genotypes were collected, or try re-running the analysis without those genotypes to see if the results are robust.\n\n6.2.7 Fitting and evaluating GLMMs\nNow we (try to) build and fit a full model, using glmer in the emo::ji(\"pacakage\") lme4. This model has random effects for all genotype and population √ó treatment random effects, and for the nuisance variables for the rack and germination method (status). (Given the mean-variance relationship we saw it‚Äôs pretty clear that we are going to have to proceed eventually to a model with overdispersion, but we fit the Poisson model first for illustration.)\n\nmp1 &lt;- glmer(total.fruits ~ nutrient * amd +\n  rack + status +\n  (amd * nutrient | popu) +\n  (amd * nutrient | gen),\ndata = dat_tf, family = \"poisson\"\n)\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nModel failed to converge with max|grad| = 0.0185742 (tol = 0.002, component 1)\n\noverdisp_fun(mp1)\n\n      chisq       ratio           p \n13909.47140    23.25999     0.00000 \n\n\n\nThe overdisp_fun() is described [here] https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#testing-for-overdispersioncomputing-overdispersion-factor) on the absolutely fantastic FAQ about GLMMs by Ben Bolker https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html\nWe can ignore the model convergence for the moment. This shows that the data are (extremely) over-dispersed, given the model.\nWe can also use the excellent DHARMa üì¶ (Hartig 2022) to evaluate fit of glm and glmm. So instead of using the function overdisp_fun(), we can simply use the function testDispersion().\n\ntestDispersion(mp1)\n\n\n\n\n\n\n\n\n    DHARMa nonparametric dispersion test via sd of residuals fitted vs.\n    simulated\n\ndata:  simulationOutput\ndispersion = 1.2934, p-value = 0.384\nalternative hypothesis: two.sided\n\n\nAs you can see, DHARMa suggests that there is no overdispersion based on the distribution of residuals from simulated data. We are going to consider that we have overdispersion and adjust the model accordingly.\nNow we add the observation-level random effect to the model to account for overdispersion (Elston et al. 2001).\n\nmp2 &lt;- update(mp1, . ~ . + (1 | X))\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nModel failed to converge with max|grad| = 0.159305 (tol = 0.002, component 1)\n\n\nThe model takes much longer to fit (and gives warnings). We look just at the variance components. In particular, if we look at the correlation matrix among the genotype random effects, we see a perfect correlation.\n\nattr(VarCorr(mp2)$gen, \"correlation\")\n\n                        (Intercept) amdclipped nutrientHigh\n(Intercept)               1.0000000 -0.9965313   -0.9877088\namdclipped               -0.9965313  1.0000000    0.9882474\nnutrientHigh             -0.9877088  0.9882474    1.0000000\namdclipped:nutrientHigh   0.8321072 -0.8426404   -0.9076218\n                        amdclipped:nutrientHigh\n(Intercept)                           0.8321072\namdclipped                           -0.8426404\nnutrientHigh                         -0.9076218\namdclipped:nutrientHigh               1.0000000\n\n\nWe‚Äôll try getting rid of the correlations between clipping (amd) and nutrients, using amd+nutrient instead of amd*nutrient in the random effects specification (here it seems easier to re-do the model rather than using update to add and subtract terms).\n\nmp3 &lt;- glmer(total.fruits ~ nutrient * amd +\n  rack + status +\n  (amd + nutrient | popu) +\n  (amd + nutrient | gen) + (1 | X),\ndata = dat_tf, family = \"poisson\"\n)\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nModel failed to converge with max|grad| = 0.226429 (tol = 0.002, component 1)\n\nattr(VarCorr(mp3)$gen, \"correlation\")\n\n             (Intercept) amdclipped nutrientHigh\n(Intercept)    1.0000000 -0.9981776   -0.9966490\namdclipped    -0.9981776  1.0000000    0.9955458\nnutrientHigh  -0.9966490  0.9955458    1.0000000\n\nattr(VarCorr(mp3)$popu, \"correlation\")\n\n             (Intercept) amdclipped nutrientHigh\n(Intercept)    1.0000000  0.9970406    0.9974900\namdclipped     0.9970406  1.0000000    0.9937833\nnutrientHigh   0.9974900  0.9937833    1.0000000\n\n\nUnfortunately, we still have perfect correlations among the random effects terms. For some models (e.g.¬†random-slope models), it is possible to fit random effects models in such a way that the correlation between the different parameters (intercept and slope in the case of random-slope models) is constrained to be zero, by fitting a model like (1|f)+(0+x|f); unfortunately, because of the way lme4 is set up, this is considerably more difficult with categorical predictors (factors).\nWe have to reduce the model further in some way in order not to overfit (i.e., in order to not have perfect ¬±1 correlations among random effects). It looks like we can‚Äôt allow both nutrients and clipping in the random effect model at either the population or the genotype level. However, it‚Äôs hard to know whether we should proceed with amd or nutrient, both, or neither in the model.\nA convenient way to proceed if we are going to try fitting several different combinations of random effects is to fit the model with all the fixed effects but only observation-level random effects, and then to use update to add various components to it.\n\nmp_obs &lt;- glmer(total.fruits ~ nutrient * amd +\n  rack + status +\n  (1 | X),\ndata = dat_tf, family = \"poisson\"\n)\n\nNow, for example, update(mp_obs,.~.+(1|gen)+(amd|popu)) fits the model with intercept random effects at the genotype level and variation in clipping effects across populations.\n\n\n\n\n\n\nExercise\n\n\n\nExercise using update, fit the models with\n\nclipping variation at both genotype and population levels;\nnutrient variation at both genotype and populations; convince yourself that trying to fit variation in either clipping or nutrients leads to overfitting (perfect correlations).\nFit the model with only intercept variation at the population and genotype levels, saving it as mp4; show that there is non-zero variance estimated\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n\n\n\nmpcli &lt;- update(mp_obs, . ~ . + (amd | gen) + (amd | popu))\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nModel failed to converge with max|grad| = 0.0882114 (tol = 0.002, component 1)\n\nVarCorr(mpcli)\n\n Groups Name        Std.Dev. Corr  \n X      (Intercept) 1.431001       \n gen    (Intercept) 0.296711       \n        amdclipped  0.038708 -0.887\n popu   (Intercept) 0.754243       \n        amdclipped  0.130903 0.997 \n\n\n\n\n\n\nmpnut &lt;- update(mp_obs, . ~ . + (nutrient | gen) + (nutrient | popu))\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nModel failed to converge with max|grad| = 0.029394 (tol = 0.002, component 1)\n\nVarCorr(mpnut)\n\n Groups Name         Std.Dev. Corr  \n X      (Intercept)  1.41977        \n gen    (Intercept)  0.47882        \n        nutrientHigh 0.32631  -1.000\n popu   (Intercept)  0.74639        \n        nutrientHigh 0.12083  1.000 \n\n\n\n\n\n\nmp4 &lt;- update(mp_obs, . ~ . + (1 | gen) + (1 | popu))\nVarCorr(mp4)\n\n Groups Name        Std.Dev.\n X      (Intercept) 1.43127 \n gen    (Intercept) 0.28582 \n popu   (Intercept) 0.80598 \n\n\n\n\n\nIn other words, while it‚Äôs biologically plausible that there is some variation in the nutrient or clipping effect at the genotype or population levels, with this modeling approach we really don‚Äôt have enough data to speak confidently about these effects. Let‚Äôs check that mp4 no longer incorporates overdispersion (the observationlevel random effect should have taken care of it):\n\noverdisp_fun(mp4)\n\n      chisq       ratio           p \n177.5249980   0.2886585   1.0000000 \n\n\nUsing the DHARMa üì¶, we will also check the model. To do so we first need to simulate some data and get the scaled residuals following the DHARMa notation. Then we can check the distributional properties of the scaled residuals and see if they follow the classic assumption using the different functions provided.\n\nscaled_res &lt;- simulateResiduals(mp4)\nplot(scaled_res)\n\nDHARMa:testOutliers with type = binomial may have inflated Type I error rates for integer-valued distributions. To get a more exact result, it is recommended to re-run testOutliers with type = 'bootstrap'. See ?testOutliers for details\n\n\n\n\n\n\n\ntestZeroInflation(mp4, plot = TRUE)\n\n\n\n\n\n\n\n\n    DHARMa zero-inflation test via comparison to expected zeros with\n    simulation under H0 = fitted model\n\ndata:  simulationOutput\nratioObsSim = 1.9768, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\n\n# note about overdispersion\nsum(dat_tf$total.fruits == 0)\n\n[1] 126\n\na &lt;- predict(mp4, type = \"response\")\nb &lt;- rep(0, 500)\nfor (j in 1:500) {\n  b[j] &lt;- sum(sapply(seq(nrow(dat_tf)), function(i) rpois(1, a[i])) == 0)\n}\nhist(b)\n\n\n\n\n\n\n\n\n6.2.8 Inference\n\n6.2.8.1 Random effects\nglmer (lmer) does not return information about the standard errors or confidence intervals of the variance components.\n\nVarCorr(mp4)\n\n Groups Name        Std.Dev.\n X      (Intercept) 1.43127 \n gen    (Intercept) 0.28582 \n popu   (Intercept) 0.80598 \n\n\n\n6.2.8.1.1 Testing for random Effects\nIf we want to test the significance of the random effects we can fit reduced models and run likelihood ratio tests via anova, keeping in mind that in this case (testing a null hypothesis of zero variance, where the parameter is on the boundary of its feasible region) the reported p value is approximately twice what it should be.\n\nmp4v1 &lt;- update(mp_obs, . ~ . + (1 | popu)) ## popu only (drop gen)\nmp4v2 &lt;- update(mp_obs, . ~ . + (1 | gen)) ## gen only (drop popu)\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nunable to evaluate scaled gradient\n\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nModel failed to converge: degenerate Hessian with 2 negative eigenvalues\n\nanova(mp4, mp4v1)\n\nData: dat_tf\nModels:\nmp4v1: total.fruits ~ nutrient + amd + rack + status + (1 | X) + (1 | popu) + nutrient:amd\nmp4: total.fruits ~ nutrient + amd + rack + status + (1 | X) + (1 | gen) + (1 | popu) + nutrient:amd\n      npar    AIC    BIC  logLik deviance  Chisq Df Pr(&gt;Chisq)  \nmp4v1    9 5017.4 5057.4 -2499.7   4999.4                       \nmp4     10 5015.4 5059.8 -2497.7   4995.4 4.0639  1    0.04381 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nanova(mp4, mp4v2)\n\nData: dat_tf\nModels:\nmp4v2: total.fruits ~ nutrient + amd + rack + status + (1 | X) + (1 | gen) + nutrient:amd\nmp4: total.fruits ~ nutrient + amd + rack + status + (1 | X) + (1 | gen) + (1 | popu) + nutrient:amd\n      npar    AIC    BIC  logLik deviance  Chisq Df Pr(&gt;Chisq)    \nmp4v2    9 5031.6 5071.5 -2506.8   5013.6                         \nmp4     10 5015.4 5059.8 -2497.7   4995.4 18.212  1  1.976e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nFor various forms of linear mixed models, the RLRsim package can do efficient simulation-based hypothesis testing of variance components ‚Äî un- fortunately, that doesn‚Äôt include GLMMs. If we are sufficiently patient we can do hypothesis testing via brute-force parametric bootstrapping where we repeatedly simulate data from the reduced (null) model, fit both the re- duced and full models to the simulated data, and compute the distribution of the deviance (change in -2 log likelihood). The code below took about half an hour on a reasonably modern desktop computer.\n\nsimdev &lt;- function() {\n  newdat &lt;- simulate(mp4v1)\n  reduced &lt;- lme4::refit(mp4v1, newdat)\n  full &lt;- lme4::refit(mp4, newdat)\n  2 * (c(logLik(full) - logLik(reduced)))\n}\n\nset.seed(101)\nnulldist0 &lt;- replicate(2, simdev())\n## zero spurious (small) negative values\nnulldist[nulldist &lt; 0 & abs(nulldist) &lt; 1e-5] &lt;- 0\nobsdev &lt;- 2 * c(logLik(mp4) - logLik(mp4v1))\n\n\nmean(c(nulldist, obsdev) &gt;= obsdev)\n\n[1] 0.01492537\n\n\nThe true p-value is actually closer to 0.05 than 0.02. In other words, here the deviations from the original statistical model from that for which the original ‚Äúp value is inflated by 2‚Äù rule of thumb was derived ‚Äî fitting a GLMM instead of a LMM, and using a moderate-sized rather than an arbitrarily large (asymptotic) data set ‚Äî have made the likelihood ratio test liberal (increased type I error) rather than conservative (decreased type I error).\nWe can also inspect the random effects estimates themselves (in proper statistical jargon, these might be considered ‚Äúpredictions‚Äù rather than ‚Äúestimates‚Äù (Robinson, 1991)). We use the built-in dotplot method for the random effects extracted from glmer fits (i.e.¬†ranef(model,condVar=TRUE)), which returns a list of plots, one for each random effect level in the model.\n\nr1 &lt;- as.data.frame(ranef(mp4, condVar = TRUE, whichel = c(\"gen\", \"popu\")))\np1 &lt;- ggplot(subset(r1, grpvar == \"gen\"), aes(y = grp, x = condval)) +\n  geom_point() +\n  geom_pointrange(\n    aes(xmin = condval - condsd * 1.96, xmax = condval + condsd * 1.96)\n  ) +\n  geom_vline(aes(xintercept = 0, color = \"red\")) +\n  theme_classic() +\n  theme(legend.position = \"none\")\np2 &lt;- ggplot(subset(r1, grpvar == \"popu\"), aes(y = grp, x = condval)) +\n  geom_point() +\n  geom_pointrange(\n    aes(xmin = condval - condsd * 1.96, xmax = condval + condsd * 1.96)\n  ) +\n  geom_vline(aes(xintercept = 0, color = \"red\")) +\n  theme_classic() +\n  theme(legend.position = \"none\")\np1 + p2\n\n\n\nDistribution of BLUPs for genotypes and populations\n\n\n\nAs expected from the similarity of the variance estimates, the population-level estimates (the only shared component) do not differ much between the two models. There is a hint of regional differentiation ‚Äî the Spanish populations have higher fruit sets than the Swedish and Dutch populations. Genotype 34 again looks a little bit unusual.\n\n6.2.8.2 Fixed effects\nNow we want to do inference on the fixed effects. We use the drop1 func- tion to assess both the AIC difference and the likelihood ratio test between models. (In glmm_funs.R we define a convenience function dfun to convert the AIC tables returned by drop1 (which we will create momentarily) into ‚àÜAIC tables.) Although the likelihood ratio test (and the AIC) are asymptotic tests, comparing fits between full and reduced models is still more accurate than the Wald (curvature-based) tests shown in the summary tables for glmer fits.\n\n(dd_aic &lt;- dfun(drop1(mp4)))\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nModel failed to converge with max|grad| = 0.00959403 (tol = 0.002, component 1)\n\n\nSingle term deletions\n\nModel:\ntotal.fruits ~ nutrient + amd + rack + status + (1 | X) + (1 | \n    gen) + (1 | popu) + nutrient:amd\n             npar   dAIC\n&lt;none&gt;             0.000\nrack            1 55.083\nstatus          2  1.612\nnutrient:amd    1  1.444\n\n(dd_lrt &lt;- drop1(mp4, test = \"Chisq\"))\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nModel failed to converge with max|grad| = 0.00959403 (tol = 0.002, component 1)\n\n\nSingle term deletions\n\nModel:\ntotal.fruits ~ nutrient + amd + rack + status + (1 | X) + (1 | \n    gen) + (1 | popu) + nutrient:amd\n             npar    AIC    LRT   Pr(Chi)    \n&lt;none&gt;            5015.4                     \nrack            1 5070.5 57.083 4.179e-14 ***\nstatus          2 5017.0  5.612   0.06044 .  \nnutrient:amd    1 5016.8  3.444   0.06349 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nOn the basis of these comparisons, there appears to be a very strong effect of rack and weak effects of status and of the interaction term. Dropping the nutrient:amd interaction gives a (slightly) increased AIC (‚àÜAIC = 1.4), so the full model has the best expected predictive capability (by a small margin). On the other hand, the p-value is slightly above 0.05 (p = 0.06). At this point we remove the non-significant interaction term so we can test the main effects. (We don‚Äôt worry about removing status because it measures an aspect of experimental design that we want to leave in the model whether it is significant or not.) Once we have fitted the reduced model, we can run the LRT via anova.\n\nmp5 &lt;- update(mp4, . ~ . - amd:nutrient)\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nModel failed to converge with max|grad| = 0.00959403 (tol = 0.002, component 1)\n\nanova(mp5, mp4)\n\nData: dat_tf\nModels:\nmp5: total.fruits ~ nutrient + amd + rack + status + (1 | X) + (1 | gen) + (1 | popu)\nmp4: total.fruits ~ nutrient + amd + rack + status + (1 | X) + (1 | gen) + (1 | popu) + nutrient:amd\n    npar    AIC    BIC  logLik deviance  Chisq Df Pr(&gt;Chisq)  \nmp5    9 5016.8 5056.8 -2499.4   4998.8                       \nmp4   10 5015.4 5059.8 -2497.7   4995.4 3.4439  1    0.06349 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nExercise Test now the reduced model.\nIn the reduced model, we find that both nutrients and clipping have strong effects, whether measured by AIC or LRT. If we wanted to be still more careful about our interpretation, we would try to relax the asymptotic assumption. In classical linear models, we would do this by doing F tests with the appropriate denominator degrees of freedom. In ‚Äúmodern‚Äù mixed model approaches, we might try to use denominator-degree-of-freedom approximations such as the Kenward-Roger (despite the controversy over these approximations, they are actually available in lmerTest, but they do not apply to GLMMs. We can use a parametric bootstrap comparison between nested models to test fixed effects, as we did above for random effects, with the caveat that is computationally slow.\nIn addition, we can check the normality of the random effects and find they are reasonable (Fig. 10).\n\nr5 &lt;- as.data.frame(ranef(mp5))\nggplot(data = r5, aes(sample = condval)) +\n  geom_qq() + geom_qq_line() +\n  facet_wrap(~ grpvar) +\n  theme_classic()\n\n\n\nQ-Q plot of BLUPs from model mp5\n\n\n\nChecking everything with DHARMa also\n\nscaled_res &lt;- simulateResiduals(mp5)\nplot(scaled_res)\n\n\n\n\n\n\ntestZeroInflation(mp5, plot = TRUE)\n\n\n\n\n\n\n\n\n    DHARMa zero-inflation test via comparison to expected zeros with\n    simulation under H0 = fitted model\n\ndata:  simulationOutput\nratioObsSim = 1.9883, p-value = 0.008\nalternative hypothesis: two.sided\n\n\nIt is better than before but not perfect. I think this is completely OK and that it will extremely rarely be perfect. You need to learn what is acceptable (by that I mean you find acceptable) and be happy to justify and discuss your decisions.\n\n6.2.9 Conclusions\nOur final model includes fixed effects of nutrients and clipping, as well as the nuisance variables rack and status; observation-level random effects to ac- count for overdispersion; and variation in overall fruit set at the population and genotype levels. However, we don‚Äôt (apparently) have quite enough in- formation to estimate the variation in clipping and nutrient effects, or their interaction, at the genotype or population levels. There is a strong overall positive effect of nutrients and a slightly weaker negative effect of clipping. The interaction between clipping and nutrients is only weakly supported (i.e.¬†the p-value is not very small), but it is positive and about the same magnitude as the clipping effect, which is consistent with the statement that ‚Äúnutrients cancel out the effect of herbivory‚Äù.\n\n\n\n\n\n\nExercise\n\n\n\nExercise\n\nRe-do the analysis with region as a fixed effect.\nRe-do the analysis with a one-way layout as suggested above\n\n\n\n\n6.2.10 Happy generalized mixed-modelling\n\n\n\n\nA GLMM character\n\n\n\n\n\n\n\nBanta, J. A., M. H. H. Stevens, and M. Pigliucci. 2010. A comprehensive test of the ‚Äúlimiting resources‚Äù framework applied to plant tolerance to apical meristem damage. Oikos 119:359‚Äì369.\n\n\nBolker, B. M., M. E. Brooks, C. J. Clark, S. W. Geange, J. R. Poulsen, M. H. H. Stevens, and J.-S. S. White. 2009. Generalized linear mixed models: A practical guide for ecology and evolution. Trends in Ecology and Evolution 24:127‚Äì135.\n\n\nElston, D. A., R. Moss, T. Boulinier, C. Arrowsmith, and X. Lambin. 2001. Analysis of aggregation, a worked example: Numbers of ticks on red grouse chicks. Parasitology 122:563‚Äì569.\n\n\nHartig, F. 2022. DHARMa: Residual diagnostics for hierarchical (multi-level / mixed) regression models.",
    "crumbs": [
      "Statistics",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Introduction to `GLMM`</span>"
    ]
  },
  {
    "objectID": "02_04-intro_bayesian.html",
    "href": "02_04-intro_bayesian.html",
    "title": "\n7¬† Introduction to Bayesian Inference\n",
    "section": "",
    "text": "7.1 Lecture\nAmazing beasties and crazy animals\nDream pet dragon",
    "crumbs": [
      "Statistics",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Introduction to `Bayesian Inference`</span>"
    ]
  },
  {
    "objectID": "02_04-intro_bayesian.html#lecture",
    "href": "02_04-intro_bayesian.html#lecture",
    "title": "\n7¬† Introduction to Bayesian Inference\n",
    "section": "",
    "text": "7.1.1 Bayes‚Äô theorem\nFirst, let‚Äôs review the theorem. Mathematically, it says how to convert one conditional probability into another one.\n\\[ P(B \\mid A) = \\frac{ P(A \\mid B) * P(B)}{P(A)} \\]\nThe formula becomes more interesting in the context of statistical modeling. We have some model that describes a data-generating process and we have some observed data, but we want to estimate some unknown model parameters. In that case, the formula reads like:\n\\[ P(\\text{hypothesis} \\mid \\text{data}) = \\frac{ P(\\text{data} \\mid \\text{hypothesis}) * P(\\text{hypothesis})}{P(\\text{data})} \\]\nThese terms have conventional names:\n\\[ \\text{posterior} = \\frac{ \\text{likelihood} * \\text{prior}}{\\text{evidence}} \\]\nPrior and posterior describe when information is obtained: what we know pre-data is our prior information, and what we learn post-data is the updated information (‚Äúposterior‚Äù).\nThe likelihood in the equation says how likely the data is given the model parameters. I think of it as fit: How well do the parameters fit the data? Classical regression‚Äôs line of best fit is the maximum likelihood line. The likelihood also encompasses the data-generating process behind the model. For example, if we assume that the observed data is normally distributed, then we evaluate the likelihood by using the normal probability density function. You don‚Äôt need to know what that last sentence means. What‚Äôs important is that the likelihood contains our built-in assumptions about how the data is distributed.\nThe evidence (sometimes called average likelihood) is hareder to grasp. I am not sure how to describe it in an intuitive way. It‚Äôs there to make sure the math works out so that the posterior probabilities sum to 1. Some presentations of Bayes‚Äô theorem gloss over it and I am not the exception üòÑ. The important thing to note is that the posterior is proportional to the likelihood and prior information.\n\\[\n\\text{posterior information} \\propto\n  \\text{likelihood of data} * \\text{prior information}\n\\]\nSo simply put, you update your prior information in proportion to how well it fits the observed data. So essentially you are doing that on a daily basis for everything except when you ar doing frequentist stats üòÑ.\n\n\n\n\nBayesian Triptych\n\n\n\n\n\n\n\n\n\nA word of encouragement! The prior is an intimidating part of Bayesian statistics. It seems highly subjective, as though we are pulling numbers from thin air, and it can be overwhelming for complex models. But if we are familiar with the kind of data we are modeling, we have prior information. We can have the model simulate new observations using the prior distribution and then plot the hypothetical data. Does anything look wrong or implausible about the simulated data? If so, then we have some prior information that we can include in our model. Note that we do not evaluate the plausibility of the simulated data based on the data we have in hand (the data we want to model); that‚Äôs not\n\n\n\n\n7.1.2 Intro to MCMC\nWe will now walk through a simple example coded in R to illustrate how an MCMC algorithm works.\nSuppose you are interested in the mean heart rate is of students when asked a question in a stat course. You are not sure what the exact mean value is, but you know the values are normally distributed with a standard deviation of 15. You have observed 5 individuals to have heart rate of 104, 120,160,90,130. You could use MCMC sampling to draw samples from the target distribution. We need to specify:\n\nthe starting value for the chain.\nthe length of the chain. In general, more iterations will give you more accurate output.\n\n\nset.seed(170)\nhr_obs &lt;- c(104, 112, 132, 115, 110)\n\nstart_value &lt;- 250\n\nn_iter &lt;- 2500 # define number of iterations\n\npd_mean &lt;- numeric(n_iter) # create vector for sample values\n\npd_mean[1] &lt;- start_value # define starting value\n\nfor (i in 2:n_iter) {\n  proposal &lt;- pd_mean[i - 1] + MASS::mvrnorm(1, 0, 5) # proposal\n  lprop &lt;- sum(dnorm(proposal, hr_obs, 15)) # likelihood of proposed parameter\n  lprev &lt;- sum(dnorm(pd_mean[i - 1], hr_obs, 15))\n  if (lprop / lprev &gt; runif(1)) { # if likelihood of prosposed &gt; likehood previous accept\n    # and if likelihood is lower accept with random noise\n    pd_mean[i] &lt;- proposal\n  } # if true sample the proposal\n  else {\n    (pd_mean[i] &lt;- pd_mean[i - 1])\n  } # if false sample the current value\n}\npd_mean &lt;- as.mcmc(data.frame(mean = pd_mean))\nmcmc_combo(pd_mean, combo = c(\"trace\", \"dens\"))\n\n\n\n\n\n\nsummary(pd_mean)\n\n\nIterations = 1:2500\nThinning interval = 1 \nNumber of chains = 1 \nSample size per chain = 2500 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n          Mean             SD       Naive SE Time-series SE \n      125.8105        32.8672         0.6573        13.3046 \n\n2. Quantiles for each variable:\n\n  2.5%    25%    50%    75%  97.5% \n 75.53 108.03 122.19 136.12 225.46 \n\n\n\nset.seed(170)\nhr_obs &lt;- c(104, 112, 132, 115, 110)\nn_iter &lt;- 2500 # define number of iterations\n\nn_chain &lt;- 3\nstart_value &lt;- c(250, 100, 50)\n\npd_mean &lt;- array(NA, dim = c(n_iter, n_chain, 1), dimnames = list(iter = NULL, chain = NULL, params = \"beta\")) # create vector for sample values\n\nfor (j in seq_len(n_chain)) {\n  pd_mean[1, j, 1] &lt;- start_value[j] # define starting value\n  for (i in 2:n_iter) {\n    proposal &lt;- pd_mean[i - 1, j, 1] + MASS::mvrnorm(1, 0, 5) # proposal\n    if (sum(dnorm(proposal, hr_obs, 15)) # likelihood of proposed parameter\n    / sum(dnorm(pd_mean[i - 1, j, 1], hr_obs, 15)) &gt; runif(1, 0, 1)) {\n      pd_mean[i, j, 1] &lt;- proposal\n    } # if true sample the proposal\n    else {\n      (pd_mean[i, j, 1] &lt;- pd_mean[i - 1, j, 1])\n    } # if false sample the current value\n  }\n}\ncolor_scheme_set(\"mix-blue-red\")\nmcmc_combo(pd_mean, combo = c(\"trace\", \"dens_overlay\"))\n\n\n\n\n\n\nsummary(pd_mean)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  41.65   99.32  109.68  112.71  122.52  250.00 \n\nmcmc_combo(pd_mean, combo = c(\"trace\", \"dens_overlay\"), n_warmup = 500)\n\n\n\n\n\n\npd_burn &lt;- pd_mean[-c(1:500), , , drop = FALSE]\nsummary(pd_burn)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  51.98  100.71  110.38  111.42  122.69  163.58 \n\nmcmc_combo(pd_burn, combo = c(\"trace\", \"dens_overlay\"), iter1 = 501)\n\n\n\n\n\n\n\n\n7.1.3 Inferences\n\n7.1.3.1 Fixed effects\nEasy peazy lemon squeezy just have a look at the posteriro distribution, does it overlap 0 yes or no.\ntalk about mean, median and mode of a distribution as well as credible intervals\n\n7.1.3.2 Random effects\nQuite a bit more harder. because constrained to be positive\n\nInterpreting posterior distribution\nDIC\nWAIC",
    "crumbs": [
      "Statistics",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Introduction to `Bayesian Inference`</span>"
    ]
  },
  {
    "objectID": "02_04-intro_bayesian.html#practical",
    "href": "02_04-intro_bayesian.html#practical",
    "title": "\n7¬† Introduction to Bayesian Inference\n",
    "section": "\n7.2 Practical",
    "text": "7.2 Practical\nIn this practical, we will revisit our analysis on unicorn aggressivity. Honestly, we can use any other data with repeated measures for this exercise but I just love unicorns ‚ù§Ô∏è. However, instead of fittng the model using lmer() from the lmerTest üì¶ (Kuznetsova et al. 2017), we will refit the model using 2 excellent softwares fitting models with a Bayesian approach: MCMCglmm (Hadfield 2010) and brms (B√ºrkner 2021).\n\n7.2.1 R packages needed\nFirst we load required libraries\n\nlibrary(lmerTest)\nlibrary(tidyverse)\nlibrary(rptR)\nlibrary(brms)\nlibrary(MCMCglmm)\nlibrary(bayesplot)\n\n\n7.2.2 A refresher on unicorn ecology\nThe last model on unicorns was:\naggression ~ opp_size + scale(body_size, center = TRUE, scale = TRUE)\n              + scale(assay_rep, scale = FALSE) + block\n              + (1 | ID)\nThose scaled terms are abit a sore for my eyes and way too long if we need to type them multiple times in this practical. So first let‚Äôs recode them. -\n\nunicorns &lt;- read.csv(\"data/unicorns_aggression.csv\")\nunicorns &lt;- unicorns %&gt;%\n  mutate(\n    body_size_sc = scale(body_size),\n    assay_rep_sc = scale(assay_rep, scale = FALSE)\n  )\n\nOk now we can fit the same model by just using:\naggression ~ opp_size + body_size_sc + assay_rep_sc + block\n              + (1 | ID)\nWe can now fit a model using lmer(). Since we want to compare a bit REML and Bayesian aproaches, I am going to wrap the model function in a function called system.time(). This function simply estimate the user and computer time use by the function.\n\nmer_time &lt;- system.time(\n  m_mer &lt;- lmer(\n    aggression ~ opp_size + body_size_sc + assay_rep_sc + block\n      + (1 | ID),\n    data = unicorns\n  )\n)\nmer_time\n\n   user  system elapsed \n  0.092   0.000   0.092 \n\nsummary(m_mer)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: aggression ~ opp_size + body_size_sc + assay_rep_sc + block +  \n    (1 | ID)\n   Data: unicorns\n\nREML criterion at convergence: 1136.5\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-2.85473 -0.62831  0.02545  0.68998  2.74064 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n ID       (Intercept) 0.02538  0.1593  \n Residual             0.58048  0.7619  \nNumber of obs: 480, groups:  ID, 80\n\nFixed effects:\n              Estimate Std. Error        df t value Pr(&gt;|t|)    \n(Intercept)    9.00181    0.03907  78.07315 230.395   &lt;2e-16 ***\nopp_size       1.05141    0.04281 396.99857  24.562   &lt;2e-16 ***\nbody_size_sc   0.03310    0.03896  84.21144   0.850    0.398    \nassay_rep_sc  -0.05783    0.04281 396.99857  -1.351    0.177    \nblock         -0.02166    0.06955 397.00209  -0.311    0.756    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) opp_sz bdy_s_ assy__\nopp_size     0.000                     \nbody_siz_sc  0.000  0.000              \nassay_rp_sc  0.000 -0.100  0.000       \nblock        0.000  0.000  0.002  0.000\n\n\nOk so it took no time at all to do it and we got our ‚Äúclassic‚Äù results.\n\n7.2.3 MCMCglmm\nWhat makes MCMCglmm so useful and powerful üí™ in ecology and for practical Bayesian people is that:\n\nit is blazing fast ‚è© (for Bayesian analysis) for some models particularly models with structured covariances\nit is fairly intuitive to code\n\nbut it also has some inconvenients:\n\nit is blazing fast for Bayesian analysis meaning it is üêå compared to maximum likelihood approaches\nit has some limitations in terms of functionality, distribution availability and model specifications compared to other Bayesian softwares\nthe priors, oh, the priors üò≠, are a bit tricky to code and understand ü§Ø.\n\n\n7.2.3.1 Fitting the Model\nSo here is how we can code the model in MCMCglmm(). It is fairly similar to lmer() except that the random effects are specified in a different argument.\n\nmcglm_time &lt;- system.time(\n  m_mcmcglmm &lt;- MCMCglmm(\n    aggression ~ opp_size + body_size_sc + assay_rep_sc + block,\n    random = ~ID,\n    data = unicorns\n  )\n)\n\n\n                       MCMC iteration = 0\n\n                       MCMC iteration = 1000\n\n                       MCMC iteration = 2000\n\n                       MCMC iteration = 3000\n\n                       MCMC iteration = 4000\n\n                       MCMC iteration = 5000\n\n                       MCMC iteration = 6000\n\n                       MCMC iteration = 7000\n\n                       MCMC iteration = 8000\n\n                       MCMC iteration = 9000\n\n                       MCMC iteration = 10000\n\n                       MCMC iteration = 11000\n\n                       MCMC iteration = 12000\n\n                       MCMC iteration = 13000\n\nsummary(m_mcmcglmm)\n\n\n Iterations = 3001:12991\n Thinning interval  = 10\n Sample size  = 1000 \n\n DIC: 1128.004 \n\n G-structure:  ~ID\n\n   post.mean  l-95% CI u-95% CI eff.samp\nID  0.003686 9.807e-14   0.0262    45.81\n\n R-structure:  ~units\n\n      post.mean l-95% CI u-95% CI eff.samp\nunits    0.6044   0.5228   0.6819     1000\n\n Location effects: aggression ~ opp_size + body_size_sc + assay_rep_sc + block \n\n             post.mean l-95% CI u-95% CI eff.samp  pMCMC    \n(Intercept)    9.00152  8.93150  9.07158     1000 &lt;0.001 ***\nopp_size       1.04940  0.96813  1.12946     1000 &lt;0.001 ***\nbody_size_sc   0.03154 -0.03985  0.09563     1000  0.410    \nassay_rep_sc  -0.05620 -0.13196  0.03546      893  0.184    \nblock         -0.02069 -0.16186  0.11553     1000  0.774    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nmcglm_time\n\n   user  system elapsed \n  1.657   0.000   1.657 \n\n\nModel is slow and not good. We need more iteration and maybe even a longer burnin, and honestly maybe better priors.\nWe can still take the time to have a look at the R object output from MCMCglmm(). The 2 main parts we are interrested in are:\n\n\nSol which stand for the model solution and includes the posteriro distribution of the fixed effects\n\nVCV, for the variance covariance estimates, which includes the posterior distribution of all (co)variances estimates for both random effects and residual variance.\n\n\nomar &lt;- par()\npar(mar = c(4, 2, 1.5, 2))\nplot(m_mcmcglmm$Sol)\n\n\n\nPosterior trace and distribution of the parameters in m_mcmcglmm using default settings\n\n\n\n\n\nPosterior trace and distribution of the parameters in m_mcmcglmm using default settings\n\n\nplot(m_mcmcglmm$VCV)\n\n\n\nPosterior trace and distribution of the parameters in m_mcmcglmm using default settings\n\n\npar(omar)\nautocorr.diag(m_mcmcglmm$VCV)\n\n               ID       units\nLag 0   1.0000000  1.00000000\nLag 10  0.8042405 -0.02074155\nLag 50  0.4807583 -0.04264317\nLag 100 0.1951356  0.04422296\nLag 500 0.1254589  0.04401956\n\n\nTalk about autocorrelation, mixing, convergence and priors here\n\nn_samp &lt;- 1000\nthin &lt;- 500\nburnin &lt;- 20000\nmcglm_time &lt;- system.time(\n  m_mcmcglmm &lt;- MCMCglmm(\n    aggression ~ opp_size + body_size_sc + assay_rep_sc + block,\n    random = ~ID,\n    data = unicorns,\n    nitt = n_samp * thin + burnin, thin = thin, burnin = burnin,\n    verbose = FALSE,\n    prior = list(\n      R = list(V = 1, nu = 0.002),\n      G = list(\n        G1 = list(V = 1, nu = 0.002)\n      )\n    )\n  )\n)\nsummary(m_mcmcglmm)\n\n\n Iterations = 20001:519501\n Thinning interval  = 500\n Sample size  = 1000 \n\n DIC: 1126.66 \n\n G-structure:  ~ID\n\n   post.mean  l-95% CI u-95% CI eff.samp\nID   0.01987 0.0002904  0.05458     1000\n\n R-structure:  ~units\n\n      post.mean l-95% CI u-95% CI eff.samp\nunits    0.5917   0.5188   0.6763     1000\n\n Location effects: aggression ~ opp_size + body_size_sc + assay_rep_sc + block \n\n             post.mean l-95% CI u-95% CI eff.samp  pMCMC    \n(Intercept)    9.00136  8.92221  9.07383     1000 &lt;0.001 ***\nopp_size       1.05363  0.96382  1.13650     1000 &lt;0.001 ***\nbody_size_sc   0.03373 -0.03781  0.10686     1000  0.396    \nassay_rep_sc  -0.05861 -0.14186  0.02882     1000  0.182    \nblock         -0.02709 -0.16061  0.11441     1000  0.698    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nmcglm_time\n\n   user  system elapsed \n 61.561   0.008  61.665 \n\n\nevaluate model here\n\nomar &lt;- par()\npar(mar = c(4, 2, 1.5, 2))\nplot(m_mcmcglmm$Sol)\n\n\n\nPosterior trace and distribution of the paremeters in m_mcmcglmm with better settings\n\n\n\n\n\nPosterior trace and distribution of the paremeters in m_mcmcglmm with better settings\n\n\nplot(m_mcmcglmm$VCV)\n\n\n\nPosterior trace and distribution of the paremeters in m_mcmcglmm with better settings\n\n\npar(omar)\nautocorr.diag(m_mcmcglmm$VCV)\n\n                    ID        units\nLag 0      1.000000000  1.000000000\nLag 500    0.013876043 -0.044235206\nLag 2500   0.026120260 -0.048012241\nLag 5000  -0.049357725  0.021158672\nLag 25000  0.002544256 -0.003722595\n\n\n\n7.2.4 Inferences\n\n7.2.4.1 Fixed effects\nEasy peazy lemon squeezy just have a look at the posterior distribution, does it overlap 0 yes or no.\n\nposterior.mode(m_mcmcglmm$Sol)\n\n (Intercept)     opp_size body_size_sc assay_rep_sc        block \n  9.00632282   1.07353252   0.03500916  -0.04048582  -0.03276275 \n\nHPDinterval(m_mcmcglmm$Sol)\n\n                   lower      upper\n(Intercept)   8.92221005 9.07383400\nopp_size      0.96382086 1.13649873\nbody_size_sc -0.03781276 0.10685606\nassay_rep_sc -0.14185602 0.02882443\nblock        -0.16060691 0.11440706\nattr(,\"Probability\")\n[1] 0.95\n\n\n\n7.2.4.2 Random effects\nQuite a bit more harder. because constrained to be positive\n\nposterior.mode(m_mcmcglmm$VCV)\n\n        ID      units \n0.00096263 0.59129362 \n\nHPDinterval(m_mcmcglmm$VCV)\n\n             lower      upper\nID    0.0002903938 0.05458376\nunits 0.5188238599 0.67634529\nattr(,\"Probability\")\n[1] 0.95\n\n\n\n7.2.5 brms\nbrms is an acronym for Bayesian Regression Models using ‚ÄòStan‚Äô (B√ºrkner 2021). It is a package developed to fit regression models with a Bayesian approach using the amazing stan software (Stan Development Team 2021).\nWhat makes brms so useful and powerful üí™ in ecology is that:\n\nit is really intuitive to code (same syntax as glmer())\nit is incredibly flexible since it is essentially a front end for stan via its rstan interface (rstan?)\n\n\nbut with great powers come great responsability üï∑\n\nbrm_time &lt;- system.time(\n  m_brm &lt;- brm(\n    aggression ~ opp_size + body_size_sc + assay_rep_sc + block\n      + (1 | ID),\n    data = unicorns, iter = 4750, warmup = 1000, thin = 15, cores = 4\n    # refresh = 0\n  )\n)\n\nCompiling Stan program...\n\n\nStart sampling\n\nbrm_time\n\n   user  system elapsed \n 99.968   6.555  89.740 \n\nsummary(m_brm)\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: aggression ~ opp_size + body_size_sc + assay_rep_sc + block + (1 | ID) \n   Data: unicorns (Number of observations: 480) \n  Draws: 4 chains, each with iter = 4750; warmup = 1000; thin = 15;\n         total post-warmup draws = 1000\n\nGroup-Level Effects: \n~ID (Number of levels: 80) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.14      0.07     0.01     0.27 1.00     1023     1014\n\nPopulation-Level Effects: \n             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept        9.00      0.04     8.93     9.08 1.00      979      910\nopp_size         1.05      0.04     0.97     1.14 1.00      857      984\nbody_size_sc     0.03      0.04    -0.04     0.11 1.00     1000     1080\nassay_rep_sc    -0.06      0.05    -0.14     0.03 1.00     1020      880\nblock           -0.02      0.07    -0.16     0.12 1.00     1028      976\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.77      0.03     0.72     0.83 1.00     1034      935\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\nmcmc_acf_bar(m_brm, regex_pars = c(\"sd\"))\n\nWarning: The `facets` argument of `facet_grid()` is deprecated as of ggplot2 2.2.0.\n‚Ñπ Please use the `rows` argument instead.\n‚Ñπ The deprecated feature was likely used in the bayesplot package.\n  Please report the issue at &lt;https://github.com/stan-dev/bayesplot/issues/&gt;.\n\n\n\n\nAutocorrelation in the chain for variance parameters in model m_brm\n\n\n\n\n7.2.5.1 Hunder the hood\nhave a look at the stan code\n\nstancode(m_brm)\n\n// generated with brms 2.20.4\nfunctions {\n}\ndata {\n  int&lt;lower=1&gt; N;  // total number of observations\n  vector[N] Y;  // response variable\n  int&lt;lower=1&gt; K;  // number of population-level effects\n  matrix[N, K] X;  // population-level design matrix\n  int&lt;lower=1&gt; Kc;  // number of population-level effects after centering\n  // data for group-level effects of ID 1\n  int&lt;lower=1&gt; N_1;  // number of grouping levels\n  int&lt;lower=1&gt; M_1;  // number of coefficients per level\n  array[N] int&lt;lower=1&gt; J_1;  // grouping indicator per observation\n  // group-level predictor values\n  vector[N] Z_1_1;\n  int prior_only;  // should the likelihood be ignored?\n}\ntransformed data {\n  matrix[N, Kc] Xc;  // centered version of X without an intercept\n  vector[Kc] means_X;  // column means of X before centering\n  for (i in 2:K) {\n    means_X[i - 1] = mean(X[, i]);\n    Xc[, i - 1] = X[, i] - means_X[i - 1];\n  }\n}\nparameters {\n  vector[Kc] b;  // regression coefficients\n  real Intercept;  // temporary intercept for centered predictors\n  real&lt;lower=0&gt; sigma;  // dispersion parameter\n  vector&lt;lower=0&gt;[M_1] sd_1;  // group-level standard deviations\n  array[M_1] vector[N_1] z_1;  // standardized group-level effects\n}\ntransformed parameters {\n  vector[N_1] r_1_1;  // actual group-level effects\n  real lprior = 0;  // prior contributions to the log posterior\n  r_1_1 = (sd_1[1] * (z_1[1]));\n  lprior += student_t_lpdf(Intercept | 3, 8.9, 2.5);\n  lprior += student_t_lpdf(sigma | 3, 0, 2.5)\n    - 1 * student_t_lccdf(0 | 3, 0, 2.5);\n  lprior += student_t_lpdf(sd_1 | 3, 0, 2.5)\n    - 1 * student_t_lccdf(0 | 3, 0, 2.5);\n}\nmodel {\n  // likelihood including constants\n  if (!prior_only) {\n    // initialize linear predictor term\n    vector[N] mu = rep_vector(0.0, N);\n    mu += Intercept;\n    for (n in 1:N) {\n      // add more terms to the linear predictor\n      mu[n] += r_1_1[J_1[n]] * Z_1_1[n];\n    }\n    target += normal_id_glm_lpdf(Y | Xc, mu, b, sigma);\n  }\n  // priors including constants\n  target += lprior;\n  target += std_normal_lpdf(z_1[1]);\n}\ngenerated quantities {\n  // actual population-level intercept\n  real b_Intercept = Intercept - dot_product(means_X, b);\n}\n\n\n\n7.2.5.2 using shiny\n\nlaunch_shinystan(m_brm)\n\n\n\n\n\nShinystan interface\n\n\n\n\n7.2.6 Inferences\n\n7.2.6.1 Fixed effects\n\nsummary(m_brm)\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: aggression ~ opp_size + body_size_sc + assay_rep_sc + block + (1 | ID) \n   Data: unicorns (Number of observations: 480) \n  Draws: 4 chains, each with iter = 4750; warmup = 1000; thin = 15;\n         total post-warmup draws = 1000\n\nGroup-Level Effects: \n~ID (Number of levels: 80) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.14      0.07     0.01     0.27 1.00     1023     1014\n\nPopulation-Level Effects: \n             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept        9.00      0.04     8.93     9.08 1.00      979      910\nopp_size         1.05      0.04     0.97     1.14 1.00      857      984\nbody_size_sc     0.03      0.04    -0.04     0.11 1.00     1000     1080\nassay_rep_sc    -0.06      0.05    -0.14     0.03 1.00     1020      880\nblock           -0.02      0.07    -0.16     0.12 1.00     1028      976\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.77      0.03     0.72     0.83 1.00     1034      935\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\nmcmc_plot(m_brm, regex_pars = \"b_\")\n\n\n\nFixed effect estimates (with 95% credible intervals) from model m_brm\n\n\n\n\n7.2.6.2 Random effects\n\nsummary(m_brm)\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: aggression ~ opp_size + body_size_sc + assay_rep_sc + block + (1 | ID) \n   Data: unicorns (Number of observations: 480) \n  Draws: 4 chains, each with iter = 4750; warmup = 1000; thin = 15;\n         total post-warmup draws = 1000\n\nGroup-Level Effects: \n~ID (Number of levels: 80) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.14      0.07     0.01     0.27 1.00     1023     1014\n\nPopulation-Level Effects: \n             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept        9.00      0.04     8.93     9.08 1.00      979      910\nopp_size         1.05      0.04     0.97     1.14 1.00      857      984\nbody_size_sc     0.03      0.04    -0.04     0.11 1.00     1000     1080\nassay_rep_sc    -0.06      0.05    -0.14     0.03 1.00     1020      880\nblock           -0.02      0.07    -0.16     0.12 1.00     1028      976\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.77      0.03     0.72     0.83 1.00     1034      935\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\nmcmc_plot(m_brm, pars = c(\"sd_ID__Intercept\", \"sigma\"))\n\nWarning: Argument 'pars' is deprecated. Please use 'variable' instead.\n\n\n\n\nAmong-individual and residual standard deviance ( with 95% credible intervals) estimated from model m_brm\n\n\n\n\n7.2.7 Happy Bayesian stats\n\n\n\n\nSherlock Holmes, a truly bayesian detective\n\n\n\n\n\n\n\nB√ºrkner, P.-C. 2021. Bayesian item response modeling in R with brms and Stan. Journal of Statistical Software 100:1‚Äì54.\n\n\nHadfield, J. D. 2010. MCMC methods for multi-response generalized linear mixed models: The MCMCglmm R package. Journal of Statistical Software 33:1‚Äì22.\n\n\nKuznetsova, A., P. B. Brockhoff, and R. H. B. Christensen. 2017. lmerTest package: Tests in linear mixed effects models. Journal of Statistical Software 82:1‚Äì26.\n\n\nStan Development Team. 2021. Stan modeling language users guide and reference manual, 2.26.",
    "crumbs": [
      "Statistics",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Introduction to `Bayesian Inference`</span>"
    ]
  },
  {
    "objectID": "02_05-multivar.html",
    "href": "02_05-multivar.html",
    "title": "\n8¬† Multivariate mixed models\n",
    "section": "",
    "text": "8.1 Lecture\nAmazing beasties and crazy animals\nDream pet dragon\nadd a comparison of lrt",
    "crumbs": [
      "Statistics",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Multivariate mixed models</span>"
    ]
  },
  {
    "objectID": "02_05-multivar.html#practical",
    "href": "02_05-multivar.html#practical",
    "title": "\n8¬† Multivariate mixed models\n",
    "section": "\n8.2 Practical",
    "text": "8.2 Practical\nIn this practical, we have collected data on the amazing blue dragon of the East that roam the sky at night.\nWe will use two different üì¶ to fit more complex models that are not possible with lmer() from lme4 üì¶ (Bates et al. 2015). We will use:\n\n\nasreml-R which is a commercial software developed by VSNi (Butler 2022). ASReml fit models using a maximum likelihood approach, is quite flexible and fast.\n\nMCMCglmm which is free and open-source and fit model using a Bayesian approach (Hadfield 2010). It is super flexible and allow to fit a wide diversity of distribution.\n\nThe aims of the practical are to learn:\n\nHow to phrase questions of interest in terms of variances and covariances (or derived correlations or regressions);\nHow to incorporate more advanced model structures, such as:\n\nFixed effects that apply only to a subset of the response traits;\nTraits which are measured a different number of times (e.g., repeated measures of behaviour and a single value of breeding success);\n\n\nHypothesis testing using likelihood ratio tests.\n\n\n8.2.1 R packages needed\nFirst we load required libraries\n\nlibrary(lmerTest)\nlibrary(tidyverse)\nlibrary(asreml)\nlibrary(MCMCglmm)\nlibrary(nadiv)\n\n\n8.2.2 The blue dragon of the East\nFor this practical, we have collected data on the amazing blue dragon of the East that roam the sky at night.\n\n\n\n\nBlue dragon male\n\n\n\nWe tagged all dragons individually when they hatch from their eggs. Here, we concentrate on female dragon that produce a single clucth of eggs per mating seasons. Adult femlae blue dragons need to explore vast amount of land to find a compatible male. We thus hypothesized that maximum flight speed as well as exploration are key traits to determine fitness. We were able to obtain repeated measures of flying speed and exploration on 80 adult females during one mating season and also measure the number of egg layed at the end of the season.\nEach females was capture 4 times during the season and each time we measured the maximum flying speed using a wind tunnel and exploration using a openfield test.\nThe data frame has 6 variables:\n\nID: Individual identity\nassay_rep: the repeat number of the behavioural assay\nmax_speed: maximum flying speed\nexploration:\neggs: measure of reproductive succes measured only once per individual\nbody_size: individual body size measured on the day of the test\n\n\ndf_dragons &lt;- read.csv(\"data/dragons.csv\")\nstr(df_dragons)\n\n'data.frame':   320 obs. of  6 variables:\n $ ID         : chr  \"S_1\" \"S_1\" \"S_1\" \"S_1\" ...\n $ assay_rep  : int  1 2 3 4 1 2 3 4 1 2 ...\n $ max_speed  : num  58.7 57.9 64.3 61.4 65.5 ...\n $ exploration: num  126 125 127 127 125 ...\n $ eggs       : int  39 NA NA NA 56 NA NA NA 51 NA ...\n $ body_size  : num  21.7 21.5 21.3 20.8 25.7 ...\n\n\nTo help with convergence of the model, and also help with parameter interpretation, we will first scale our covariates.\n\ndf_dragons &lt;- df_dragons %&gt;%\n  mutate(\n    body_size_sc = scale(body_size),\n    assay_rep_sc = scale(assay_rep, scale = FALSE)\n  )\n\n\n8.2.3 Multiple univariate models\nWe first use the lme4 üì¶ to determine the proportion of phenotypic variation (adjusted for fixed effects) that is due to differences among individuals, separately for each trait with repeated measures.\n\n8.2.3.1 Flying speed\nOur model includes fixed effects of the assay repeat number (centred) and individual body size (centred and scaled to standard deviation units), as we wish to control for any systematic effects of these variables on individual behaviour. Be aware that controlling variables are at your discretion ‚Äî for example, while we want to characterise among-individual variance in flying speed after controlling for size effects in this study, others may wish to characterise among-individual variance in flying speed without such control. Using techniques shown later in the practical, it would be entirely possible to characterise both among-individual variance in flying speed and in size, and the among-individual covariance between these measurements.\n\nlmer_f &lt;- lmer(max_speed ~ assay_rep_sc + body_size_sc + (1 | ID),\n  data = df_dragons\n)\npar(mfrow = c(1, 3))\nplot(resid(lmer_f, type = \"pearson\") ~ fitted(lmer_f))\nqqnorm(residuals(lmer_f))\nqqline(residuals(lmer_f))\nhist(residuals(lmer_f))\n\n\n\nChecking assumptions of model lmer_f\n\n\nsummary(lmer_f)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: max_speed ~ assay_rep_sc + body_size_sc + (1 | ID)\n   Data: df_dragons\n\nREML criterion at convergence: 1791.4\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.3645 -0.6496 -0.1154  0.6463  2.6894 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n ID       (Intercept)  6.951   2.636   \n Residual             11.682   3.418   \nNumber of obs: 320, groups:  ID, 80\n\nFixed effects:\n             Estimate Std. Error       df t value Pr(&gt;|t|)    \n(Intercept)   63.5344     0.3513  78.0954 180.870   &lt;2e-16 ***\nassay_rep_sc  -0.1519     0.1709 238.9807  -0.889    0.375    \nbody_size_sc   0.4468     0.3445  88.0328   1.297    0.198    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) assy__\nassay_rp_sc  0.000       \nbody_siz_sc  0.000 -0.002\n\n\nHaving examined diagnostic plots of the model fit, we can check the model summary. We are interested in the random effects section of the lme4 model output (specifically the variance component ‚Äî note that the standard deviation here is simply the square root of the variance). Evidence for ‚Äòanimal personality‚Äô (or ‚Äòconsistent among-individual differences in behaviour‚Äô) in the literature is largely taken from the repeatability of behaviorual traits: we can compute this repeatability (also known as the intraclass correlation coefficient) by dividing the variance in the trait due to differences among individuals (\\(V_{ID}\\)) by the total phenotypic variance after accounting for the fixed effects (\\(V_{ID} + V_{residual}\\) ).\n\nrep_flying &lt;- as.data.frame(VarCorr(lmer_f)) %&gt;%\n  select(grp, vcov) %&gt;%\n  spread(grp, vcov) %&gt;%\n  mutate(repeatability = ID / (ID + Residual))\nrep_flying\n\n\n\n\nVariance components and repeatbility for the maximum flying speed of blue dragons\n\nID\nResidual\nrepeatability\n\n\n6.951\n11.682\n0.373\n\n\n\n\nSo we can see that 37.31% of the phenotypic variation in boldness (having controlled for body size and assay repeat number) is due to differences among individuals.\n\n8.2.3.2 Exploration\n\nlmer_e &lt;- lmer(exploration ~ assay_rep_sc + body_size_sc + (1 | ID),\n  data = df_dragons\n)\npar(mfrow = c(1, 3))\nplot(resid(lmer_e, type = \"pearson\") ~ fitted(lmer_e))\nqqnorm(residuals(lmer_e))\nqqline(residuals(lmer_e))\nhist(residuals(lmer_e))\n\n\n\nChecking assumptions of model lmer_e\n\n\nsummary(lmer_e)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: exploration ~ assay_rep_sc + body_size_sc + (1 | ID)\n   Data: df_dragons\n\nREML criterion at convergence: 1691.2\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-2.73290 -0.62520  0.01635  0.55523  2.95896 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n ID       (Intercept) 3.623    1.903   \n Residual             9.091    3.015   \nNumber of obs: 320, groups:  ID, 80\n\nFixed effects:\n              Estimate Std. Error        df t value Pr(&gt;|t|)    \n(Intercept)  127.22524    0.27148  78.08871 468.639   &lt;2e-16 ***\nassay_rep_sc  -0.07811    0.15076 238.99943  -0.518    0.605    \nbody_size_sc   0.26114    0.26806  85.68180   0.974    0.333    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) assy__\nassay_rp_sc  0.000       \nbody_siz_sc  0.000 -0.002\n\n\nSo the model looks good and we can see our estimates for both fixed and random effects. We can now estimate the repeatbility of exploration.\n\nrep_expl &lt;- as.data.frame(VarCorr(lmer_e)) %&gt;%\n  select(grp, vcov) %&gt;%\n  spread(grp, vcov) %&gt;%\n  mutate(repeatability = ID / (ID + Residual))\nrep_expl\n\n\n\n\nVariance components and repeatability for exploration behaviour of blue dragons\n\nID\nResidual\nrepeatability\n\n\n3.623\n9.091\n0.285\n\n\n\n\nBoth of traits of interest are repeatable at the among-individual level. So, the remaining question is estimating the relation between these two traits. Are individuals that are consistently faster than average also more exploratory than average (and vice versa)?\n\n8.2.3.3 Correlation using BLUPs\nUsing BLUPs to estimate correlations between traits or to further investigate biological associations can lead to spurious results and anticonservative hypothesis tests and narrow confidence intervals. Hadfield et al. (2010) discuss the problem as well as present some alternative method to avoid the problem using Bayesian methods. However, it is always preferable to use multivariate models when possible.\nWe need to create a data frame that contain the BLUPs from both univariate models.\n\ndf_blups_fe &lt;- merge(\n  as.data.frame(ranef(lmer_f)),\n  as.data.frame(ranef(lmer_e)),\n  by = \"grp\"\n) %&gt;%\n  mutate(\n    speed = condval.x,\n    exploration = condval.y\n  )\n\nWe can now test the correlation among-individual between flying speed and exploration.\n\n(cor_blups &lt;- with(df_blups_fe, cor.test(speed, exploration)))\n\n\n    Pearson's product-moment correlation\n\ndata:  speed and exploration\nt = 3.2131, df = 78, p-value = 0.00191\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.1320924 0.5223645\nsample estimates:\n      cor \n0.3418867 \n\nggplot(df_blups_fe, aes(x = exploration, y = speed)) +\n  geom_point() +\n  labs(xlab = \"Exploration (BLUP)\", ylab = \"Flying speed (BLUP)\") +\n  theme_classic()\n\n\n\nRelation between exploration and flying speed using BLUPs from univariate models\n\n\n\nAs you can see, we get a positive correlation with a very small p-value (P = 0.00191), indicating that these traits are involved in a behavioural syndrome. While the correlation itself is fairly weak ($r = 0.342), it appears to be highly significant, and suggests that individuals that are faster than average also tend to be more exploratory than average. However, as discussed in Hadfield et al. (2010) and Houslay and Wilson (2017), using BLUPs in this way leads to anticonservative significance tests. This is because the error inherent in their prediction is not carried forward from the lmer models to the subsequent analysis (in this case, a correlation test). To illustrate this point quickly, below we plot the individual estimates along with their associated standard errors.\n\nggplot(df_blups_fe, aes(x = exploration, y = speed)) +\n  geom_point() +\n  geom_linerange(aes(\n    xmin = exploration - condsd.x,\n    xmax = exploration + condsd.x\n  )) +\n  geom_linerange(aes(\n    ymin = speed - condsd.y,\n    ymax = speed + condsd.y\n  )) +\n  labs(\n    xlab = \"Exploration (BLUP +/- SE)\",\n    ylab = \"Flying speed (BLUP +/- SE)\"\n  ) +\n  theme_classic()\n\n\n\nRelation between exploration and flying speed using BLUPs from univariate models including +/- SE as error bars\n\n\n\n\n8.2.4 Multivariate approach\n\n8.2.4.1 Based on ASRemlR\nThe correct approach for testing the hypothesised relation between speed and exploration uses both response variables in a two-trait (‚Äòbivariate‚Äô) mixed model. This model estimates the among-individual variance for each response variable (and the covariance between them). Separate (co)variances are also fitted for the residual variation. The bivariate model also allows for fixed effects to be fitted on both response variables. We set up our model using the asreml function call, with our bivariate response variable being exploration and flying speed bound together using cbind. You will also note that we scale our response variables, meaning that each is centred at their mean value and standardised to units of 1 standard deviation. This is not essential, but simply makes it easier for the model to be fit. Scaling the response variables also aids our understanding of the output, as both flying speed and exploration are now on the same scale.\nasreml can be a bit specific sometime and random effects should absolutely be factor and not character or integer\n\ndf_dragons &lt;- df_dragons %&gt;%\n  mutate(\n    ID = as.factor(ID),\n    speed_sc = scale(max_speed),\n    exploration_sc = scale(exploration)\n  )\n\nasr_us &lt;- asreml(\n  cbind(speed_sc, exploration_sc) ~ trait +\n    trait:assay_rep_sc + trait:body_size_sc,\n  random = ~ ID:us(trait),\n  residual = ~ units:us(trait),\n  data = df_dragons,\n  maxiter = 100\n)\n\nModel fitted using the sigma parameterization.\nASReml 4.1.0 Mon Jan 22 00:06:55 2024\n          LogLik        Sigma2     DF     wall    cpu\n 1      -333.105           1.0    634 00:06:55    0.0\n 2      -303.637           1.0    634 00:06:55    0.0\n 3      -274.849           1.0    634 00:06:55    0.0\n 4      -260.243           1.0    634 00:06:55    0.0\n 5      -256.118           1.0    634 00:06:55    0.0\n 6      -255.891           1.0    634 00:06:55    0.0\n 7      -255.889           1.0    634 00:06:55    0.0\n\n\nOn the right hand side of our model formula, we use the trait keyword to specify that this is a multivariate model ‚Äî trait itself tells the model to give us the intercept for each trait. We then interact trait with the fixed effects, assay_rep_sc and body_size_sc, so that we get estimates for the effect of these variables on each of teh 2 traits. The random effects structure starts with the random effects, where we tell the model to fit an unstructured (us) covariance matrix for the grouping variable ID. This means that the variance in exploration due to differences among individuals, the variance in boldness due to differences among individuals, and the covariance between these variances will be estimated. Next, we set a structure for the residual variation (residual), which is also sometimes known as the within-individual variation. As we have repeated measures for both traits at the individual level, we also set an unstructured covariance matrix, which estimates the residual variance for each trait and also allows the residuals to covary across the two traits. Finally, we provide the name of the data frame, and a maximum number of iterations for ASReml to attempt to fit the model. After the model has been fit by ASReml, we can check the fit using the same type of model diagnostic plots as we use for lme4:\n\npar(mfrow = c(1, 3))\nplot(residuals(asr_us) ~ fitted(asr_us))\nqqnorm(residuals(asr_us))\nqqline(residuals(asr_us))\nhist(residuals(asr_us))\n\n\n\nChecking assumptions of model asr_us\n\n\n\nThe summary part of the ASReml model fit contains a large amount of information, so it is best to look only at certain parts of it at a single time. While we are not particularly interested in the fixed effects for current purposes, you can inspect these using the following code to check whether there were any large effects of assay repeat or body size on either trait:\n\nsummary(asr_us, coef = TRUE)$coef.fixed\n\n                                       solution  std error       z.ratio\ntrait_speed_sc:body_size_sc        1.040579e-01 0.07972962  1.305135e+00\ntrait_exploration_sc:body_size_sc  7.269022e-02 0.07533421  9.649033e-01\ntrait_speed_sc:assay_rep_sc       -3.521261e-02 0.03960492 -8.890967e-01\ntrait_exploration_sc:assay_rep_sc -2.195541e-02 0.04238056 -5.180538e-01\ntrait_speed_sc                    -1.820461e-16 0.08140684 -2.236251e-15\ntrait_exploration_sc              -2.853753e-16 0.07631479 -3.739449e-15\n\nwa &lt;- wald(asr_us, ssType = \"conditional\", denDF = \"numeric\")\n\nModel fitted using the sigma parameterization.\nASReml 4.1.0 Tue Jan 23 00:54:08 2024\n          LogLik        Sigma2     DF     wall    cpu\n 1      -255.889           1.0    634 00:54:08    0.0\n 2      -255.889           1.0    634 00:54:08    0.0\nCalculating denominator DF\n\nattr(wa$Wald, \"heading\") &lt;- NULL\nwa\n\n$Wald\n\n                   Df denDF  F.inc  F.con Margin      Pr\ntrait               2  77.1 0.0000 0.0000        1.00000\ntrait:assay_rep_sc  2 237.9 0.3955 0.3984      B 0.67184\ntrait:body_size_sc  2  86.6 0.9871 0.9871      B 0.37679\n\n$stratumVariances\nNULL\n\n\nWe can see that there is a separate intercept for both personality traits (no surprise that these are very close to zero, given that we mean-centred and scaled each trait before fitting the model), and an estimate of the effect of assay repeat and body size on both traits. None of these appear to be large effects, so let‚Äôs move on to the more interesting parts ‚Äî the random effects estimates:\n\nsummary(asr_us)$varcomp\n\n                                                 component  std.error   z.ratio\nID:trait!trait_speed_sc:speed_sc                0.37333063 0.08607123  4.337461\nID:trait!trait_exploration_sc:speed_sc          0.08838639 0.06067006  1.456837\nID:trait!trait_exploration_sc:exploration_sc    0.28631012 0.07637247  3.748865\nunits:trait!R                                   1.00000000         NA        NA\nunits:trait!trait_speed_sc:speed_sc             0.62741689 0.05740281 10.930073\nunits:trait!trait_exploration_sc:speed_sc       0.32632113 0.04829175  6.757286\nunits:trait!trait_exploration_sc:exploration_sc 0.71844189 0.06572780 10.930563\n                                                bound %ch\nID:trait!trait_speed_sc:speed_sc                    P   0\nID:trait!trait_exploration_sc:speed_sc              P   0\nID:trait!trait_exploration_sc:exploration_sc        P   0\nunits:trait!R                                       F   0\nunits:trait!trait_speed_sc:speed_sc                 P   0\nunits:trait!trait_exploration_sc:speed_sc           P   0\nunits:trait!trait_exploration_sc:exploration_sc     P   0\n\n\nIn the above summary table, we have the among-individual (co)variances listed first (starting with ID), then the residual (or within-individual) (co)variances (starting with R). You will notice that the variance estimates here are actually close to the lme4 repeatability estimates, because our response variables were scaled to phenotypic standard deviations. We can also find the ‚Äòadjusted repeatability‚Äô (i.e., the repeatability conditional on the fixed effects) for each trait by dividing its among-individual variance estimate by the sum of its among-individual and residual variances. Here, we use the vpredict function to estimate the repeatability and its standard error for each trait, conditional on the effects of assay repeat and body size. For this function, we provide the name of the model object, followed by a name that we want to give the estimate being returned, and a formula for the calculation. Each ‚ÄòV‚Äô term in the formula refers to a variance component, using its position in the model summary shown above.\n\nvpredict(asr_us, rep_speed ~ V1 / (V1 + V5))\n\n           Estimate         SE\nrep_speed 0.3730518 0.06124032\n\nvpredict(asr_us, rep_expl ~ V3 / (V3 + V7))\n\n         Estimate         SE\nrep_expl 0.284956 0.06113539\n\n\nWe can also use this function to calculate the estimate and standard error of the correlation from our model (co)variances. We do this by specifying the formula for the correlation:\n\n(cor_fe &lt;- vpredict(asr_us, cor_expl_speed ~ V2 / (sqrt(V1 * V3))))\n\n                Estimate        SE\ncor_expl_speed 0.2703462 0.1594097\n\n\nIn this case, the estimate is similar (here, slightly lower) than our correlation estimate using BLUPs. However, if we consider confidence intervals as +/- 1.96 SE around the estimate, the lower bound of the confidence interval would actually be -0.0421. With confidence intervals straddling zero, we would conclude that this correlation is likely non-significant. As the use of standard errors in this way is only approximate, we should also test our hypothesis formally using likelihood ratio tests.\n\n8.2.4.1.1 Hypothesis testing\nWe can now test the statistical significance of this correlation directly, by fitting a second model without the among-individual covariance between our two traits, and then using a likelihood ratio test to determine whether the model with the covariance produces a better fit. Here, we use the idh structure for our random effects. This stands for ‚Äòidentity matrix‚Äô (i.e., with 0s on the off-diagonals) with heterogeneous variances (i.e., the variance components for our two response traits are allowed to be different from one another). The rest of the model is identical to the previous version.\n\nasr_idh &lt;- asreml(\n  cbind(speed_sc, exploration_sc) ~ trait +\n    trait:assay_rep_sc + trait:body_size_sc,\n  random = ~ ID:idh(trait),\n  residual = ~ units:us(trait),\n  data = df_dragons,\n  maxiter = 100\n)\n\nModel fitted using the sigma parameterization.\nASReml 4.1.0 Tue Jan 23 00:54:09 2024\n          LogLik        Sigma2     DF     wall    cpu\n 1      -327.051           1.0    634 00:54:09    0.0\n 2      -299.874           1.0    634 00:54:09    0.0\n 3      -273.689           1.0    634 00:54:09    0.0\n 4      -260.838           1.0    634 00:54:09    0.0\n 5      -257.331           1.0    634 00:54:09    0.0\n 6      -257.120           1.0    634 00:54:09    0.0\n 7      -257.118           1.0    634 00:54:09    0.0\n\n\nThe likelihood ratio test is calculated as twice the difference between model log-likelihoods, on a single degree of freedom (the covariance term):\n\n(p_biv &lt;- pchisq(2 * (asr_us$loglik - asr_idh$loglik),\n  df = 1,\n  lower.tail = FALSE\n))\n\n[1] 0.1170385\n\n\nIn sharp contrast to the highly-significant P-value given by a correlation test using BLUPs, here we find no evidence for a correlation between flying speed and exploration. To better understand why BLUPs produce an anticonservative p-value in comparison to multivariate models, we should plot the correlation estimates and their confidence intervals. The confidence intervals are taken directly from the cor.test function for BLUPs, and for ASReml they are calculated as 1.96 times the standard error from the vpredict function.\n\ndf_cor &lt;- data.frame(\n  Method = c(\"ASReml\", \"BLUPs\"),\n  Correlation = c(as.numeric(cor_fe[1]), cor_blups$estimate),\n  low = c(as.numeric(cor_fe[1] - 1.96 * cor_fe[2]), cor_blups$conf.int[1]),\n  high = c(as.numeric(cor_fe[1] + 1.96 * cor_fe[2]), cor_blups$conf.int[2])\n)\nggplot(df_cor, aes(x = Method, y = Correlation)) +\n  geom_point() +\n  geom_linerange(aes(ymin = low, ymax = high)) +\n  ylim(-1, 1) +\n  geom_hline(yintercept = 0, linetype = 2) +\n  theme_classic()\n\n\n\nCorrelation estimates (with CI) using 2 different methods\n\n\n\nHere we can clearly see that the BLUPs method - having failed to carry through the error around the predictions of individual-level estimates - is anticonservative, with small confidence intervals and a correspondingly small P-value (P = 0.00191). Testing the syndrome directly in a bivariate model that retains all the data, by comparison, enables us to capture the true uncertainty about the estimate of the correlation. This is reflected in the larger confidence intervals and, in this case, the non-significant P-value (P = 0.117).\n\n\n8.2.4.1.2 Conclusions\nTo conclude, then: we found that the correlation between flying speed and exploration tends to be positive among female blue dragon. This correlation is not statistically significant, and thus does not provide strong evidence. However, inappropriate analysis of BLUP extracted from univariate models would lead to a different (erroneous) conclusion.\n\n8.2.4.2 Using MCMCglmm\nIn this section I present the code needed to fit the model and explain only the specific aspect of fittign and evaluating the models with MCMCglmm.\nTo be completed. with more details\nFirst, we need to create a ‚Äòprior‚Äô for our model. We recommend reading up on the use of priors (see the course notes of MCMCglmm Hadfield 2010); briefly, we use a parameter-expanded prior here that should be uninformative for our model. One of the model diagnostic steps that should be used later is to check that the model is robust to multiple prior specifications.\n\nprior_1ex &lt;- list(\n  R = list(V = diag(2), nu = 0.002),\n  G = list(G1 = list(\n    V = diag(2) * 0.02, nu = 3,\n    alpha.mu = rep(0, 2),\n    alpha.V = diag(1000, 2, 2)\n  ))\n)\n\n\nmcmc_us &lt;- MCMCglmm(cbind(speed_sc, exploration_sc) ~ trait - 1 +\n  trait:assay_rep_sc +\n  trait:body_size_sc,\nrandom = ~ us(trait):ID,\nrcov = ~ us(trait):units,\nfamily = c(\"gaussian\", \"gaussian\"),\nprior = prior_1ex,\nnitt = 420000,\nburnin = 20000,\nthin = 100,\nverbose = FALSE,\ndata = df_dragons\n)\n\n\nomar &lt;- par()\npar(mar = c(4, 2, 1.5, 2))\nplot(mcmc_us$VCV[, c(1, 2, 4)])\n\n\n\nMCMC trace and Posterior distribution of the (co)variance estimates of model mcmc_us\n\n\nplot(mcmc_us$VCV[, c(5, 6, 8)])\n\n\n\nMCMC trace and Posterior distribution of the (co)variance estimates of model mcmc_us\n\n\npar(omar)\n\n\nsummary(mcmc_us)\n\n\n Iterations = 20001:419901\n Thinning interval  = 100\n Sample size  = 4000 \n\n DIC: 1596.726 \n\n G-structure:  ~us(trait):ID\n\n                                           post.mean l-95% CI u-95% CI eff.samp\ntraitspeed_sc:traitspeed_sc.ID               0.38670   0.2185   0.5691     4000\ntraitexploration_sc:traitspeed_sc.ID         0.08035  -0.0333   0.2091     4000\ntraitspeed_sc:traitexploration_sc.ID         0.08035  -0.0333   0.2091     4000\ntraitexploration_sc:traitexploration_sc.ID   0.29360   0.1537   0.4545     4000\n\n R-structure:  ~us(trait):units\n\n                                              post.mean l-95% CI u-95% CI\ntraitspeed_sc:traitspeed_sc.units                0.6383   0.5249   0.7500\ntraitexploration_sc:traitspeed_sc.units          0.3332   0.2408   0.4318\ntraitspeed_sc:traitexploration_sc.units          0.3332   0.2408   0.4318\ntraitexploration_sc:traitexploration_sc.units    0.7329   0.6054   0.8652\n                                              eff.samp\ntraitspeed_sc:traitspeed_sc.units                 4000\ntraitexploration_sc:traitspeed_sc.units           4000\ntraitspeed_sc:traitexploration_sc.units           4000\ntraitexploration_sc:traitexploration_sc.units     4000\n\n Location effects: cbind(speed_sc, exploration_sc) ~ trait - 1 + trait:assay_rep_sc + trait:body_size_sc \n\n                                 post.mean  l-95% CI  u-95% CI eff.samp pMCMC\ntraitspeed_sc                     0.002011 -0.167262  0.164569     4000 0.996\ntraitexploration_sc               0.001389 -0.147113  0.153418     4000 0.999\ntraitspeed_sc:assay_rep_sc       -0.036231 -0.110201  0.043971     4000 0.360\ntraitexploration_sc:assay_rep_sc -0.022918 -0.103150  0.064172     4000 0.589\ntraitspeed_sc:body_size_sc        0.103544 -0.053667  0.253207     4000 0.199\ntraitexploration_sc:body_size_sc  0.075044 -0.075995  0.221211     5131 0.313\n\n\n\nmcmc_prop_f &lt;- mcmc_us$VCV[, 1] /\n  (mcmc_us$VCV[, 1] + mcmc_us$VCV[, 5])\nplot(mcmc_prop_f)\n\n\n\nPosterior trace and distribution of the repeatability in flying speed\n\n\n\n\nposterior.mode(mcmc_prop_f)\n\n     var1 \n0.3450241 \n\nHPDinterval(mcmc_prop_f)\n\n         lower     upper\nvar1 0.2497688 0.4897519\nattr(,\"Probability\")\n[1] 0.95\n\n\n\nmcmc_prop_e &lt;- mcmc_us$VCV[, 4] /\n  (mcmc_us$VCV[, 4] + mcmc_us$VCV[, 8])\nplot(mcmc_prop_e)\n\n\n\nPosterior trace and distribution of the repeatbility of exploration\n\n\nposterior.mode(mcmc_prop_e)\n\n    var1 \n0.279527 \n\nHPDinterval(mcmc_prop_e)\n\n         lower     upper\nvar1 0.1609295 0.4000869\nattr(,\"Probability\")\n[1] 0.95\n\n\n\nmcmc_cor_fe &lt;- mcmc_us$VCV[, 2] /\n  sqrt(mcmc_us$VCV[, 1] * mcmc_us$VCV[, 4])\nplot(mcmc_cor_fe)\n\n\n\nPosterior trace and distribution of the correlation between flying speed and exploration\n\n\nposterior.mode(mcmc_cor_fe)\n\n     var1 \n0.3100281 \n\nHPDinterval(mcmc_cor_fe)\n\n           lower     upper\nvar1 -0.09380121 0.5304097\nattr(,\"Probability\")\n[1] 0.95\n\n\n\ndf_cor[3, 1] &lt;- \"MCMCglmm\"\ndf_cor[3, -1] &lt;- c(posterior.mode(mcmc_cor_fe), HPDinterval(mcmc_cor_fe))\nrownames(df_cor) &lt;- NULL\n\nggplot(df_cor, aes(x = Method, y = Correlation)) +\n  geom_point() +\n  geom_linerange(aes(ymin = low, ymax = high)) +\n  ylim(-1, 1) +\n  geom_hline(yintercept = 0, linetype = 2) +\n  theme_classic()\n\n\n\nCorrelation estimates (with CI) using 3 different methods\n\n\n\n\n\n\nCorrelation (with 95% intervals) between flying speed and exploration estimated with 3 different methods\n\nMethod\nCorrelation\nlow\nhigh\n\n\n\nASReml\n0.270\n-0.042\n0.583\n\n\nBLUPs\n0.342\n0.132\n0.522\n\n\nMCMCglmm\n0.310\n-0.094\n0.530\n\n\n\n\n\n\n8.2.5 Happy multivariate models\n\n\n\n\nA female blue dragon of the West\n\n\n\n\n\n\n\nBates, D., M. M√§chler, B. Bolker, and S. Walker. 2015. Fitting linear mixed-effects models using lme4. Journal of Statistical Software 67:1‚Äì48.\n\n\nButler, D. 2022. asreml: Fits the linear mixed model.\n\n\nHadfield, J. D. 2010. MCMC methods for multi-response generalized linear mixed models: The MCMCglmm R package. Journal of Statistical Software 33:1‚Äì22.\n\n\nHadfield, J. D., A. J. Wilson, D. Garant, B. C. Sheldon, and L. E. Kruuk. 2010. The Misuse of BLUP in Ecology and Evolution. American Naturalist 175:116‚Äì125.\n\n\nHouslay, T. M., and A. J. Wilson. 2017. Avoiding the misuse of BLUP in behavioural ecology. Behavioral Ecology 28:948‚Äì952.",
    "crumbs": [
      "Statistics",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Multivariate mixed models</span>"
    ]
  },
  {
    "objectID": "02_06-randreg.html",
    "href": "02_06-randreg.html",
    "title": "\n9¬† Random regression and character state approaches\n",
    "section": "",
    "text": "9.1 Lecture\nAmazing beasties and crazy animals\nDream pet dragon",
    "crumbs": [
      "Statistics",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Random regression and character state approaches</span>"
    ]
  },
  {
    "objectID": "02_06-randreg.html#practical",
    "href": "02_06-randreg.html#practical",
    "title": "\n9¬† Random regression and character state approaches\n",
    "section": "\n9.2 Practical",
    "text": "9.2 Practical\nIn this practical, we will revisit our analysis on unicorn aggressivity. Honestly, we can use any other data with repeated measures for this exercise but I just ‚ù§Ô∏è unicorns.\n\n9.2.1 R packages needed\nFirst we load required libraries\n\nlibrary(lme4)\nlibrary(tidyverse)\nlibrary(broom.mixed)\nlibrary(asreml)\nlibrary(MCMCglmm)\nlibrary(bayesplot)\n\n\n9.2.2 Refresher on unicorn aggression\nIn the previous, practical on linear mixed models, we simply explored the differences among individuals in their mean aggression (Intercept), but we assumed that the response to the change in aggression with the opponent size (i.e.¬†plasticity) was the same for all individuals. However, this plastic responses can also vary amon individuals. This is called IxE, or individual by environment interaction. To test if individuals differ in their plasticity we can use a random regression, whcih is simply a mixed-model where we fit both a random intercept and a random slope effect.\nFollowing analysis from the previous pratical, our model of interest using scaled covariate was:\naggression ~ opp_size + body_size_sc + assay_rep_sc + block\n              + (1 | ID)\nWe should start by loading the data and refitting the model using lmer().\n\nunicorns &lt;- read.csv(\"data/unicorns_aggression.csv\")\nunicorns &lt;- unicorns %&gt;%\n  mutate(\n    body_size_sc = scale(body_size),\n    assay_rep_sc = scale(assay_rep, scale = FALSE)\n  )\n\nm_mer &lt;- lmer(\n    aggression ~ opp_size + body_size_sc + assay_rep_sc + block\n      + (1 | ID),\n    data = unicorns\n)\nsummary(m_mer)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: aggression ~ opp_size + body_size_sc + assay_rep_sc + block +  \n    (1 | ID)\n   Data: unicorns\n\nREML criterion at convergence: 1136.5\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-2.85473 -0.62831  0.02545  0.68998  2.74064 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n ID       (Intercept) 0.02538  0.1593  \n Residual             0.58048  0.7619  \nNumber of obs: 480, groups:  ID, 80\n\nFixed effects:\n              Estimate Std. Error        df t value Pr(&gt;|t|)    \n(Intercept)    9.00181    0.03907  78.07315 230.395   &lt;2e-16 ***\nopp_size       1.05141    0.04281 396.99857  24.562   &lt;2e-16 ***\nbody_size_sc   0.03310    0.03896  84.21144   0.850    0.398    \nassay_rep_sc  -0.05783    0.04281 396.99857  -1.351    0.177    \nblock         -0.02166    0.06955 397.00209  -0.311    0.756    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) opp_sz bdy_s_ assy__\nopp_size     0.000                     \nbody_siz_sc  0.000  0.000              \nassay_rp_sc  0.000 -0.100  0.000       \nblock        0.000  0.000  0.002  0.000\n\n\nWe can now plot the predictions for each of our observations and plot for the observed and the fitted data for each individuals. Todo so we will use the augment() function from the üì¶ broom.mixed.\nBelow, we plot the raw data for each individual in one panel, with the fitted slopes in a second panel. Because we have 2 blocks of data, and block is fitted as a fixed effect, for ease of presentation we need to either select only 1 block for representation, take teh avaerage over the block effect or do a more complex graph with the two blocks. Here I have selected only one of the blocks for this plot\n\npred_m_mer &lt;- augment(m_mer) %&gt;%\n  select(ID, block, opp_size, .fitted, aggression) %&gt;%\n  filter(block == -0.5) %&gt;%\n  gather(\n    type, aggression,\n    `.fitted`:aggression\n  )\nggplot(pred_m_mer, aes(x = opp_size, y = aggression, group = ID)) +\n  geom_line(alpha = 0.3) +\n  theme_classic() +\n  facet_grid(. ~ type)\n\n\n\nPredicted (from m_mer) and observed value of aggression as a function of opponent size in unicorns\n\n\n\nThis illustrates the importance of using model predictions to see whether the model actually fits the individual-level data well or not ‚Äî while the diagnostic plots looked fine, and the model captures mean plasticity, here we can see that the model really doesn‚Äôt fit the actual data very well at all.\n\n\n9.2.3 Random regression\n\n9.2.3.1 with lme4\n\n\nrr_mer &lt;- lmer(\n  aggression ~ opp_size + body_size_sc + assay_rep_sc + block\n  + (1 + opp_size | ID),\n  data = unicorns\n)\n\n\npred_rr_mer &lt;- augment(rr_mer) %&gt;%\n  select(ID, block, opp_size, .fitted, aggression) %&gt;%\n  filter(block == -0.5) %&gt;%\n  gather(type,aggression, `.fitted`:aggression)\nggplot(pred_rr_mer, aes(x = opp_size, y = aggression, group = ID)) +\n  geom_line(alpha = 0.3) +\n  theme_classic() +\n  facet_grid(. ~ type)\n\n\n\n\n\n\n\nWe can test the improvement of the model fit using the overloaded anova function in R to perform a likelihood ratio test (LRT):\n\nanova(rr_mer, m_mer, refit = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnpar\nAIC\nBIC\nlogLik\ndeviance\nChisq\nDf\nPr(&gt;Chisq)\n\n\n\nm_mer\n7\n1150.477\n1179.693\n-568.2383\n1136.477\nNA\nNA\nNA\n\n\nrr_mer\n9\n1092.356\n1129.920\n-537.1780\n1074.356\n62.1206\n2\n0\n\n\n\n\n\nWe can see here that the LRT uses a chi-square test with 2 degrees of freedom, and indicates that the random slopes model shows a statistically significant improvement in model fit. The 2df are because there are two additional (co)variance terms estimated in the random regression model: a variance term for individual slopes, and the covariance (or correlation) between the slopes and intercepts. Let‚Äôs look at those values, and also the fixed effects parameters, via the model summary:\n\nsummary(rr_mer)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: aggression ~ opp_size + body_size_sc + assay_rep_sc + block +  \n    (1 + opp_size | ID)\n   Data: unicorns\n\nREML criterion at convergence: 1074.4\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-3.04932 -0.59780 -0.02002  0.59574  2.68010 \n\nRandom effects:\n Groups   Name        Variance Std.Dev. Corr\n ID       (Intercept) 0.05043  0.2246       \n          opp_size    0.19167  0.4378   0.96\n Residual             0.42816  0.6543       \nNumber of obs: 480, groups:  ID, 80\n\nFixed effects:\n              Estimate Std. Error        df t value Pr(&gt;|t|)    \n(Intercept)    9.00181    0.03902  78.44088 230.707   &lt;2e-16 ***\nopp_size       1.05033    0.06123  79.50694  17.153   &lt;2e-16 ***\nbody_size_sc   0.02725    0.03377  84.34959   0.807    0.422    \nassay_rep_sc  -0.04702    0.03945 387.69415  -1.192    0.234    \nblock         -0.02169    0.05973 318.19553  -0.363    0.717    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) opp_sz bdy_s_ assy__\nopp_size     0.495                     \nbody_siz_sc  0.000  0.000              \nassay_rp_sc  0.000 -0.064 -0.006       \nblock        0.000  0.000  0.002  0.000\n\n\n\n9.2.3.2 with asreml\n\n\nunicorns &lt;- unicorns %&gt;%\n  mutate( ID = as.factor(ID))\nrr_asr &lt;- asreml(\n  aggression ~ opp_size + body_size_sc + assay_rep_sc + block,\n  random = ~str(~ ID + ID:opp_size, ~us(2):id(ID)),\n  residual = ~ units,\n  data = unicorns,\n  maxiter = 200\n)\n\nModel fitted using the gamma parameterization.\nASReml 4.1.0 Mon Jan 22 00:18:51 2024\n          LogLik        Sigma2     DF     wall    cpu\n 1      -109.426      0.463232    475 00:18:51    0.0\n 2      -105.050      0.454593    475 00:18:51    0.0\n 3      -101.814      0.443662    475 00:18:51    0.0\n 4      -100.814      0.433873    475 00:18:51    0.0\n 5      -100.683      0.428596    475 00:18:51    0.0\n 6      -100.682      0.428170    475 00:18:51    0.0\n\n\n\nplot(rr_asr)\n\n\n\n\n\n\n\n\nsummary(rr_asr, coef = TRUE)$coef.fixed\n\n                solution  std error     z.ratio\nblock        -0.02168725 0.05973354  -0.3630665\nassay_rep_sc -0.04702032 0.03944594  -1.1920191\nbody_size_sc  0.02725092 0.03377443   0.8068506\nopp_size      1.05032703 0.06123110  17.1534907\n(Intercept)   9.00181250 0.03901766 230.7112239\n\nwa &lt;- wald(rr_asr, ssType = \"conditional\", denDF = \"numeric\")\n\nModel fitted using the gamma parameterization.\nASReml 4.1.0 Tue Jan 23 00:58:06 2024\n          LogLik        Sigma2     DF     wall    cpu\n 1      -100.682      0.428168    475 00:58:06    0.0\n 2      -100.682      0.428168    475 00:58:06    0.0\nCalculating denominator DF\n\nattr(wa$Wald, \"heading\") &lt;- NULL\nwa\n\n$Wald\n\n             Df denDF F.inc F.con Margin      Pr\n(Intercept)   1  78.3 65490 53230        0.00000\nopp_size      1  79.5   293   294      A 0.00000\nbody_size_sc  1  84.3     1     1      A 0.42202\nassay_rep_sc  1 387.6     1     1      A 0.23398\nblock         1 318.1     0     0      A 0.71680\n\n$stratumVariances\n                                df  Variance ID+ID:opp_size!us(2)_1:1\nID+ID:opp_size!us(2)_1:1  78.00483 0.4790737                 5.216311\nID+ID:opp_size!us(2)_2:1   0.00000 0.0000000                 0.000000\nID+ID:opp_size!us(2)_2:2  78.94046 1.1937287                 0.000000\nunits!R                  318.05470 0.4281680                 0.000000\n                         ID+ID:opp_size!us(2)_2:1 ID+ID:opp_size!us(2)_2:2\nID+ID:opp_size!us(2)_1:1                -3.301137                0.5221955\nID+ID:opp_size!us(2)_2:1                 0.000000                0.0000000\nID+ID:opp_size!us(2)_2:2                 0.000000                3.9943993\nunits!R                                  0.000000                0.0000000\n                         units!R\nID+ID:opp_size!us(2)_1:1       1\nID+ID:opp_size!us(2)_2:1       1\nID+ID:opp_size!us(2)_2:2       1\nunits!R                        1\n\n\n\nsummary(rr_asr)$varcomp\n\n                          component  std.error   z.ratio bound %ch\nID+ID:opp_size!us(2)_1:1 0.05042932 0.02027564  2.487187     P   0\nID+ID:opp_size!us(2)_2:1 0.09458336 0.02400745  3.939751     P   0\nID+ID:opp_size!us(2)_2:2 0.19165924 0.04832059  3.966409     P   0\nunits!R                  0.42816954 0.03395320 12.610582     P   0\n\n\n\nrio_asr &lt;- asreml(\n  aggression ~ opp_size + body_size_sc + assay_rep_sc + block,\n  random = ~ ID,\n  residual = ~units,\n  data = unicorns,\n  maxiter = 200\n)\n\nModel fitted using the gamma parameterization.\nASReml 4.1.0 Tue Jan 23 00:58:07 2024\n          LogLik        Sigma2     DF     wall    cpu\n 1      -132.611      0.560353    475 00:58:07    0.0\n 2      -132.106      0.567043    475 00:58:07    0.0\n 3      -131.796      0.575157    475 00:58:07    0.0\n 4      -131.743      0.580762    475 00:58:07    0.0\n 5      -131.742      0.580480    475 00:58:07    0.0\n\n\n\npchisq(2 * (rr_asr$loglik - rio_asr$loglik), 2,\n  lower.tail = FALSE\n)\n\n[1] 3.241026e-14\n\n\n\nvpredict(rr_asr, cor_is ~ V2 / (sqrt(V1) * sqrt(V3)))\n\n        Estimate        SE\ncor_is 0.9620736 0.1773965\n\n\n\npred_rr_asr &lt;- as.data.frame(predict(rr_asr,\n  classify = \"opp_size:ID\",\n  levels = list(\n    \"opp_size\" =\n      c(opp_size = -1:1)\n  )\n)$pvals)\n\nModel fitted using the gamma parameterization.\nASReml 4.1.0 Tue Jan 23 00:58:07 2024\n          LogLik        Sigma2     DF     wall    cpu\n 1      -100.682      0.428168    475 00:58:08    0.1\n 2      -100.682      0.428168    475 00:58:08    0.0\n 3      -100.682      0.428168    475 00:58:08    0.0\n\np_rr &lt;- ggplot(pred_rr_asr, aes(x = opp_size,\ny = predicted.value,\ngroup = ID)) +\ngeom_line(alpha = 0.2) +\nscale_x_continuous(breaks = c(-1, 0, 1)) +\n  labs(\n    x = \"Opponent size (SDU)\",\n    y = \"Aggression\"\n  ) +\n  theme_classic()\np_rr\n\n\n\n\n\n\n\n\n9.2.3.3 with MCMCglmm\n\n\nprior_RR &lt;- list(\n  R = list(V = 1, nu = 0.002),\n  G = list(\n    G1 = list(V = diag(2)*0.02, nu = 3,\nalpha.mu = rep(0, 2),\nalpha.V= diag(1000, 2, 2))))\nrr_mcmc &lt;- MCMCglmm(\n  aggression ~ opp_size + assay_rep_sc + body_size_sc + block,\n  random = ~ us(1 + opp_size):ID,\n  rcov = ~ units,\nfamily = \"gaussian\",\nprior = prior_RR,\nnitt=750000,\nburnin=50000,\nthin=350,\nverbose = FALSE,\ndata = unicorns,\npr = TRUE,\nsaveX = TRUE, saveZ = TRUE)\n\n\nomar &lt;- par()\npar(mar = c(4, 2, 1.5, 2))\nplot(rr_mcmc$VCV)\n\n\n\n\n\n\n\n\n\n\n\n\npar(omar)\n\nWarning in par(omar): graphical parameter \"cin\" cannot be set\n\n\nWarning in par(omar): graphical parameter \"cra\" cannot be set\n\n\nWarning in par(omar): graphical parameter \"csi\" cannot be set\n\n\nWarning in par(omar): graphical parameter \"cxy\" cannot be set\n\n\nWarning in par(omar): graphical parameter \"din\" cannot be set\n\n\nWarning in par(omar): graphical parameter \"page\" cannot be set\n\n\n\nposterior.mode(rr_mcmc$VCV[, \"opp_size:opp_size.ID\"]) # mean\n\n     var1 \n0.1928353 \n\nHPDinterval(rr_mcmc$VCV[, \"opp_size:opp_size.ID\"])\n\n         lower     upper\nvar1 0.1145301 0.3053043\nattr(,\"Probability\")\n[1] 0.95\n\n\n\nrr_cor_mcmc &lt;- rr_mcmc$VCV[, \"opp_size:(Intercept).ID\"] /\n  (sqrt(rr_mcmc$VCV[, \"(Intercept):(Intercept).ID\"]) *\n    sqrt(rr_mcmc$VCV[, \"opp_size:opp_size.ID\"]))\nposterior.mode(rr_cor_mcmc)\n\n     var1 \n0.8099658 \n\nHPDinterval(rr_cor_mcmc)\n\n         lower     upper\nvar1 0.5248906 0.9830044\nattr(,\"Probability\")\n[1] 0.95\n\n\n\ndf_rand &lt;- cbind(unicorns,\n  rr_fit = predict(rr_mcmc, marginal = NULL)\n) %&gt;%\n  select(ID, opp_size, rr_fit, aggression) %&gt;%\n  group_by(ID, opp_size) %&gt;%\n  summarise(\n    rr_fit = mean(rr_fit),\n    aggression = mean(aggression)\n  ) %&gt;%\n  gather(\n    Type, Value,\n    rr_fit:aggression\n  )\n\n`summarise()` has grouped output by 'ID'. You can override using the `.groups`\nargument.\n\n# Plot separate panels for individual lines of each type\nggplot(df_rand, aes(x = opp_size, y = Value, group = ID)) +\n  geom_line(alpha = 0.3) +\n  scale_x_continuous(breaks = c(-1, 0, 1)) +\n  theme_classic() +\n  facet_grid(. ~ Type)\n\n\n\n\n\n\n\n\n\n\nVariance estimated from random regression models using 3 different softwares\n\nMethod\nv_int\ncov\nv_sl\nv_r\n\n\n\nlmer\n0.0504347\n0.0945863\n0.1916653\n0.4281625\n\n\nasreml\n0.0504293\n0.0945834\n0.1916592\n0.4281695\n\n\nMCMCglmm\n0.0503277\n0.0729472\n0.1928353\n0.4258950\n\n\n\n\n\n\n9.2.4 Character-State approach\nNeed to pivot to a wider format\n\nunicorns_cs &lt;- unicorns %&gt;%\n  select(ID, body_size, assay_rep, block, aggression, opp_size) %&gt;%\n  mutate(\n    opp_size = recode(as.character(opp_size), \"-1\" = \"s\", \"0\" = \"m\", \"1\" = \"l\")\n  ) %&gt;%\n  dplyr::rename(agg = aggression) %&gt;%\n  pivot_wider(names_from = opp_size, values_from = c(agg, assay_rep)) %&gt;%\n  mutate(\n    body_size_sc = scale(body_size),\n    opp_order = as.factor(paste(assay_rep_s, assay_rep_m, assay_rep_l, sep = \"_\"))\n  )\nstr(unicorns_cs)\n\ntibble [160 √ó 11] (S3: tbl_df/tbl/data.frame)\n $ ID          : Factor w/ 80 levels \"ID_1\",\"ID_10\",..: 1 1 2 2 3 3 4 4 5 5 ...\n $ body_size   : num [1:160] 206 207 283 288 229 ...\n $ block       : num [1:160] -0.5 0.5 -0.5 0.5 -0.5 0.5 -0.5 0.5 -0.5 0.5 ...\n $ agg_s       : num [1:160] 7.02 8.44 7.73 8.08 8.06 8.16 8.16 8.51 7.59 6.67 ...\n $ agg_l       : num [1:160] 10.67 10.51 10.81 10.67 9.77 ...\n $ agg_m       : num [1:160] 10.22 8.95 9.43 9.46 7.63 ...\n $ assay_rep_s : int [1:160] 1 3 2 2 1 1 3 3 1 1 ...\n $ assay_rep_l : int [1:160] 2 2 1 1 2 2 2 1 2 2 ...\n $ assay_rep_m : int [1:160] 3 1 3 3 3 3 1 2 3 3 ...\n $ body_size_sc: num [1:160, 1] -1.504 -1.456 0.988 1.143 -0.76 ...\n  ..- attr(*, \"scaled:center\")= num 253\n  ..- attr(*, \"scaled:scale\")= num 31.1\n $ opp_order   : Factor w/ 6 levels \"1_2_3\",\"1_3_2\",..: 2 5 4 4 2 2 5 6 2 2 ...\n\nhead(unicorns_cs)\n\n# A tibble: 6 √ó 11\n  ID    body_size block agg_s agg_l agg_m assay_rep_s assay_rep_l assay_rep_m\n  &lt;fct&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;       &lt;int&gt;       &lt;int&gt;       &lt;int&gt;\n1 ID_1       206.  -0.5  7.02 10.7  10.2            1           2           3\n2 ID_1       207.   0.5  8.44 10.5   8.95           3           2           1\n3 ID_10      283.  -0.5  7.73 10.8   9.43           2           1           3\n4 ID_10      288    0.5  8.08 10.7   9.46           2           1           3\n5 ID_11      229.  -0.5  8.06  9.77  7.63           1           2           3\n6 ID_11      236.   0.5  8.16 10.8   8.23           1           2           3\n# ‚Ñπ 2 more variables: body_size_sc &lt;dbl[,1]&gt;, opp_order &lt;fct&gt;\n\n\n\ncs_asr &lt;- asreml(\n  cbind(agg_s, agg_m, agg_l) ~ trait + trait:body_size_sc +\n    trait:block +\n    trait:opp_order,\n  random =~ ID:us(trait),\n  residual =~ units:us(trait),\n  data = unicorns_cs,\n  maxiter = 200\n)\n\nModel fitted using the sigma parameterization.\nASReml 4.1.0 Tue Jan 23 01:00:44 2024\n          LogLik        Sigma2     DF     wall    cpu\n 1      -150.172           1.0    456 01:00:44    0.0\n 2      -129.658           1.0    456 01:00:44    0.0\n 3      -110.454           1.0    456 01:00:44    0.0\n 4      -101.879           1.0    456 01:00:44    0.0\n 5      -100.092           1.0    456 01:00:44    0.0\n 6      -100.054           1.0    456 01:00:44    0.0\n 7      -100.054           1.0    456 01:00:44    0.0\n\nplot(residuals(cs_asr) ~ fitted(cs_asr))\n\n\n\n\n\n\nqqnorm(residuals(cs_asr))\nqqline(residuals(cs_asr))\n\n\n\n\n\n\nhist(residuals(cs_asr))\n\n\n\n\n\n\n\n\nsummary(cs_asr, all = T)$coef.fixed\n\nNULL\n\nwa &lt;- wald(cs_asr, ssType = \"conditional\", denDF = \"numeric\")\n\nModel fitted using the sigma parameterization.\nASReml 4.1.0 Tue Jan 23 01:00:45 2024\n          LogLik        Sigma2     DF     wall    cpu\n 1      -100.054           1.0    456 01:00:45    0.0\n 2      -100.054           1.0    456 01:00:45    0.0\nCalculating denominator DF\n\nattr(wa$Wald, \"heading\") &lt;- NULL\nwa\n\n$Wald\n\n                   Df denDF   F.inc   F.con Margin      Pr\ntrait               3  73.2 21080.0 21080.0        0.00000\ntrait:body_size_sc  3  86.6     0.4     0.5      B 0.68324\ntrait:block         3  75.2     0.6     0.3      B 0.82418\ntrait:opp_order    15 240.5     1.3     1.3      B 0.23282\n\n$stratumVariances\nNULL\n\n\n\nsummary(cs_asr)$varcomp[, c(\"component\", \"std.error\")]\n\n                                 component  std.error\nID:trait!trait_agg_s:agg_s     0.192959991 0.06321872\nID:trait!trait_agg_m:agg_s    -0.168519644 0.05085583\nID:trait!trait_agg_m:agg_m     0.245594370 0.07096325\nID:trait!trait_agg_l:agg_s    -0.151990204 0.05660748\nID:trait!trait_agg_l:agg_m     0.158418588 0.06374995\nID:trait!trait_agg_l:agg_l     0.312548090 0.09125168\nunits:trait!R                  1.000000000         NA\nunits:trait!trait_agg_s:agg_s  0.318089965 0.05198135\nunits:trait!trait_agg_m:agg_s  0.010362390 0.03695483\nunits:trait!trait_agg_m:agg_m  0.322379911 0.05248291\nunits:trait!trait_agg_l:agg_s -0.009311656 0.04168455\nunits:trait!trait_agg_l:agg_m  0.159240476 0.04569305\nunits:trait!trait_agg_l:agg_l  0.405942147 0.06679700\n\n\n\ncs_idh_asr &lt;- asreml(\n  cbind(agg_s, agg_m, agg_l) ~ trait + trait:body_size_sc +\n    trait:block +\n    trait:opp_order,\n  random = ~ ID:idh(trait),\n  residual = ~ units:us(trait),\n  data = unicorns_cs,\n  maxiter = 200\n)\n\nModel fitted using the sigma parameterization.\nASReml 4.1.0 Tue Jan 23 01:00:45 2024\n          LogLik        Sigma2     DF     wall    cpu\n 1      -147.068           1.0    456 01:00:45    0.0\n 2      -131.268           1.0    456 01:00:45    0.0\n 3      -116.908           1.0    456 01:00:45    0.0\n 4      -110.996           1.0    456 01:00:45    0.0\n 5      -109.905           1.0    456 01:00:45    0.0\n 6      -109.866           1.0    456 01:00:45    0.0\n 7      -109.863           1.0    456 01:00:45    0.0\n\n\n\npchisq(2 * (cs_asr$loglik - cs_idh_asr$loglik), 3,\n  lower.tail = FALSE\n)\n\n[1] 0.0002038324\n\n\n\nvpredict(cs_asr, cor_S_M ~ V2 / (sqrt(V1) * sqrt(V3)))\n\n          Estimate        SE\ncor_S_M -0.7741189 0.1869789\n\nvpredict(cs_asr, cor_M_L ~ V5 / (sqrt(V3) * sqrt(V6)))\n\n         Estimate        SE\ncor_M_L 0.5717926 0.1469504\n\nvpredict(cs_asr, cor_S_L ~ V4 / (sqrt(V1) * sqrt(V6)))\n\n          Estimate        SE\ncor_S_L -0.6189044 0.1912133\n\n\n\nvpredict(cs_asr, prop_S ~ V1 / (V1 + V8))\n\n        Estimate         SE\nprop_S 0.3775756 0.09950306\n\nvpredict(cs_asr, prop_M ~ V3 / (V3 + V10))\n\n       Estimate        SE\nprop_M 0.432404 0.0934477\n\nvpredict(cs_asr, prop_L ~ V6 / (V6 + V13))\n\n        Estimate         SE\nprop_L 0.4350067 0.09498512\n\n\n\ninit_CS_cor1_tri &lt;- c(\n  0.999,\n  0.999, 0.999,\n  1, 1, 1\n)\nnames(init_CS_cor1_tri) &lt;- c(\n  \"F\",\n  \"F\", \"F\",\n  \"U\", \"U\", \"U\"\n)\ncs_asr_cor1_tri &lt;- asreml(\n  cbind(agg_s, agg_m, agg_l) ~ trait + trait:body_size_sc +\n    trait:block +\n    trait:opp_order,\n  random = ~ ID:corgh(trait, init = init_CS_cor1_tri),\nresidual = ~ units:us(trait),\ndata = unicorns_cs,\nmaxiter = 500\n)\n\nModel fitted using the sigma parameterization.\nASReml 4.1.0 Tue Jan 23 01:00:45 2024\n          LogLik        Sigma2     DF     wall    cpu\n 1      -228.016           1.0    456 01:00:45    0.0 (3 restrained)\n 2      -150.014           1.0    456 01:00:45    0.0\n 3      -129.580           1.0    456 01:00:45    0.0\n 4      -119.992           1.0    456 01:00:45    0.0 (1 restrained)\n 5      -116.907           1.0    456 01:00:45    0.0 (1 restrained)\n 6      -115.772           1.0    456 01:00:45    0.0\n 7      -115.647           1.0    456 01:00:45    0.0\n 8      -115.588           1.0    456 01:00:45    0.0\n 9      -115.533           1.0    456 01:00:45    0.0\n10      -115.479           1.0    456 01:00:45    0.0\n11      -115.427           1.0    456 01:00:45    0.0\n12      -115.378           1.0    456 01:00:45    0.0\n13      -115.331           1.0    456 01:00:45    0.0\n14      -115.289           1.0    456 01:00:45    0.0\n15      -115.251           1.0    456 01:00:45    0.0\n16      -115.217           1.0    456 01:00:45    0.0\n17      -115.188           1.0    456 01:00:45    0.0\n18      -115.162           1.0    456 01:00:45    0.0\n19      -115.141           1.0    456 01:00:45    0.0\n20      -115.122           1.0    456 01:00:45    0.0\n21      -115.107           1.0    456 01:00:45    0.0\n22      -115.093           1.0    456 01:00:45    0.0\n23      -115.082           1.0    456 01:00:45    0.0\n24      -115.073           1.0    456 01:00:45    0.0 (1 restrained)\n25      -115.064           1.0    456 01:00:45    0.0\n26      -115.064           1.0    456 01:00:46    0.0\n\npchisq(2 * (cs_asr$loglik - cs_asr_cor1_tri$loglik),\n  3,\n  lower.tail = FALSE\n)\n\n[1] 1.367792e-06\n\n\n\ndf_CS_pred &lt;- as.data.frame(predict(cs_asr,\n  classify = \"trait:ID\"\n)$pvals)\n\nModel fitted using the sigma parameterization.\nASReml 4.1.0 Tue Jan 23 01:00:46 2024\n          LogLik        Sigma2     DF     wall    cpu\n 1      -100.054           1.0    456 01:00:46    0.1\n 2      -100.054           1.0    456 01:00:46    0.0\n 3      -100.054           1.0    456 01:00:46    0.0\n\n# Add numeric variable for easier plotting\n# of opponent size\ndf_CS_pred &lt;- df_CS_pred %&gt;%\n  mutate(sizeNum = ifelse(trait == \"agg_s\", -1,\n    ifelse(trait == \"agg_m\", 0, 1)\n  ))\np_cs &lt;- ggplot(df_CS_pred, aes(\n  x = sizeNum,\n  y = predicted.value,\n  group = ID\n)) +\n  geom_line(alpha = 0.2) +\n  scale_x_continuous(breaks = c(-1, 0, 1)) +\n  labs(\n    x = \"Opponent size (SDU)\",\n    y = \"Aggression\"\n  ) +\n  theme_classic()\np_cs\n\n\n\n\n\n\n\n\nunicorns &lt;- arrange(unicorns, opp_size, by_group = ID)\np_obs &lt;- ggplot(unicorns[unicorns$block==-0.5,], aes(x = opp_size, y = aggression, group = ID)) +\n  geom_line(alpha = 0.3) +\n  scale_x_continuous(breaks = c(-1, 0, 1)) +\n  labs(\n    x = \"Opponent size (SDU)\",\n    y = \"Aggression\"\n  ) +\n  ggtitle(\"Observed\") +\n  ylim(5.9, 12) +\n  theme_classic()\n\np_rr &lt;- p_rr + ggtitle(\"Random regression\") + ylim(5.9, 12)\np_cs &lt;- p_cs + ggtitle(\"Character-State\") + ylim(5.9, 12)\np_obs + p_rr + p_cs\n\nWarning: Removed 2 rows containing missing values (`geom_line()`).\n\n\n\n\n\n\n\n\n\n9.2.5 From random regression to character-state\n\nvar_mat_asr &lt;- function(model, var_names, pos){\n  size &lt;- length(var_names)\n  v_out &lt;- matrix(NA, ncol = size, nrow = size)\n  rownames(v_out) &lt;- var_names\n  colnames(v_out) &lt;- var_names\n  v_out[upper.tri(v_out, diag = TRUE)] &lt;- summary(model)$varcomp[pos, 1]\n  v_out &lt;- forceSymmetric(v_out, uplo = \"U\")\n  as.matrix(v_out)\n}\nv_id_rr &lt;- var_mat_asr(rr_asr, c(\"v_int\", \"v_sl\"), 1:3)\nknitr::kable(v_id_rr, digits = 3)\n\n\n\n\nv_int\nv_sl\n\n\n\nv_int\n0.050\n0.095\n\n\nv_sl\n0.095\n0.192\n\n\n\n\n\n\nv_id_cs &lt;- var_mat_asr(cs_asr, c(\"v_s\", \"v_m\", \"v_l\"), 1:6)\nknitr::kable(v_id_cs, digits = 3)\n\n\n\n\nv_s\nv_m\nv_l\n\n\n\nv_s\n0.193\n-0.169\n-0.152\n\n\nv_m\n-0.169\n0.246\n0.158\n\n\nv_l\n-0.152\n0.158\n0.313\n\n\n\n\n\nWe also need to make a second matrix, let‚Äôs call it Q (no particular reason, pick something else if you want). This is going to contain the values needed to turn an individual‚Äôs intercept (mean) and slope (plasticity) deviations into estimates of environment-specific individual merit in a character state model.\nWhat do we mean by this? Well if an individual i has an intercept deviation of IDint(i) and a slope deviation of IDslp(i) for a given value of the environment opp_size we might be interested in:\nIDi = (1 x IDint(i)) + (opp_size x IDslp(i))\nWe want to look at character states representing the three observed values of opp_size here so\n\nQ &lt;- as.matrix(cbind(c(1, 1, 1),\n                    c(-1, 0, 1)))\n\nThen we can generate our among-individual covariance matrix environment specific aggresiveness, which we can call ID_cs_rr by matrix multiplication:\n\nID_cs_rr&lt;- Q %*% v_id_rr %*%t(Q)    #where t(Q) is the transpose of Q\n                               #and %*% is matrix multiplication\n\nID_cs_rr  #rows and columns correspond to aggressiveness at opp_size=-1,0,1 in that order\n\n            [,1]        [,2]       [,3]\n[1,]  0.05292184 -0.04415404 -0.1412299\n[2,] -0.04415404  0.05042932  0.1450127\n[3,] -0.14122993  0.14501267  0.4312553\n\ncov2cor(ID_cs_rr)   #Converting to a correlation scale\n\n           [,1]       [,2]       [,3]\n[1,]  1.0000000 -0.8546956 -0.9348503\n[2,] -0.8546956  1.0000000  0.9833253\n[3,] -0.9348503  0.9833253  1.0000000\n\ncov2cor(v_id_cs)\n\n           v_s        v_m        v_l\nv_s  1.0000000 -0.7741189 -0.6189044\nv_m -0.7741189  1.0000000  0.5717926\nv_l -0.6189044  0.5717926  1.0000000\n\n\n\n9.2.6 Conclusions\n\n9.2.7 Happy multivariate models\n\n\n\n\nA female blue dragon of the West",
    "crumbs": [
      "Statistics",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Random regression and character state approaches</span>"
    ]
  },
  {
    "objectID": "02_07-beyond_p.html",
    "href": "02_07-beyond_p.html",
    "title": "\n10¬† Beyond P < 0.05\n",
    "section": "",
    "text": "cite a bunch a must read paper on the subject and maybe summarize the big point of Do and Don‚Äôt\n\nlibrary(ggplot2)\n\n\nalpha &lt;- 0.05\nbeta &lt;- 0.2 \n\np_h1_true &lt;- seq(0, 1, length = 100)\np_fp &lt;- alpha * (1 - p_h1_true) /\n  (alpha * (1 - p_h1_true) + (1 - beta) * p_h1_true)\np_fn &lt;- beta * p_h1_true /\n  (beta * p_h1_true + (1 - alpha) * (1 - p_h1_true))\n\ndat &lt;- rbind(\n  data.frame(p_h1 = p_h1_true, prob = p_fp, result = \"positive\" ),\n  data.frame(p_h1 = p_h1_true, prob = p_fn, result = \"negative\")\n)\nggplot(dat, aes(x = p_h1, y = prob, colour = result)) +\n  geom_line() +\n  geom_vline(xintercept = 0.5, linetype = 2) +\n  xlab(\"Probability alternative hypothesis is true\") + \n  ylab(\"Probabilitity of false results\") +\n  xlim(0, 1) +\n  theme_classic()",
    "crumbs": [
      "Statistics",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Beyond *P < 0.05*</span>"
    ]
  },
  {
    "objectID": "99-references.html",
    "href": "99-references.html",
    "title": "References",
    "section": "",
    "text": "R packages\nThis book was produced using all the following R packages\nPackage\nVersion\nCitation\n\n\n\nasreml\n4.1.0.176\nButler (2022)\n\n\nbase\n4.3.2\nR Core Team (2023)\n\n\nbayesplot\n1.10.0\n\nGabry et al. (2019); Gabry and Mahr (2022)\n\n\n\nbookdown\n0.37\n\nXie (2016); Xie (2023a)\n\n\n\nbrms\n2.20.4\n\nB√ºrkner (2017); B√ºrkner (2018); B√ºrkner (2021)\n\n\n\nbroom.mixed\n0.2.9.4\nBolker and Robinson (2022)\n\n\nDHARMa\n0.4.6\nHartig (2022)\n\n\nemo\n0.0.0.9000\nWickham et al. (2023b)\n\n\nfactoextra\n1.0.7\nKassambara and Mundt (2020)\n\n\nFactoMineR\n2.9\nL√™ et al. (2008)\n\n\nknitr\n1.45\n\nXie (2014); Xie (2015); Xie (2023b)\n\n\n\nlattice\n0.22.5\n(lattice?)\n\n\nlme4\n1.1.35.1\nBates et al. (2015)\n\n\nlmerTest\n3.1.3\nKuznetsova et al. (2017)\n\n\nMASS\n7.3.60\n(MASS?)\n\n\nMCMCglmm\n2.35\nHadfield (2010)\n\n\nmvtnorm\n1.2.4\nGenz and Bretz (2009)\n\n\nnadiv\n2.17.2\nWolak (2012)\n\n\npalmerpenguins\n0.1.1\nHorst et al. (2020)\n\n\npatchwork\n1.2.0\nPedersen (2024)\n\n\nperformance\n0.10.8\nL√ºdecke et al. (2021)\n\n\nrmarkdown\n2.25\n\nXie et al. (2018); Xie et al. (2020); Allaire et al. (2023b)\n\n\n\nrptR\n0.9.22\nStoffel et al. (2017)\n\n\ntidybayes\n3.0.6\nKay (2023a)\n\n\ntidyverse\n2.0.0\nWickham et al. (2019)\n\n\n\n\n\n\n\n\n\n\n\n\nPackage\nVersion\nCitation\n\n\n\nabind\n1.4.5\nPlate and Heiberger (2016)\n\n\nape\n5.7.1\nParadis and Schliep (2019)\n\n\narrayhelpers\n1.1.0\nBeleites (2020)\n\n\naskpass\n1.2.0\nOoms (2023a)\n\n\nbackports\n1.4.1\nLang and R Core Team (2021)\n\n\nbase64enc\n0.1.3\nUrbanek (2015)\n\n\nbayestestR\n0.13.1\nMakowski et al. (2019)\n\n\nBH\n1.84.0.0\nEddelbuettel et al. (2024a)\n\n\nbit\n4.0.5\nOehlschl√§gel and Ripley (2022)\n\n\nbit64\n4.0.5\nOehlschl√§gel and Silvestri (2020)\n\n\nblob\n1.2.4\nWickham (2023a)\n\n\nbridgesampling\n1.1.2\nGronau et al. (2020)\n\n\nbrio\n1.1.4\nHester and Cs√°rdi (2023)\n\n\nBrobdingnag\n1.2.9\nHankin (2007)\n\n\nbslib\n0.6.1\nSievert et al. (2023)\n\n\ncachem\n1.0.8\nChang (2023a)\n\n\ncallr\n3.7.3\nCs√°rdi and Chang (2022)\n\n\ncar\n3.1.2\nFox and Weisberg (2019)\n\n\ncarData\n3.0.5\nFox et al. (2022)\n\n\ncellranger\n1.1.0\nBryan (2016)\n\n\ncheckmate\n2.3.1\nLang (2017)\n\n\nclipr\n0.8.0\nLincoln (2022)\n\n\ncoda\n0.19.4\nPlummer et al. (2006)\n\n\ncolorspace\n2.1.0\n\nZeileis et al. (2009); Stauffer et al. (2009); Zeileis et al. (2020)\n\n\n\ncolourpicker\n1.3.0\nAttali (2023)\n\n\ncommonmark\n1.9.0\nOoms (2023b)\n\n\ncorpcor\n1.6.10\nSchafer et al. (2021)\n\n\ncorrplot\n0.92\nWei and Simko (2021)\n\n\ncowplot\n1.1.2\nWilke (2023a)\n\n\ncpp11\n0.4.7\nVaughan et al. (2023)\n\n\ncrayon\n1.5.2\nCs√°rdi (2022)\n\n\ncrosstalk\n1.2.1\nCheng and Sievert (2023)\n\n\ncubature\n2.1.0\nNarasimhan et al. (2023)\n\n\ncurl\n5.2.0\nOoms (2023c)\n\n\ndata.table\n1.14.10\nBarrett et al. (2023)\n\n\ndatawizard\n0.9.1\nPatil et al. (2022)\n\n\nDBI\n1.2.1\nR Special Interest Group on Databases (R-SIG-DB) et al. (2024)\n\n\ndendextend\n1.17.1\nGalili (2015)\n\n\ndesc\n1.4.3\nCs√°rdi et al. (2023b)\n\n\ndiffobj\n0.3.5\nGaslam (2021)\n\n\ndigest\n0.6.34\nAntoine Lucas et al. (2024)\n\n\ndistributional\n0.3.2\nO‚ÄôHara-Wild et al. (2023)\n\n\ndoParallel\n1.0.17\nCorporation and Weston (2022)\n\n\nDT\n0.31\nXie et al. (2023b)\n\n\ndygraphs\n1.1.1.6\nVanderkam et al. (2018)\n\n\nellipse\n0.5.0\nMurdoch and Chow (2023)\n\n\nellipsis\n0.3.2\nWickham (2021)\n\n\nemmeans\n1.9.0\nLenth (2023)\n\n\nestimability\n1.4.1\nLenth (2022)\n\n\nevaluate\n0.23\nWickham and Xie (2023)\n\n\nfansi\n1.0.6\nGaslam (2023)\n\n\nfarver\n2.1.1\nPedersen et al. (2022)\n\n\nfastmap\n1.1.1\nChang (2023b)\n\n\nflashClust\n1.1.2\nLangfelder and Horvath (2012)\n\n\nfontawesome\n0.5.2\nIannone (2023)\n\n\nforeach\n1.5.2\nMicrosoft and Weston (2022)\n\n\nfs\n1.6.3\nHester et al. (2023b)\n\n\nfurrr\n0.3.1\nVaughan and Dancho (2022)\n\n\nfuture\n1.33.1\n@\n\n\ngap\n1.5.3\n\nZhao (2007); Zhao (2023a)\n\n\n\ngap.datasets\n0.0.6\nZhao (2023b)\n\n\ngargle\n1.5.2\nBryan et al. (2023)\n\n\ngenerics\n0.1.3\nWickham et al. (2022a)\n\n\nggdist\n3.3.1\n\nKay (2023b); Kay (2024)\n\n\n\nggpubr\n0.6.0\nKassambara (2023a)\n\n\nggrepel\n0.9.5\nSlowikowski (2024)\n\n\nggridges\n0.5.5\nWilke (2023b)\n\n\nggsci\n3.0.0\nXiao (2023)\n\n\nggsignif\n0.6.4\nConstantin and Patil (2021)\n\n\nglobals\n0.16.2\nBengtsson (2022a)\n\n\nglue\n1.7.0\nHester and Bryan (2024)\n\n\ngridExtra\n2.3\nAuguie (2017)\n\n\ngtable\n0.3.4\nWickham and Pedersen (2023)\n\n\ngtools\n3.9.5\nWarnes et al. (2023)\n\n\nhighr\n0.10\nXie and Qiu (2022)\n\n\nhtmltools\n0.5.7\nCheng et al. (2023c)\n\n\nhtmlwidgets\n1.6.4\nVaidyanathan et al. (2023)\n\n\nhttpuv\n1.6.13\nCheng et al. (2023a)\n\n\nids\n1.0.1\nFitzJohn (2017)\n\n\nigraph\n1.6.0\n\nCsardi and Nepusz (2006); Cs√°rdi et al. (2024)\n\n\n\ninline\n0.3.19\nSklyar et al. (2021)\n\n\ninsight\n0.19.7\nL√ºdecke et al. (2019)\n\n\nisoband\n0.2.7\nWickham et al. (2022b)\n\n\niterators\n1.0.14\nAnalytics and Weston (2022)\n\n\njquerylib\n0.1.4\nSievert and Cheng (2021)\n\n\nlabeling\n0.4.3\nJustin Talbot (2023)\n\n\nlater\n1.3.2\nChang and Cheng (2023)\n\n\nlazyeval\n0.2.2\nWickham (2019)\n\n\nleaps\n3.1\nFortran code by Alan Miller (2020)\n\n\nlifecycle\n1.0.4\nHenry and Wickham (2023)\n\n\nlistenv\n0.9.0\nBengtsson (2022b)\n\n\nlmtest\n0.9.40\nZeileis and Hothorn (2002)\n\n\nloo\n2.6.0\n\nVehtari et al. (2017); Yao et al. (2017); Vehtari et al. (2023)\n\n\n\nmarkdown\n1.12\nXie et al. (2023a)\n\n\nMatrixModels\n0.5.3\nBates and Maechler (2023)\n\n\nmatrixStats\n1.2.0\nBengtsson (2023a)\n\n\nmemoise\n2.0.1\nWickham et al. (2021)\n\n\nmime\n0.12\nXie (2021)\n\n\nminiUI\n0.1.1.1\nCheng (2018)\n\n\nminqa\n1.2.6\nBates et al. (2023)\n\n\nmultcompView\n0.1.9\nGraves et al. (2023)\n\n\nmunsell\n0.5.0\nWickham (2018)\n\n\nnleqslv\n3.3.5\nHasselman (2023)\n\n\nnloptr\n2.0.3\nJohnson (?)\n\n\nnumDeriv\n2016.8.1.1\nGilbert and Varadhan (2019)\n\n\nopenssl\n2.1.1\nOoms (2023d)\n\n\nparallelly\n1.36.0\nBengtsson (2023b)\n\n\npbapply\n1.7.2\nSolymos and Zawadzki (2023)\n\n\npbkrtest\n0.5.2\nHalekoh and H√∏jsgaard (2014)\n\n\npkgbuild\n1.4.3\nWickham et al. (2023d)\n\n\npkgconfig\n2.0.3\nCs√°rdi (2019)\n\n\npkgload\n1.3.3\nWickham et al. (2023a)\n\n\nplotly\n4.10.3\nSievert (2020)\n\n\nplyr\n1.8.9\nWickham (2011a)\n\n\npolynom\n1.4.1\nVenables et al. (2022)\n\n\nposterior\n1.5.0\n\nVehtari et al. (2021); B√ºrkner et al. (2023)\n\n\n\npraise\n1.0.0\nCsardi and Sorhus (2015)\n\n\nprettyunits\n1.2.0\nCsardi (2023a)\n\n\nprocessx\n3.8.3\nCs√°rdi and Chang (2023)\n\n\nprogress\n1.2.3\nCs√°rdi and FitzJohn (2023)\n\n\npromises\n1.2.1\nCheng (2023)\n\n\nps\n1.7.5\nLoden et al. (2023)\n\n\nqgam\n1.3.4\nFasiolo et al. (2021)\n\n\nquadprog\n1.5.8\nBerwin A. Turlach R port by Andreas Weingessel &lt;Andreas.Weingessel@ci.tuwien.ac.at&gt; Fortran contributions from Cleve Moler dpodi/LINPACK) (2019)\n\n\nquantreg\n5.97\nKoenker (2023)\n\n\nQuickJSR\n1.0.9\nJohnson (2023)\n\n\nR6\n2.5.1\nChang (2021a)\n\n\nrappdirs\n0.3.3\nRatnakumar et al. (2021)\n\n\nrbibutils\n2.2.16\nBoshnakov and Putman (2023)\n\n\nRColorBrewer\n1.1.3\nNeuwirth (2022)\n\n\nRcpp\n1.0.12\n\nEddelbuettel and Fran√ßois (2011); Eddelbuettel (2013); Eddelbuettel and Balamuta (2018); Eddelbuettel et al. (2024b)\n\n\n\nRcppEigen\n0.3.3.9.4\nBates and Eddelbuettel (2013)\n\n\nRcppParallel\n5.1.7\nAllaire et al. (2023a)\n\n\nRdpack\n2.6\nBoshnakov (2023)\n\n\nrematch\n2.0.0\nCsardi (2023b)\n\n\nrematch2\n2.1.2\nCs√°rdi (2020)\n\n\nremotes\n2.4.2.1\nCs√°rdi et al. (2023a)\n\n\nrenv\n1.0.3\nUshey and Wickham (2023)\n\n\nreshape2\n1.4.4\nWickham (2007)\n\n\nrprojroot\n2.0.4\nM√ºller (2023)\n\n\nrstan\n2.32.5\nStan Development Team (2024)\n\n\nrstantools\n2.3.1.1\nGabry et al. (2023)\n\n\nrstatix\n0.7.2\nKassambara (2023b)\n\n\nsass\n0.4.8\nCheng et al. (2023b)\n\n\nscales\n1.3.0\nWickham et al. (2023e)\n\n\nscatterplot3d\n0.3.44\nLigges and M√§chler (2003)\n\n\nselectr\n0.4.2\nPotter (2012)\n\n\nshiny\n1.8.0\nChang et al. (2023)\n\n\nshinyjs\n2.1.0\nAttali (2021)\n\n\nshinystan\n2.6.0\nGabry and Veen (2022)\n\n\nshinythemes\n1.2.0\nChang (2021b)\n\n\nsourcetools\n0.1.7.1\nUshey (2023)\n\n\nSparseM\n1.81\nKoenker (2021)\n\n\nStanHeaders\n2.32.5\nStan Development Team (2020)\n\n\nstringi\n1.8.3\nGagolewski (2022)\n\n\nsvUnit\n1.0.6\nGrosjean (2023)\n\n\nsys\n3.4.2\nOoms (2023e)\n\n\nsystemfonts\n1.0.5\nPedersen et al. (2023)\n\n\ntensorA\n0.36.2.1\nvan den Boogaart (2023)\n\n\ntestthat\n3.2.1\nWickham (2011b)\n\n\ntextshaping\n0.3.7\nPedersen (2023)\n\n\nthreejs\n0.3.3\nLewis (2020)\n\n\ntidyselect\n1.2.0\nHenry and Wickham (2022)\n\n\ntimechange\n0.2.0\nSpinu (2023)\n\n\ntinytex\n0.49\n\nXie (2019); Xie (2023c)\n\n\n\ntzdb\n0.4.0\nVaughan (2023)\n\n\nutf8\n1.2.4\nPerry (2023)\n\n\nuuid\n1.1.1\nUrbanek and Ts‚Äôo (2023)\n\n\nvctrs\n0.6.5\nWickham et al. (2023c)\n\n\nviridis\n0.6.4\nGarnier et al. (2023a)\n\n\nviridisLite\n0.4.2\nGarnier et al. (2023b)\n\n\nvroom\n1.6.5\nHester et al. (2023a)\n\n\nwaldo\n0.5.2\nWickham (2023b)\n\n\nwithr\n3.0.0\nHester et al. (2024)\n\n\nxfun\n0.41\nXie (2023d)\n\n\nxtable\n1.8.4\nDahl et al. (2019)\n\n\nxts\n0.13.1\nRyan and Ulrich (2023)\n\n\nyaml\n2.3.8\nGarbett et al. (2023)\n\n\nzoo\n1.8.12\nZeileis and Grothendieck (2005)",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "99-references.html#r-packages",
    "href": "99-references.html#r-packages",
    "title": "References",
    "section": "",
    "text": "Bibliography\n\n\nAllaire, J., R. Francois, K. Ushey, G. Vandenbrouck, M. Geelnard, and\nIntel. 2023a. RcppParallel:\nParallel programming tools for ‚ÄúRcpp‚Äù.\n\n\nAllaire, J., Y. Xie, C. Dervieux, J. McPherson, J. Luraschi, K. Ushey,\nA. Atkins, H. Wickham, J. Cheng, W. Chang, and R. Iannone. 2023b. rmarkdown: Dynamic documents for r.\n\n\nAnalytics, R., and S. Weston. 2022. iterators: Provides iterator construct.\n\n\nAntoine Lucas, D. E. with contributions by, J. Tuszynski, H. Bengtsson,\nS. Urbanek, M. Frasca, B. Lewis, M. Stokely, H. Muehleisen, D. Murdoch,\nJ. Hester, W. Wu, Q. Kou, T. Onkelinx, M. Lang, V. Simko, K. Hornik, R.\nNeal, K. Bell, M. de Queljoe, I. Suruceanu, B. Denney, D. Schumacher, W.\nChang, D. Attali, and M. Chirico. 2024. digest: Create compact hash digests of r\nobjects.\n\n\nAttali, D. 2021. shinyjs: Easily improve the user experience of\nyour shiny apps in seconds.\n\n\nAttali, D. 2023. colourpicker: A colour picker tool for shiny and\nfor selecting colours in plots.\n\n\nAuguie, B. 2017. gridExtra: Miscellaneous functions for\n‚ÄúGrid‚Äù graphics.\n\n\nBanta, J. A., M. H. H. Stevens, and M. Pigliucci. 2010. A comprehensive\ntest of the ‚Äúlimiting resources‚Äù framework applied to plant\ntolerance to apical meristem damage. Oikos 119:359‚Äì369.\n\n\nBarrett, T., M. Dowle, and A. Srinivasan. 2023. data.table: Extension of ‚Äúdata.frame‚Äù.\n\n\nBates, D., and D. Eddelbuettel. 2013. Fast and elegant numerical\nlinear algebra using the RcppEigen package. Journal of\nStatistical Software 52:1‚Äì24.\n\n\nBates, D., M. M√§chler, B. Bolker, and S. Walker. 2015. Fitting linear\nmixed-effects models using lme4. Journal\nof Statistical Software 67:1‚Äì48.\n\n\nBates, D., and M. Maechler. 2023. MatrixModels:\nModelling with sparse and dense matrices.\n\n\nBates, D., K. M. Mullen, J. C. Nash, and R. Varadhan. 2023. minqa: Derivative-free optimization algorithms by\nquadratic approximation.\n\n\nBeleites, C. 2020. arrayhelpers: Convenience functions for\narrays.\n\n\nBengtsson, H. 2022a. globals: Identify global objects in r\nexpressions.\n\n\nBengtsson, H. 2022b. listenv: Environments behaving (almost) as\nlists.\n\n\nBengtsson, H. 2023a. matrixStats: Functions that apply to rows and\ncolumns of matrices (and to vectors).\n\n\nBengtsson, H. 2023b. parallelly: Enhancing the ‚Äúparallel‚Äù package.\n\n\nBerwin A. Turlach R port by Andreas Weingessel\n&lt;Andreas.Weingessel@ci.tuwien.ac.at&gt; Fortran contributions from\nCleve Moler dpodi/LINPACK), S. original by. 2019. quadprog: Functions to solve quadratic programming\nproblems.\n\n\nBolker, B. M., M. E. Brooks, C. J. Clark, S. W. Geange, J. R. Poulsen,\nM. H. H. Stevens, and J.-S. S. White. 2009. Generalized linear mixed\nmodels: A practical guide for ecology and evolution. Trends in Ecology\nand Evolution 24:127‚Äì135.\n\n\nBolker, B., and D. Robinson. 2022. broom.mixed: Tidying methods for mixed models.\n\n\nBoshnakov, G. N. 2023. Rdpack:\nUpdate and manipulate rd documentation objects.\n\n\nBoshnakov, G. N., and C. Putman. 2023. rbibutils: Read ‚ÄúBibtex‚Äù\nfiles and convert between bibliography formats.\n\n\nBryan, J. 2016. cellranger: Translate spreadsheet cell ranges to\nrows and columns.\n\n\nBryan, J., C. Citro, and H. Wickham. 2023. gargle: Utilities for working with google\nAPIs.\n\n\nB√ºrkner, P.-C. 2017. brms: An R package for\nBayesian multilevel models using Stan.\nJournal of Statistical Software 80:1‚Äì28.\n\n\nB√ºrkner, P.-C. 2018. Advanced\nBayesian multilevel modeling with the R\npackage brms. The R Journal 10:395‚Äì411.\n\n\nB√ºrkner, P.-C. 2021. Bayesian item response\nmodeling in R with brms and\nStan. Journal of Statistical Software 100:1‚Äì54.\n\n\nB√ºrkner, P.-C., J. Gabry, M. Kay, and A. Vehtari. 2023. posterior: Tools for working with posterior\ndistributions.\n\n\nButler, D. 2022. asreml: Fits the linear mixed model.\n\n\nChang, W. 2021a. R6:\nEncapsulated classes with reference semantics.\n\n\nChang, W. 2021b. shinythemes: Themes for shiny.\n\n\nChang, W. 2023a. cachem: Cache r objects with automatic\npruning.\n\n\nChang, W. 2023b. fastmap: Fast data structures.\n\n\nChang, W., and J. Cheng. 2023. later: Utilities for scheduling functions to\nexecute later with event loops.\n\n\nChang, W., J. Cheng, J. Allaire, C. Sievert, B. Schloerke, Y. Xie, J.\nAllen, J. McPherson, A. Dipert, and B. Borges. 2023. shiny: Web application framework for r.\n\n\nCheng, J. 2018. miniUI: Shiny UI widgets for small screens.\n\n\nCheng, J. 2023. promises: Abstractions for promise-based\nasynchronous programming.\n\n\nCheng, J., W. Chang, S. Reid, J. Brown, B. Trower, and A. Peslyak.\n2023a. httpuv: HTTP and WebSocket server library.\n\n\nCheng, J., T. Mastny, R. Iannone, B. Schloerke, and C. Sievert. 2023b.\nsass: Syntactically awesome style sheets\n(‚ÄúSass‚Äù).\n\n\nCheng, J., and C. Sievert. 2023. crosstalk: Inter-widget interactivity for HTML\nwidgets.\n\n\nCheng, J., C. Sievert, B. Schloerke, W. Chang, Y. Xie, and J. Allen.\n2023c. htmltools: Tools for HTML.\n\n\nConstantin, A.-E., and I. Patil. 2021. ggsignif: R package for displaying significance\nbrackets for ‚Äúggplot2‚Äù. PsyArxiv.\n\n\nCorporation, M., and S. Weston. 2022. doParallel: Foreach parallel adaptor for the\n‚Äúparallel‚Äù package.\n\n\nCsardi, G. 2023a. prettyunits: Pretty, human readable formatting of\nquantities.\n\n\nCsardi, G. 2023b. rematch: Match regular expressions with a nicer\n‚ÄúAPI‚Äù.\n\n\nCsardi, G., and T. Nepusz. 2006. The igraph\nsoftware package for complex network research. InterJournal Complex\nSystems:1695.\n\n\nCsardi, G., and S. Sorhus. 2015. praise: Praise users.\n\n\nCs√°rdi, G. 2019. pkgconfig: Private configuration for\n‚ÄúR‚Äù packages.\n\n\nCs√°rdi, G. 2020. rematch2: Tidy output\nfrom regular expression matching.\n\n\nCs√°rdi, G. 2022. crayon: Colored terminal output.\n\n\nCs√°rdi, G., and W. Chang. 2022. callr: Call r from r.\n\n\nCs√°rdi, G., and W. Chang. 2023. processx: Execute and control system\nprocesses.\n\n\nCs√°rdi, G., and R. FitzJohn. 2023. progress: Terminal progress bars.\n\n\nCs√°rdi, G., J. Hester, H. Wickham, W. Chang, M. Morgan, and D.\nTenenbaum. 2023a. remotes: R package installation from remote\nrepositories, including ‚ÄúGitHub‚Äù.\n\n\nCs√°rdi, G., K. M√ºller, and J. Hester. 2023b. desc: Manipulate DESCRIPTION files.\n\n\nCs√°rdi, G., T. Nepusz, V. Traag, S. Horv√°t, F. Zanini, D. Noom, and K.\nM√ºller. 2024. igraph: Network analysis and visualization in\nr.\n\n\nDahl, D. B., D. Scott, C. Roosen, A. Magnusson, and J. Swinton. 2019. xtable: Export tables to LaTeX or HTML.\n\n\nEddelbuettel, D. 2013. Seamless R\nand C++ integration with Rcpp. Springer,\nNew York.\n\n\nEddelbuettel, D., and J. J. Balamuta. 2018. Extending R with C++: A Brief\nIntroduction to Rcpp. The American Statistician\n72:28‚Äì36.\n\n\nEddelbuettel, D., J. W. Emerson, and M. J. Kane. 2024a. BH: Boost c++\nheader files.\n\n\nEddelbuettel, D., R. Francois, J. Allaire, K. Ushey, Q. Kou, N. Russell,\nI. Ucar, D. Bates, and J. Chambers. 2024b. Rcpp:\nSeamless r and c++ integration.\n\n\nEddelbuettel, D., and R. Fran√ßois. 2011. Rcpp: Seamless\nR and C++ integration. Journal of\nStatistical Software 40:1‚Äì18.\n\n\nElston, D. A., R. Moss, T. Boulinier, C. Arrowsmith, and X. Lambin.\n2001. Analysis of aggregation, a worked example: Numbers of ticks on red\ngrouse chicks. Parasitology 122:563‚Äì569.\n\n\nFasiolo, M., S. N. Wood, M. Zaffran, R. Nedellec, and Y. Goude. 2021. qgam: Bayesian nonparametric quantile\nregression modeling in R. Journal of Statistical\nSoftware 100:1‚Äì31.\n\n\nFitzJohn, R. 2017. ids: Generate random identifiers.\n\n\nFortran code by Alan Miller, T. L. based on. 2020. leaps: Regression subset selection.\n\n\nFox, J., and S. Weisberg. 2019. An\nR companion to applied regression. Third. Sage,\nThousand Oaks CA.\n\n\nFox, J., S. Weisberg, and B. Price. 2022. carData: Companion to applied regression data\nsets.\n\n\nGabry, J., B. Goodrich, M. Lysy, and A. Johnson. 2023. rstantools: Tools for developing r packages\ninterfacing with ‚ÄúStan‚Äù.\n\n\nGabry, J., and T. Mahr. 2022. bayesplot: Plotting for bayesian models.\n\n\nGabry, J., D. Simpson, A. Vehtari, M. Betancourt, and A. Gelman. 2019.\nVisualization in bayesian\nworkflow. J. R. Stat. Soc. A 182:389‚Äì402.\n\n\nGabry, J., and D. Veen. 2022. shinystan: Interactive visual and numerical\ndiagnostics and posterior analysis for bayesian models.\n\n\nGagolewski, M. 2022. stringi: Fast and portable character\nstring processing in R. Journal of Statistical Software\n103:1‚Äì59.\n\n\nGalili, T. 2015. dendextend: An r package for visualizing,\nadjusting, and comparing trees of hierarchical clustering.\nBioinformatics.\n\n\nGarbett, S. P., J. Stephens, K. Simonov, Y. Xie, Z. Dong, H. Wickham, J.\nHorner, reikoch, W. Beasley, B. O‚ÄôConnor, G. R. Warnes, M. Quinn, and Z.\nN. Kamvar. 2023. yaml: Methods to convert r data to YAML and\nback.\n\n\nGarnier, Simon, Ross, Noam, Rudis, Robert, Camargo, A. Pedro, Sciaini,\nMarco, Scherer, and C√©dric. 2023a. viridis(Lite) - colorblind-friendly color maps for\nr.\n\n\nGarnier, Simon, Ross, Noam, Rudis, Robert, Camargo, A. Pedro, Sciaini,\nMarco, Scherer, and C√©dric. 2023b. viridis(Lite) - colorblind-friendly color maps for\nr.\n\n\nGaslam, B. 2021. diffobj: Diffs for r objects.\n\n\nGaslam, B. 2023. fansi: ANSI control sequence aware string\nfunctions.\n\n\nGenz, A., and F. Bretz. 2009. Computation of multivariate normal and t\nprobabilities. Springer-Verlag, Heidelberg.\n\n\nGilbert, P., and R. Varadhan. 2019. numDeriv: Accurate numerical derivatives.\n\n\nGraves, S., H.-P. Piepho, and L. S. with help from Sundar Dorai-Raj.\n2023. multcompView: Visualizations of paired\ncomparisons.\n\n\nGronau, Q. F., H. Singmann, and E.-J. Wagenmakers. 2020. bridgesampling: An R package for\nestimating normalizing constants. Journal of Statistical Software\n92:1‚Äì29.\n\n\nGrosjean, P. 2023. SciViews-r. UMONS, MONS,\nBelgium.\n\n\nHadfield, J. D. 2010. MCMC\nmethods for multi-response generalized linear mixed models: The\nMCMCglmm R package. Journal of Statistical\nSoftware 33:1‚Äì22.\n\n\nHadfield, J. D., A. J. Wilson, D. Garant, B. C. Sheldon, and L. E.\nKruuk. 2010. The Misuse of BLUP in\nEcology and Evolution. American Naturalist\n175:116‚Äì125.\n\n\nHalekoh, U., and S. H√∏jsgaard. 2014. A kenward-roger approximation\nand parametric bootstrap methods for tests in linear mixed models ‚Äì the\nR package pbkrtest. Journal\nof Statistical Software 59:1‚Äì30.\n\n\nHankin, R. K. S. 2007. Very large numbers in r: Introducing package\nbrobdingnag. R News 7.\n\n\nHartig, F. 2022. DHARMa:\nResidual diagnostics for hierarchical (multi-level / mixed) regression\nmodels.\n\n\nHasselman, B. 2023. nleqslv: Solve systems of nonlinear equations.\n\n\nHenry, L., and H. Wickham. 2022. tidyselect: Select from a set of strings.\n\n\nHenry, L., and H. Wickham. 2023. lifecycle: Manage the life cycle of your package\nfunctions.\n\n\nHester, J., and J. Bryan. 2024. glue: Interpreted string literals.\n\n\nHester, J., and G. Cs√°rdi. 2023. brio: Basic r input output.\n\n\nHester, J., L. Henry, K. M√ºller, K. Ushey, H. Wickham, and W. Chang.\n2024. withr: Run code ‚ÄúWith‚Äù\ntemporarily modified global state.\n\n\nHester, J., H. Wickham, and J. Bryan. 2023a. vroom: Read and write rectangular text data\nquickly.\n\n\nHester, J., H. Wickham, and G. Cs√°rdi. 2023b. fs: Cross-platform file system operations based on\n‚Äúlibuv‚Äù.\n\n\nHorst, A. M., A. P. Hill, and K. B. Gorman. 2020. palmerpenguins: Palmer archipelago (antarctica)\npenguin data.\n\n\nHouslay, T. M., and A. J. Wilson. 2017. Avoiding the misuse of\nBLUP in behavioural ecology. Behavioral Ecology\n28:948‚Äì952.\n\n\nIannone, R. 2023. fontawesome: Easily work with ‚ÄúFont\nAwesome‚Äù icons.\n\n\nJohnson, A. R. 2023. QuickJSR:\nInterface for the ‚ÄúQuickJS‚Äù lightweight\n‚ÄúJavaScript‚Äù engine.\n\n\nJohnson, S. G. ? The NLopt nonlinear-optimization package. ? ?\n\n\nJustin Talbot. 2023. labeling: Axis labeling.\n\n\nKassambara, A. 2023a. ggpubr: ‚Äúggplot2‚Äù based publication ready plots.\n\n\nKassambara, A. 2023b. rstatix: Pipe-friendly framework for basic\nstatistical tests.\n\n\nKassambara, A., and F. Mundt. 2020. factoextra: Extract and visualize the results of\nmultivariate data analyses.\n\n\nKay, M. 2023a. ggdist: Visualizations of distributions and\nuncertainty.\n\n\nKay, M. 2023b. tidybayes: Tidy data and geoms for\nBayesian models.\n\n\nKay, M. 2024. ggdist: Visualizations of distributions and\nuncertainty in the grammar of graphics. IEEE Transactions on\nVisualization and Computer Graphics:1‚Äì11.\n\n\nKoenker, R. 2021. SparseM:\nSparse linear algebra.\n\n\nKoenker, R. 2023. quantreg: Quantile regression.\n\n\nKuznetsova, A., P. B. Brockhoff, and R. H. B. Christensen. 2017. lmerTest package: Tests in linear mixed effects\nmodels. Journal of Statistical Software 82:1‚Äì26.\n\n\nLang, M. 2017. checkmate: Fast argument checks for defensive\nR programming. The R Journal 9:437‚Äì445.\n\n\nLang, M., and R Core Team. 2021. backports: Reimplementations of functions\nintroduced since r-3.0.0.\n\n\nLangfelder, P., and S. Horvath. 2012. Fast R functions\nfor robust correlations and hierarchical clustering. Journal of\nStatistical Software 46:1‚Äì17.\n\n\nL√™, S., J. Josse, and F. Husson. 2008. FactoMineR: A\npackage for multivariate analysis. Journal of Statistical Software\n25:1‚Äì18.\n\n\nLenth, R. 2022. estimability: Tools for assessing estimability of\nlinear predictions.\n\n\nLenth, R. V. 2023. emmeans: Estimated marginal means, aka\nleast-squares means.\n\n\nLewis, B. W. 2020. threejs: Interactive 3D scatter plots, networks\nand globes.\n\n\nLigges, U., and M. M√§chler. 2003. Scatterplot3d - an r\npackage for visualizing multivariate data. Journal of Statistical\nSoftware 8:1‚Äì20.\n\n\nLincoln, M. 2022. clipr: Read and write from the system\nclipboard.\n\n\nLoden, J., D. Daeschler, G. Rodola‚Äô, and G. Cs√°rdi. 2023. ps: List, query, manipulate system processes.\n\n\nL√ºdecke, D., M. S. Ben-Shachar, I. Patil, P. Waggoner, and D. Makowski.\n2021. performance: An R package for\nassessment, comparison and testing of statistical models. Journal of\nOpen Source Software 6:3139.\n\n\nL√ºdecke, D., P. Waggoner, and D. Makowski. 2019. insight: A unified interface to access information\nfrom model objects in R. Journal of Open Source\nSoftware 4:1412.\n\n\nMakowski, D., M. S. Ben-Shachar, and D. L√ºdecke. 2019. bayestestR: Describing effects and their\nuncertainty, existence and significance within the bayesian\nframework. Journal of Open Source Software 4:1541.\n\n\nMicrosoft, and S. Weston. 2022. foreach: Provides foreach looping construct.\n\n\nM√ºller, K. 2023. rprojroot: Finding files in project\nsubdirectories.\n\n\nMurdoch, D., and E. D. Chow. 2023. ellipse: Functions for drawing ellipses and\nellipse-like confidence regions.\n\n\nNarasimhan, B., S. G. Johnson, T. Hahn, A. Bouvier, and K. Ki√™u. 2023.\ncubature: Adaptive multivariate integration over\nhypercubes.\n\n\nNeuwirth, E. 2022. RColorBrewer:\nColorBrewer palettes.\n\n\nO‚ÄôHara-Wild, M., M. Kay, and A. Hayes. 2023. distributional: Vectorised probability\ndistributions.\n\n\nOehlschl√§gel, J., and B. Ripley. 2022. bit: Classes and methods for fast memory-efficient\nboolean selections.\n\n\nOehlschl√§gel, J., and L. Silvestri. 2020. bit64: A S3 class for\nvectors of 64bit integers.\n\n\nOoms, J. 2023a. askpass: Password entry utilities for r, git, and\nSSH.\n\n\nOoms, J. 2023b. commonmark: High performance CommonMark and github\nmarkdown rendering in r.\n\n\nOoms, J. 2023c. curl: A modern and flexible web client for r.\n\n\nOoms, J. 2023d. openssl: Toolkit for encryption, signatures and\ncertificates based on OpenSSL.\n\n\nOoms, J. 2023e. sys: Powerful and reliable tools for running\nsystem commands in r.\n\n\nParadis, E., and K. Schliep. 2019. Ape 5.0: An\nenvironment for modern phylogenetics and evolutionary analyses in\nR. Bioinformatics 35:526‚Äì528.\n\n\nPatil, I., D. Makowski, M. S. Ben-Shachar, B. M. Wiernik, E. Bacher, and\nD. L√ºdecke. 2022. datawizard: An R package for easy\ndata preparation and statistical transformations. Journal of Open\nSource Software 7:4684.\n\n\nPedersen, T. L. 2023. textshaping: Bindings to the\n‚ÄúHarfBuzz‚Äù and\n‚ÄúFribidi‚Äù libraries for text shaping.\n\n\nPedersen, T. L. 2024. patchwork: The composer of plots.\n\n\nPedersen, T. L., B. Nicolae, and R. Fran√ßois. 2022. farver: High performance colour space\nmanipulation.\n\n\nPedersen, T. L., J. Ooms, and D. Govett. 2023. systemfonts: System native font finding.\n\n\nPerry, P. O. 2023. utf8: Unicode text\nprocessing.\n\n\nPlate, T., and R. Heiberger. 2016. abind: Combine multidimensional arrays.\n\n\nPlummer, M., N. Best, K. Cowles, and K. Vines. 2006. CODA:\nConvergence diagnosis and output analysis for MCMC. R News 6:7‚Äì11.\n\n\nPotter, S. 2012. Introducing\nthe selectr package. The University of Auckland, Auckland, New\nZealand.\n\n\nR Core Team. 2023. R:\nA language and environment for statistical computing. R Foundation\nfor Statistical Computing, Vienna, Austria.\n\n\nR Special Interest Group on Databases (R-SIG-DB), H. Wickham, and K.\nM√ºller. 2024. DBI: R\ndatabase interface.\n\n\nRatnakumar, S., T. Mick, and T. Davis. 2021. rappdirs: Application directories: Determine where\nto save data, caches, and logs.\n\n\nRyan, J. A., and J. M. Ulrich. 2023. xts: eXtensible time series.\n\n\nSchafer, J., R. Opgen-Rhein, V. Zuber, M. Ahdesmaki, A. P. D. Silva, and\nK. Strimmer. 2021. corpcor: Efficient estimation of covariance and\n(partial) correlation.\n\n\nSievert, C. 2020. Interactive web-based\ndata visualization with r, plotly, and shiny. Chapman; Hall/CRC.\n\n\nSievert, C., and J. Cheng. 2021. jquerylib: Obtain ‚ÄújQuery‚Äù as an HTML dependency object.\n\n\nSievert, C., J. Cheng, and G. Aden-Buie. 2023. bslib: Custom\n‚ÄúBootstrap‚Äù ‚ÄúSass‚Äù\nthemes for ‚Äúshiny‚Äù and\n‚Äúrmarkdown‚Äù.\n\n\nSklyar, O., D. Murdoch, M. Smith, D. Eddelbuettel, R. Francois, K.\nSoetaert, and J. Ranke. 2021. inline: Functions to inline c, c++, fortran\nfunction calls from r.\n\n\nSlowikowski, K. 2024. ggrepel: Automatically position non-overlapping\ntext labels with ‚Äúggplot2‚Äù.\n\n\nSolymos, P., and Z. Zawadzki. 2023. pbapply: Adding progress bar to ‚Äú*apply‚Äù functions.\n\n\nSpinu, V. 2023. timechange: Efficient manipulation of\ndate-times.\n\n\nStan Development Team. 2020. StanHeaders: Headers for the\nR interface to Stan.\n\n\nStan Development Team. 2021. Stan modeling\nlanguage users guide and reference manual, 2.26.\n\n\nStan Development Team. 2024. RStan: The R\ninterface to Stan.\n\n\nStauffer, R., G. J. Mayr, M. Dabernig, and A. Zeileis. 2009. Somewhere over the\nrainbow: How to make effective use of colors in meteorological\nvisualizations. Bulletin of the American Meteorological Society\n96:203‚Äì216.\n\n\nStoffel, M. A., S. Nakagawa, and H. Schielzeth. 2017. rptR: Repeatability estimation and variance\ndecomposition by generalized linear mixed-effects models. Methods in\nEcology and Evolution 8:1639???1644.\n\n\nUrbanek, S. 2015. base64enc: Tools for\nbase64 encoding.\n\n\nUrbanek, S., and T. Ts‚Äôo. 2023. uuid: Tools for generating and handling of\nUUIDs.\n\n\nUshey, K. 2023. sourcetools: Tools for reading, tokenizing and\nparsing r code.\n\n\nUshey, K., and H. Wickham. 2023. renv: Project environments.\n\n\nVaidyanathan, R., Y. Xie, J. Allaire, J. Cheng, C. Sievert, and K.\nRussell. 2023. htmlwidgets: HTML widgets for r.\n\n\nvan den Boogaart, K. G. 2023. tensorA: Advanced tensor arithmetic with named\nindices.\n\n\nVanderkam, D., J. Allaire, J. Owen, D. Gromer, and B. Thieurmel. 2018.\ndygraphs: Interface to\n‚ÄúDygraphs‚Äù interactive time series charting\nlibrary.\n\n\nVaughan, D. 2023. tzdb: Time zone database information.\n\n\nVaughan, D., and M. Dancho. 2022. furrr: Apply mapping functions in parallel using\nfutures.\n\n\nVaughan, D., J. Hester, and R. Fran√ßois. 2023. cpp11: A c++11 interface\nfor r‚Äôs c interface.\n\n\nVehtari, A., J. Gabry, M. Magnusson, Y. Yao, P.-C. B√ºrkner, T. Paananen,\nand A. Gelman. 2023. loo: Efficient leave-one-out cross-validation and\nWAIC for bayesian models.\n\n\nVehtari, A., A. Gelman, and J. Gabry. 2017. Practical bayesian\nmodel evaluation using leave-one-out cross-validation and WAIC.\nStatistics and Computing 27:1413‚Äì1432.\n\n\nVehtari, A., A. Gelman, D. Simpson, B. Carpenter, and P.-C. B√ºrkner.\n2021. Rank-normalization, folding, and localization: An improved rhat\nfor assessing convergence of MCMC (with discussion). Bayesian Analysis.\n\n\nVenables, B., K. Hornik, and M. Maechler. 2022. polynom: A collection of functions to implement a\nclass for univariate polynomial manipulations.\n\n\nWarnes, G. R., B. Bolker, T. Lumley, A. Magnusson, B. Venables, G.\nRyodan, and S. Moeller. 2023. gtools: Various r programming tools.\n\n\nWei, T., and V. Simko. 2021. R package ‚Äúcorrplot‚Äù: Visualization of a correlation\nmatrix.\n\n\nWickham, C. 2018. munsell: Utilities for using munsell colours.\n\n\nWickham, H. 2007. Reshaping\ndata with the reshape package. Journal\nof Statistical Software 21:1‚Äì20.\n\n\nWickham, H. 2011a. The\nsplit-apply-combine strategy for data analysis. Journal of\nStatistical Software 40:1‚Äì29.\n\n\nWickham, H. 2011b. testthat: Get started with testing. The R\nJournal 3:5‚Äì10.\n\n\nWickham, H. 2019. lazyeval: Lazy (non-standard) evaluation.\n\n\nWickham, H. 2021. ellipsis: Tools for working with ...\n\n\nWickham, H. 2023a. blob: A simple S3 class for representing vectors\nof binary data (‚ÄúBLOBS‚Äù).\n\n\nWickham, H. 2023b. waldo: Find differences between r objects.\n\n\nWickham, H., M. Averick, J. Bryan, W. Chang, L. D. McGowan, R. Fran√ßois,\nG. Grolemund, A. Hayes, L. Henry, J. Hester, M. Kuhn, T. L. Pedersen, E.\nMiller, S. M. Bache, K. M√ºller, J. Ooms, D. Robinson, D. P. Seidel, V.\nSpinu, K. Takahashi, D. Vaughan, C. Wilke, K. Woo, and H. Yutani. 2019.\nWelcome to the tidyverse. Journal of Open Source Software\n4:1686.\n\n\nWickham, H., W. Chang, J. Hester, and L. Henry. 2023a. pkgload: Simulate package installation and\nattach.\n\n\nWickham, H., R. Fran√ßois, and L. D‚ÄôAgostino McGowan. 2023b. emo:\nEasily insert ‚ÄúEmoji‚Äù.\n\n\nWickham, H., and G. Grolemund. 2016. R for Data Science:\nImport, Tidy, Transform,\nVisualize, and Model Data. 1st edition.\nO‚ÄôReilly Media.\n\n\nWickham, H., L. Henry, and D. Vaughan. 2023c. vctrs: Vector helpers.\n\n\nWickham, H., J. Hester, W. Chang, K. M√ºller, and D. Cook. 2021. memoise: ‚ÄúMemoisation‚Äù\nof functions.\n\n\nWickham, H., J. Hester, and G. Cs√°rdi. 2023d. pkgbuild: Find tools needed to build r\npackages.\n\n\nWickham, H., M. Kuhn, and D. Vaughan. 2022a. generics: Common S3 generics not provided by base\nr methods related to model fitting.\n\n\nWickham, H., and T. L. Pedersen. 2023. gtable: Arrange ‚ÄúGrobs‚Äù\nin tables.\n\n\nWickham, H., T. L. Pedersen, and D. Seidel. 2023e. scales: Scale functions for visualization.\n\n\nWickham, H., C. O. Wilke, and T. L. Pedersen. 2022b. isoband: Generate isolines and isobands from\nregularly spaced elevation grids.\n\n\nWickham, H., and Y. Xie. 2023. evaluate: Parsing and evaluation tools that\nprovide more details than the default.\n\n\nWilke, C. O. 2023a. cowplot: Streamlined plot theme and plot\nannotations for ‚Äúggplot2‚Äù.\n\n\nWilke, C. O. 2023b. ggridges: Ridgeline plots in ‚Äúggplot2‚Äù.\n\n\nWolak, M. E. 2012. nadiv: An R\npackage to create relatedness matrices for estimating non-additive\ngenetic variances in animal models. Methods in Ecology and Evolution\n3:792‚Äì796.\n\n\nXiao, N. 2023. ggsci: Scientific journal and sci-fi themed color\npalettes for ‚Äúggplot2‚Äù.\n\n\nXie, Y. 2014. knitr: A comprehensive tool\nfor reproducible research in R. in V. Stodden, F.\nLeisch, and R. D. Peng, editors. Implementing reproducible computational\nresearch. Chapman; Hall/CRC.\n\n\nXie, Y. 2015. Dynamic documents with\nR and knitr. 2nd edition. Chapman; Hall/CRC, Boca\nRaton, Florida.\n\n\nXie, Y. 2016. bookdown: Authoring books and technical documents\nwith R markdown. Chapman; Hall/CRC, Boca Raton,\nFlorida.\n\n\nXie, Y. 2019. TinyTeX:\nA lightweight, cross-platform, and easy-to-maintain LaTeX distribution\nbased on TeX live. TUGboat 40:30‚Äì32.\n\n\nXie, Y. 2021. mime: Map filenames to MIME types.\n\n\nXie, Y. 2023a. bookdown: Authoring books and technical documents\nwith r markdown.\n\n\nXie, Y. 2023b. knitr: A general-purpose package for dynamic\nreport generation in r.\n\n\nXie, Y. 2023c. tinytex: Helper functions to install and maintain\nTeX live, and compile LaTeX documents.\n\n\nXie, Y. 2023d. xfun: Supporting functions for packages maintained\nby ‚ÄúYihui Xie‚Äù.\n\n\nXie, Y., J. J. Allaire, and G. Grolemund. 2018. R markdown: The definitive\nguide. Chapman; Hall/CRC, Boca Raton, Florida.\n\n\nXie, Y., J. Allaire, and J. Horner. 2023a. markdown: Render markdown with ‚Äúcommonmark‚Äù.\n\n\nXie, Y., J. Cheng, and X. Tan. 2023b. DT: A wrapper\nof the JavaScript library ‚ÄúDataTables‚Äù.\n\n\nXie, Y., C. Dervieux, and E. Riederer. 2020. R markdown\ncookbook. Chapman; Hall/CRC, Boca Raton, Florida.\n\n\nXie, Y., and Y. Qiu. 2022. highr: Syntax highlighting for r source code.\n\n\nYao, Y., A. Vehtari, D. Simpson, and A. Gelman. 2017. Using stacking to average\nbayesian predictive distributions. Bayesian Analysis.\n\n\nZeileis, A., J. C. Fisher, K. Hornik, R. Ihaka, C. D. McWhite, P.\nMurrell, R. Stauffer, and C. O. Wilke. 2020. colorspace: A toolbox for manipulating and\nassessing colors and palettes. Journal of Statistical Software\n96:1‚Äì49.\n\n\nZeileis, A., and G. Grothendieck. 2005. zoo: S3 infrastructure for regular and irregular\ntime series. Journal of Statistical Software 14:1‚Äì27.\n\n\nZeileis, A., K. Hornik, and P. Murrell. 2009. Escaping\nRGBland: Selecting colors for statistical graphics.\nComputational Statistics & Data Analysis 53:3259‚Äì3270.\n\n\nZeileis, A., and T. Hothorn. 2002. Diagnostic checking in\nregression relationships. R News 2:7‚Äì10.\n\n\nZhao, J. H. 2007. gap: Genetic analysis package. Journal of\nStatistical Software 23:1‚Äì18.\n\n\nZhao, J. H. 2023a. gap: Genetic analysis package.\n\n\nZhao, J. H. 2023b. gap.datasets: Datasets for ‚Äúgap‚Äù.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "98_01-R.html",
    "href": "98_01-R.html",
    "title": "Appendix A ‚Äî R",
    "section": "",
    "text": "Need to write something about R\nWe also use various methods for manipulating and visualising data frames using the üì¶ tidyverse (Wickham et al. 2019) (including tidyr, dplyr, ggplot2 etc). You can get more details on their use can be found at in the Book R for Data Science (Wickham and Grolemund 2016) which is freely available as a bookdown website here.\n\n\n\n\nWickham, H., M. Averick, J. Bryan, W. Chang, L. D. McGowan, R. Fran√ßois, G. Grolemund, A. Hayes, L. Henry, J. Hester, M. Kuhn, T. L. Pedersen, E. Miller, S. M. Bache, K. M√ºller, J. Ooms, D. Robinson, D. P. Seidel, V. Spinu, K. Takahashi, D. Vaughan, C. Wilke, K. Woo, and H. Yutani. 2019. Welcome to the tidyverse. Journal of Open Source Software 4:1686.\n\n\nWickham, H., and G. Grolemund. 2016. R for Data Science: Import, Tidy, Transform, Visualize, and Model Data. 1st edition. O‚ÄôReilly Media.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>¬† <span class='chapter-title'>R</span>"
    ]
  }
]