<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>5.1 Lecture | BIO8940 Advanced stats and Open Science</title>
  <meta name="description" content="Theory and practicals for BIO8940 course at the University of Ottawa" />
  <meta name="generator" content="bookdown 0.37 and GitBook 2.6.7" />

  <meta property="og:title" content="5.1 Lecture | BIO8940 Advanced stats and Open Science" />
  <meta property="og:type" content="book" />
  <meta property="og:image" content="/images/missing.png" />
  <meta property="og:description" content="Theory and practicals for BIO8940 course at the University of Ottawa" />
  <meta name="github-repo" content="BIO8940-uOttawa/class_book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="5.1 Lecture | BIO8940 Advanced stats and Open Science" />
  
  <meta name="twitter:description" content="Theory and practicals for BIO8940 course at the University of Ottawa" />
  <meta name="twitter:image" content="/images/missing.png" />

<meta name="author" content="Julien Martin" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="5-introduction-to-linear-mixed-models.html"/>
<link rel="next" href="5.2-practical-2.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Advanced stats and open science</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Note</a></li>
<li class="part"><span><b>I Open Science</b></span></li>
<li class="chapter" data-level="1" data-path="1-introduction-to-open-science.html"><a href="1-introduction-to-open-science.html"><i class="fa fa-check"></i><b>1</b> Introduction to open Science</a>
<ul>
<li class="chapter" data-level="1.1" data-path="1.1-why-do-we-need-it.html"><a href="1.1-why-do-we-need-it.html"><i class="fa fa-check"></i><b>1.1</b> Why do we need it?</a></li>
<li class="chapter" data-level="1.2" data-path="1.2-lecture.html"><a href="1.2-lecture.html"><i class="fa fa-check"></i><b>1.2</b> Lecture</a></li>
<li class="chapter" data-level="1.3" data-path="1.3-what-it-is.html"><a href="1.3-what-it-is.html"><i class="fa fa-check"></i><b>1.3</b> What it is?</a></li>
<li class="chapter" data-level="1.4" data-path="1.4-reproducible-code-and-analysis.html"><a href="1.4-reproducible-code-and-analysis.html"><i class="fa fa-check"></i><b>1.4</b> Reproducible code and analysis</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="2-introduction-to-rmarkdown.html"><a href="2-introduction-to-rmarkdown.html"><i class="fa fa-check"></i><b>2</b> Introduction to Rmarkdown</a>
<ul>
<li class="chapter" data-level="2.1" data-path="2.1-lecture-1.html"><a href="2.1-lecture-1.html"><i class="fa fa-check"></i><b>2.1</b> Lecture</a></li>
<li class="chapter" data-level="2.2" data-path="2.2-practical.html"><a href="2.2-practical.html"><i class="fa fa-check"></i><b>2.2</b> Practical</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="2.2-practical.html"><a href="2.2-practical.html#context"><i class="fa fa-check"></i><b>2.2.1</b> Context</a></li>
<li class="chapter" data-level="2.2.2" data-path="2.2-practical.html"><a href="2.2-practical.html#questions"><i class="fa fa-check"></i><b>2.2.2</b> Questions</a></li>
<li class="chapter" data-level="" data-path="2.2-practical.html"><a href="2.2-practical.html#example-of-output"><i class="fa fa-check"></i>Example of output</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="3-introduction-to-github-with-r.html"><a href="3-introduction-to-github-with-r.html"><i class="fa fa-check"></i><b>3</b> Introduction to github with R</a>
<ul>
<li class="chapter" data-level="3.1" data-path="3.1-lecture-2.html"><a href="3.1-lecture-2.html"><i class="fa fa-check"></i><b>3.1</b> Lecture</a></li>
<li class="chapter" data-level="3.2" data-path="3.2-git_practical.html"><a href="3.2-git_practical.html"><i class="fa fa-check"></i><b>3.2</b> Practical</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="3.2-git_practical.html"><a href="3.2-git_practical.html#context-1"><i class="fa fa-check"></i><b>3.2.1</b> Context</a></li>
<li class="chapter" data-level="3.2.2" data-path="3.2-git_practical.html"><a href="3.2-git_practical.html#information-of-the-data"><i class="fa fa-check"></i><b>3.2.2</b> Information of the data</a></li>
<li class="chapter" data-level="3.2.3" data-path="3.2-git_practical.html"><a href="3.2-git_practical.html#questions-1"><i class="fa fa-check"></i><b>3.2.3</b> Questions</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II Statistics</b></span></li>
<li class="chapter" data-level="4" data-path="4-generalized-linear-model-glm.html"><a href="4-generalized-linear-model-glm.html"><i class="fa fa-check"></i><b>4</b> Generalized linear model, <code>glm</code></a>
<ul>
<li class="chapter" data-level="4.1" data-path="4.1-lecture-3.html"><a href="4.1-lecture-3.html"><i class="fa fa-check"></i><b>4.1</b> Lecture</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="4.1-lecture-3.html"><a href="4.1-lecture-3.html#distributions"><i class="fa fa-check"></i><b>4.1.1</b> Distributions</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="4.2-practical-1.html"><a href="4.2-practical-1.html"><i class="fa fa-check"></i><b>4.2</b> Practical</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="4.2-practical-1.html"><a href="4.2-practical-1.html#logistic-regression"><i class="fa fa-check"></i><b>4.2.1</b> Logistic regression</a></li>
<li class="chapter" data-level="4.2.2" data-path="4.2-practical-1.html"><a href="4.2-practical-1.html#poisson-regression"><i class="fa fa-check"></i><b>4.2.2</b> Poisson regression</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="5-introduction-to-linear-mixed-models.html"><a href="5-introduction-to-linear-mixed-models.html"><i class="fa fa-check"></i><b>5</b> Introduction to linear mixed models</a>
<ul>
<li class="chapter" data-level="5.1" data-path="5.1-lecture-4.html"><a href="5.1-lecture-4.html"><i class="fa fa-check"></i><b>5.1</b> Lecture</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="5.1-lecture-4.html"><a href="5.1-lecture-4.html#testing-fixed-effects"><i class="fa fa-check"></i><b>5.1.1</b> Testing fixed effects</a></li>
<li class="chapter" data-level="5.1.2" data-path="5.1-lecture-4.html"><a href="5.1-lecture-4.html#shrinkage"><i class="fa fa-check"></i><b>5.1.2</b> Shrinkage</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="5.2-practical-2.html"><a href="5.2-practical-2.html"><i class="fa fa-check"></i><b>5.2</b> Practical</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="5.2-practical-2.html"><a href="5.2-practical-2.html#overview"><i class="fa fa-check"></i><b>5.2.1</b> Overview</a></li>
<li class="chapter" data-level="5.2.2" data-path="5.2-practical-2.html"><a href="5.2-practical-2.html#r-packages-needed"><i class="fa fa-check"></i><b>5.2.2</b> R packages needed</a></li>
<li class="chapter" data-level="5.2.3" data-path="5.2-practical-2.html"><a href="5.2-practical-2.html#the-superb-wild-unicorns-of-the-scottish-highlands"><i class="fa fa-check"></i><b>5.2.3</b> The superb wild unicorns of the Scottish Highlands</a></li>
<li class="chapter" data-level="5.2.4" data-path="5.2-practical-2.html"><a href="5.2-practical-2.html#do-unicorns-differ-in-aggressiveness-your-first-mixed-model"><i class="fa fa-check"></i><b>5.2.4</b> Do unicorns differ in aggressiveness? Your first mixed model</a></li>
<li class="chapter" data-level="5.2.5" data-path="5.2-practical-2.html"><a href="5.2-practical-2.html#do-unicorns-differ-in-aggressiveness-a-better-mixed-model"><i class="fa fa-check"></i><b>5.2.5</b> Do unicorns differ in aggressiveness? A better mixed model</a></li>
<li class="chapter" data-level="5.2.6" data-path="5.2-practical-2.html"><a href="5.2-practical-2.html#what-is-the-repeatability"><i class="fa fa-check"></i><b>5.2.6</b> What is the repeatability?</a></li>
<li class="chapter" data-level="5.2.7" data-path="5.2-practical-2.html"><a href="5.2-practical-2.html#a-quick-note-on-uncertainty"><i class="fa fa-check"></i><b>5.2.7</b> A quick note on uncertainty</a></li>
<li class="chapter" data-level="5.2.8" data-path="5.2-practical-2.html"><a href="5.2-practical-2.html#an-easy-way-to-mess-up-your-mixed-models"><i class="fa fa-check"></i><b>5.2.8</b> An easy way to mess up your mixed models</a></li>
<li class="chapter" data-level="5.2.9" data-path="5.2-practical-2.html"><a href="5.2-practical-2.html#happy-mixed-modelling"><i class="fa fa-check"></i><b>5.2.9</b> Happy mixed-modelling</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="6-introduction-to-glmm.html"><a href="6-introduction-to-glmm.html"><i class="fa fa-check"></i><b>6</b> Introduction to <code>GLMM</code></a>
<ul>
<li class="chapter" data-level="6.1" data-path="6.1-lecture-5.html"><a href="6.1-lecture-5.html"><i class="fa fa-check"></i><b>6.1</b> Lecture</a></li>
<li class="chapter" data-level="6.2" data-path="6.2-practical-3.html"><a href="6.2-practical-3.html"><i class="fa fa-check"></i><b>6.2</b> Practical</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="6.2-practical-3.html"><a href="6.2-practical-3.html#packages-and-functions"><i class="fa fa-check"></i><b>6.2.1</b> Packages and functions</a></li>
<li class="chapter" data-level="6.2.2" data-path="6.2-practical-3.html"><a href="6.2-practical-3.html#the-data-set"><i class="fa fa-check"></i><b>6.2.2</b> The data set</a></li>
<li class="chapter" data-level="6.2.3" data-path="6.2-practical-3.html"><a href="6.2-practical-3.html#specifying-fixed-and-random-effects"><i class="fa fa-check"></i><b>6.2.3</b> Specifying fixed and random Effects</a></li>
<li class="chapter" data-level="6.2.4" data-path="6.2-practical-3.html"><a href="6.2-practical-3.html#look-at-overall-patterns-in-data"><i class="fa fa-check"></i><b>6.2.4</b> Look at overall patterns in data</a></li>
<li class="chapter" data-level="6.2.5" data-path="6.2-practical-3.html"><a href="6.2-practical-3.html#choose-an-error-distribution"><i class="fa fa-check"></i><b>6.2.5</b> Choose an error distribution</a></li>
<li class="chapter" data-level="6.2.6" data-path="6.2-practical-3.html"><a href="6.2-practical-3.html#fitting-group-wise-glm"><i class="fa fa-check"></i><b>6.2.6</b> Fitting group-wise GLM</a></li>
<li class="chapter" data-level="6.2.7" data-path="6.2-practical-3.html"><a href="6.2-practical-3.html#fitting-and-evaluating-glmms"><i class="fa fa-check"></i><b>6.2.7</b> Fitting and evaluating GLMMs</a></li>
<li class="chapter" data-level="6.2.8" data-path="6.2-practical-3.html"><a href="6.2-practical-3.html#inference"><i class="fa fa-check"></i><b>6.2.8</b> Inference</a></li>
<li class="chapter" data-level="6.2.9" data-path="6.2-practical-3.html"><a href="6.2-practical-3.html#conclusions"><i class="fa fa-check"></i><b>6.2.9</b> Conclusions</a></li>
<li class="chapter" data-level="6.2.10" data-path="6.2-practical-3.html"><a href="6.2-practical-3.html#happy-generalized-mixed-modelling"><i class="fa fa-check"></i><b>6.2.10</b> Happy generalized mixed-modelling</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="7-introduction-to-bayesian-inference.html"><a href="7-introduction-to-bayesian-inference.html"><i class="fa fa-check"></i><b>7</b> Introduction to <code>Bayesian Inference</code></a>
<ul>
<li class="chapter" data-level="7.1" data-path="7.1-lecture-6.html"><a href="7.1-lecture-6.html"><i class="fa fa-check"></i><b>7.1</b> Lecture</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="7.1-lecture-6.html"><a href="7.1-lecture-6.html#bayes-theorem"><i class="fa fa-check"></i><b>7.1.1</b> Bayes’ theorem</a></li>
<li class="chapter" data-level="7.1.2" data-path="7.1-lecture-6.html"><a href="7.1-lecture-6.html#intro-to-mcmc"><i class="fa fa-check"></i><b>7.1.2</b> Intro to MCMC</a></li>
<li class="chapter" data-level="7.1.3" data-path="7.1-lecture-6.html"><a href="7.1-lecture-6.html#inferences-1"><i class="fa fa-check"></i><b>7.1.3</b> Inferences</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="7.2-practical-4.html"><a href="7.2-practical-4.html"><i class="fa fa-check"></i><b>7.2</b> Practical</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="7.2-practical-4.html"><a href="7.2-practical-4.html#r-packages-needed-1"><i class="fa fa-check"></i><b>7.2.1</b> R packages needed</a></li>
<li class="chapter" data-level="7.2.2" data-path="7.2-practical-4.html"><a href="7.2-practical-4.html#a-refresher-on-unicorn-ecology"><i class="fa fa-check"></i><b>7.2.2</b> A refresher on unicorn ecology</a></li>
<li class="chapter" data-level="7.2.3" data-path="7.2-practical-4.html"><a href="7.2-practical-4.html#mcmcglmm"><i class="fa fa-check"></i><b>7.2.3</b> MCMCglmm</a></li>
<li class="chapter" data-level="7.2.4" data-path="7.2-practical-4.html"><a href="7.2-practical-4.html#inferences-2"><i class="fa fa-check"></i><b>7.2.4</b> Inferences</a></li>
<li class="chapter" data-level="7.2.5" data-path="7.2-practical-4.html"><a href="7.2-practical-4.html#brms"><i class="fa fa-check"></i><b>7.2.5</b> brms</a></li>
<li class="chapter" data-level="7.2.6" data-path="7.2-practical-4.html"><a href="7.2-practical-4.html#inferences-3"><i class="fa fa-check"></i><b>7.2.6</b> Inferences</a></li>
<li class="chapter" data-level="7.2.7" data-path="7.2-practical-4.html"><a href="7.2-practical-4.html#happy-bayesian-stats"><i class="fa fa-check"></i><b>7.2.7</b> Happy Bayesian stats</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="8-multivariate-mixed-models.html"><a href="8-multivariate-mixed-models.html"><i class="fa fa-check"></i><b>8</b> Multivariate mixed models</a>
<ul>
<li class="chapter" data-level="8.1" data-path="8.1-lecture-7.html"><a href="8.1-lecture-7.html"><i class="fa fa-check"></i><b>8.1</b> Lecture</a></li>
<li class="chapter" data-level="8.2" data-path="8.2-practical-5.html"><a href="8.2-practical-5.html"><i class="fa fa-check"></i><b>8.2</b> Practical</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="8.2-practical-5.html"><a href="8.2-practical-5.html#r-packages-needed-2"><i class="fa fa-check"></i><b>8.2.1</b> R packages needed</a></li>
<li class="chapter" data-level="8.2.2" data-path="8.2-practical-5.html"><a href="8.2-practical-5.html#the-blue-dragon-of-the-east"><i class="fa fa-check"></i><b>8.2.2</b> The blue dragon of the East</a></li>
<li class="chapter" data-level="8.2.3" data-path="8.2-practical-5.html"><a href="8.2-practical-5.html#multiple-univariate-models"><i class="fa fa-check"></i><b>8.2.3</b> Multiple univariate models</a></li>
<li class="chapter" data-level="8.2.4" data-path="8.2-practical-5.html"><a href="8.2-practical-5.html#multivariate-approach"><i class="fa fa-check"></i><b>8.2.4</b> Multivariate approach</a></li>
<li class="chapter" data-level="8.2.5" data-path="8.2-practical-5.html"><a href="8.2-practical-5.html#happy-multivariate-models"><i class="fa fa-check"></i><b>8.2.5</b> Happy multivariate models</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="9-random-regression-and-character-state-approaches.html"><a href="9-random-regression-and-character-state-approaches.html"><i class="fa fa-check"></i><b>9</b> Random regression and character state approaches</a>
<ul>
<li class="chapter" data-level="9.1" data-path="9.1-lecture-8.html"><a href="9.1-lecture-8.html"><i class="fa fa-check"></i><b>9.1</b> Lecture</a></li>
<li class="chapter" data-level="9.2" data-path="9.2-practical-6.html"><a href="9.2-practical-6.html"><i class="fa fa-check"></i><b>9.2</b> Practical</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="9.2-practical-6.html"><a href="9.2-practical-6.html#r-packages-needed-3"><i class="fa fa-check"></i><b>9.2.1</b> R packages needed</a></li>
<li class="chapter" data-level="9.2.2" data-path="9.2-practical-6.html"><a href="9.2-practical-6.html#refresher-on-unicorn-aggression"><i class="fa fa-check"></i><b>9.2.2</b> Refresher on unicorn aggression</a></li>
<li class="chapter" data-level="9.2.3" data-path="9.2-practical-6.html"><a href="9.2-practical-6.html#random-regression"><i class="fa fa-check"></i><b>9.2.3</b> Random regression</a></li>
<li class="chapter" data-level="9.2.4" data-path="9.2-practical-6.html"><a href="9.2-practical-6.html#character-state-approach"><i class="fa fa-check"></i><b>9.2.4</b> Character-State approach</a></li>
<li class="chapter" data-level="9.2.5" data-path="9.2-practical-6.html"><a href="9.2-practical-6.html#from-random-regression-to-character-state"><i class="fa fa-check"></i><b>9.2.5</b> From random regression to character-state</a></li>
<li class="chapter" data-level="9.2.6" data-path="9.2-practical-6.html"><a href="9.2-practical-6.html#conclusions-2"><i class="fa fa-check"></i><b>9.2.6</b> Conclusions</a></li>
<li class="chapter" data-level="9.2.7" data-path="9.2-practical-6.html"><a href="9.2-practical-6.html#happy-multivariate-models-1"><i class="fa fa-check"></i><b>9.2.7</b> Happy multivariate models</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="10-beyond-p-0.html"><a href="10-beyond-p-0.html"><i class="fa fa-check"></i><b>10</b> Beyond <em>P &lt; 0.05</em></a></li>
<li class="part"><span><b>III Appendix</b></span></li>
<li class="chapter" data-level="" data-path="r.html"><a href="r.html"><i class="fa fa-check"></i>R</a></li>
<li class="chapter" data-level="" data-path="to-do-list.html"><a href="to-do-list.html"><i class="fa fa-check"></i>To do list</a>
<ul>
<li class="chapter" data-level="10.1" data-path="10.1-potential-structure.html"><a href="10.1-potential-structure.html"><i class="fa fa-check"></i><b>10.1</b> potential structure</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="_blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">BIO8940 Advanced stats and Open Science</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="lecture-4" class="section level2 hasAnchor" number="5.1">
<h2><span class="header-section-number">5.1</span> Lecture<a href="5.1-lecture-4.html#lecture-4" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="testing-fixed-effects" class="section level3 hasAnchor" number="5.1.1">
<h3><span class="header-section-number">5.1.1</span> Testing fixed effects<a href="5.1-lecture-4.html#testing-fixed-effects" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>making a note that LRT on fixed effects should not be the preferred method and more inportantly should eb done using ML and not REML Fitsee pinheiro &amp; Bates
2000 p76</p>
</div>
<div id="shrinkage" class="section level3 hasAnchor" number="5.1.2">
<h3><span class="header-section-number">5.1.2</span> Shrinkage<a href="5.1-lecture-4.html#shrinkage" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The following is an example of <strong>shrinkage</strong>, sometimes called <strong>partial-pooling</strong>, as it occurs in <strong>mixed effects models</strong>.
<!-- For some background, one can see the section of my document on mixed models [here](https://m-clark.github.io/mixed-models-with-R/random_slopes.html#comparison-to-many-regressions), and the document in general for an introduction to mixed models.  Part of the inspiration of this document comes from some of the visuals seen [here](https://www.tjmahr.com/plotting-partial-pooling-in-mixed-effects-models/). --></p>
<p>It is often the case that we have data such that observations are clustered in some way (e.g. repeated observations for units over time, students within schools, etc.). In mixed models, we obtain cluster-specific effects in addition to those for standard coefficients of our regression model. The former are called <strong>random effects</strong>, while the latter are typically referred to as <strong>fixed effects</strong> or <strong>population-average</strong> effects.</p>
<p>In other circumstances, we could ignore the clustering, and run a basic regression model. Unfortunately this assumes that all observations behave in the same way, i.e. that there are no cluster-specific effects, which would often be an untenable assumption. Another approach would be to run separate models for each cluster. However, aside from being problematic due to potentially small cluster sizes in common data settings, this ignores the fact that clusters are not isolated and potentially have some commonality.</p>
<p>Mixed models provide an alternative where we have cluster specific effects, but ‘borrow strength’ from the population-average effects. In general, this borrowing is more apparent for what would otherwise be more extreme clusters, and those that have less data. The following will demonstrate how shrinkage arises in different data situations.</p>
<div id="analysis" class="section level4 hasAnchor" number="5.1.2.1">
<h4><span class="header-section-number">5.1.2.1</span> Analysis<a href="5.1-lecture-4.html#analysis" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>For the following we run a basic mixed model with a random intercept and random slopes for a single predictor variable. There are a number of ways to write such models, and the following does so for a single cluster <span class="math inline">\(c\)</span> and observation <span class="math inline">\(i\)</span>. <span class="math inline">\(y\)</span> is a function of the covariate <span class="math inline">\(x\)</span>, and otherwise we have a basic linear regression model. In this formulation, the random effects for a given cluster (<span class="math inline">\(u_{* c}\)</span>) are added to each fixed effect (intercept <span class="math inline">\(b_0\)</span> and the effect of <span class="math inline">\(x\)</span>, <span class="math inline">\(b_1\)</span>). The random effects are multivariate normally distributed with some covariance. The per observation noise <span class="math inline">\(\sigma\)</span> is assumed constant across observations.</p>
<p><span class="math display">\[\mu_{ic} = (b_0 + \mathrm{u}_{0c})+ (b_1+\mathrm{u}_{1c}) * x_{ic}\]</span>
<span class="math display">\[\mathrm{u}_{0}, \mathrm{u}_{1} \sim \mathcal{N}(0, \Sigma)\]</span>
<span class="math display">\[y \sim \mathcal{N}(\mu, \sigma^2)\]</span></p>
<p>Such models are highly flexible and have many extensions, but this simple model is enough for our purposes.</p>
</div>
<div id="data" class="section level4 hasAnchor" number="5.1.2.2">
<h4><span class="header-section-number">5.1.2.2</span> Data<a href="5.1-lecture-4.html#data" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Default settings for data creation are as follows:</p>
<ul>
<li><code>obs_per_cluster</code> (observations per cluster) = 10</li>
<li><code>n_cluster</code> (number of clusters) = 100</li>
<li><code>intercept</code> (intercept) = 1</li>
<li><code>beta</code> (coefficient for x) = .5</li>
<li><code>sigma</code> (observation level standard deviation) = 1</li>
<li><code>sd_int</code> (standard deviation for intercept random effect)= .5</li>
<li><code>sd_slope</code> (standard deviation for x random effect)= .25</li>
<li><code>cor</code> (correlation of random effect) = 0</li>
<li><code>balanced</code> (fraction of overall sample size) = 1</li>
<li><code>seed</code> (for reproducibility) = 1024</li>
</ul>
<p>In this setting, <span class="math inline">\(x\)</span> is a standardized variable with mean zero and standard deviation of 1. Unless a fraction is provided for <code>balanced</code>, the <span class="math inline">\(N\)</span>, i.e. the total sample size, is equal to <code>n_cluster</code> * <code>obs_per_cluster</code>. The following is the function that will be used to create the data, which tries to follow the model depiction above. It requires the tidyverse package to work.</p>
</div>
<div id="run-the-baseline-model" class="section level4 hasAnchor" number="5.1.2.3">
<h4><span class="header-section-number">5.1.2.3</span> Run the baseline model<a href="5.1-lecture-4.html#run-the-baseline-model" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>We will use <strong>lme4</strong> to run the analysis. We can see that the model recovers the parameters fairly well, even with the default of only 1000 observations.</p>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb50-1"><a href="5.1-lecture-4.html#cb50-1" aria-hidden="true"></a>df &lt;-<span class="st"> </span><span class="kw">create_data</span>()</span>
<span id="cb50-2"><a href="5.1-lecture-4.html#cb50-2" aria-hidden="true"></a></span>
<span id="cb50-3"><a href="5.1-lecture-4.html#cb50-3" aria-hidden="true"></a><span class="kw">library</span>(lme4)</span>
<span id="cb50-4"><a href="5.1-lecture-4.html#cb50-4" aria-hidden="true"></a>mod &lt;-<span class="st"> </span><span class="kw">lmer</span>(y <span class="op">~</span><span class="st"> </span>x <span class="op">+</span><span class="st"> </span>(x <span class="op">|</span><span class="st"> </span>cluster), df)</span>
<span id="cb50-5"><a href="5.1-lecture-4.html#cb50-5" aria-hidden="true"></a><span class="kw">summary</span>(mod, <span class="dt">cor =</span> F)</span></code></pre></div>
<pre><code>## Linear mixed model fit by REML. t-tests use
##   Satterthwaite&#39;s method [lmerModLmerTest]
## Formula: y ~ x + (x | cluster)
##    Data: df
## 
## REML criterion at convergence: 3012.2
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -2.9392 -0.6352 -0.0061  0.6156  2.8721 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev. Corr
##  cluster  (Intercept) 0.29138  0.5398       
##           x           0.05986  0.2447   0.30
##  Residual             0.99244  0.9962       
## Number of obs: 1000, groups:  cluster, 100
## 
## Fixed effects:
##             Estimate Std. Error       df t value Pr(&gt;|t|)
## (Intercept)  0.93647    0.06282 98.38512   14.91   &lt;2e-16
## x            0.54405    0.04270 91.69469   12.74   &lt;2e-16
##                
## (Intercept) ***
## x           ***
## ---
## Signif. codes:  
## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<!-- put data creating and plotting fucntion in a file to be sourced.
start with variance in intercept only then variance in both slope and intercept, then unbalanced sample -->
</div>
<div id="visualize-the-baseline-model" class="section level4 hasAnchor" number="5.1.2.4">
<h4><span class="header-section-number">5.1.2.4</span> Visualize the baseline model<a href="5.1-lecture-4.html#visualize-the-baseline-model" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Now it is time to visualize the results. We will use <strong>gganimate</strong> to bring the shrinkage into focus. We start with the estimates that would be obtained by a ‘regression-by-cluster’ approach or a linear regression for each cluster. The movement shown will be of those cluster-specific estimates toward the mixed model estimates. On the x axis is the estimate for the intercepts, on the y axis are the estimated slopes of the <code>x</code> covariate.</p>
<p><img src="images/shrinkage_1.gif" /><!-- --></p>
<p>We see more clearly what the mixed model does. The general result is that cluster-specific effects (lighter color) are shrunk back toward the population-average effects (the ‘black hole’), as the imposed normal distribution for the random effects makes the extreme values less probable. Likewise, those more extreme cluster-specific effects, some of which are not displayed as they are so far from the population average, will generally have the most shrinkage imposed. In terms of prediction, it is akin to introducing bias for the cluster specific effects while lowering variance for prediction of new data, and allows us to make predictions on new categories we have not previously seen - we just assume an ‘average’ cluster effect, i.e. a random effect of 0.</p>
</div>
<div id="summary" class="section level4 hasAnchor" number="5.1.2.5">
<h4><span class="header-section-number">5.1.2.5</span> Summary<a href="5.1-lecture-4.html#summary" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Mixed models incorporate some amount of shrinkage for cluster-specific effects. Data nuances will determine the relative amount of ‘strength borrowed’, but in general, such models provide a good way for the data to speak for itself when it should, and reflect an ‘average’ when there is little information. An additional benefit is that thinking about models in this way can be seen as a precursor to Bayesian approaches, which can allow for even more flexibility via priors, and more control over how shrinkage is added to the model.</p>
<!--
#################################################################################################################
-->
</div>
</div>
</div>
<script src="js/solution.js"></script>
            </section>

          </div>
        </div>
      </div>
<a href="5-introduction-to-linear-mixed-models.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="5.2-practical-2.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": false,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/BIO8940-uOttawa/class_book/02_02-intro_lmm.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["BIO8940_book.pdf", "BIO8940_book.epub", "BIO8940_book.mobi"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
