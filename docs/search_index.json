[["index.html", "BIO8940 Advanced stats and Open Science Work in Progress Note", " BIO8940 Advanced stats and Open Science Work in Progress Julien Martin 17-01-2024 Note Work in progress. New chapters are going to appears regularly meaning that if you download the pdf it might be incomplete by the time we do the practical in class. if you see a dragon section is in severe development Figure 0.1: Dream pet dragon "],["1-introduction-to-open-science.html", "1 Introduction to open Science ", " 1 Introduction to open Science "],["1.1-why-do-we-need-it.html", "1.1 Why do we need it?", " 1.1 Why do we need it? "],["1.2-lecture.html", "1.2 Lecture", " 1.2 Lecture Figure 1.1: Dream pet dragon "],["1.3-what-it-is.html", "1.3 What it is?", " 1.3 What it is? "],["1.4-reproducible-code-and-analysis.html", "1.4 Reproducible code and analysis", " 1.4 Reproducible code and analysis "],["2-introduction-to-rmarkdown.html", "2 Introduction to Rmarkdown ", " 2 Introduction to Rmarkdown "],["2.1-lecture-1.html", "2.1 Lecture", " 2.1 Lecture Figure 2.1: Dream pet dragon "],["2.2-practical.html", "2.2 Practical", " 2.2 Practical We will create a new Rmarkdown document and edit it using basic R and Rmarkdown functions. 2.2.1 Context We will use the awesome palmerpenguins dataset üêß to explore and visualize data. These data have been collected and shared by Dr.¬†Kristen Gorman and Palmer Station, Antarctica LTER. The package was built by Drs Allison Horst and Alison Hill, check out the official website. The package palmerpenguins has two datasets: penguins_raw has the raw data of penguins observations (see ?penguins_raw for more info) penguins is a simplified version of the raw data (see ?penguins for more info) For this exercise, we‚Äôre gonna use the penguins dataset. library(palmerpenguins) head(penguins) ## # A tibble: 6 √ó 8 ## species island bill_length_mm bill_depth_mm ## &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Adelie Torgersen 39.1 18.7 ## 2 Adelie Torgersen 39.5 17.4 ## 3 Adelie Torgersen 40.3 18 ## 4 Adelie Torgersen NA NA ## 5 Adelie Torgersen 36.7 19.3 ## 6 Adelie Torgersen 39.3 20.6 ## # ‚Ä¶ with 4 more variables: flipper_length_mm &lt;int&gt;, ## # body_mass_g &lt;int&gt;, sex &lt;fct&gt;, year &lt;int&gt; 2.2.2 Questions 1) Install the package palmerpenguins. install.packages(&quot;palmerpenguins&quot;) 2) Create a new R Markdown document, name it and save it. Delete everything after line 12. Add a new section title, simple text and text in bold font. Compile (‚ÄúKnit‚Äù). 3) Add a chunk in which you load the palmerpenguins. The corresponding line of code should be hidden in the output. Load also the tidyverse suite of packages. Modify the defaults to suppress all messages. ```{r, echo = FALSE, message = FALSE} library(palmerpenguins) library(tidyverse) ``` 4) Add another chunk in which you build a table with the 10 first rows of the dataset. ```{r} penguins %&gt;% slice(1:10) %&gt;% knitr::kable() ``` 5) In a new section, display how many individuals, penguins species and islands we have in the dataset. This info should appear directly in the text, you need to use inline code üòÑ. Calculate the mean of the (numeric) traits measured on the penguins. ## Numerical exploration There are `r nrow(penguins)` penguins in the dataset, and `r length(unique(penguins$species))` different species. The data were collected in `r length(unique(penguins$island))` islands of the Palmer archipelago in Antarctica. The mean of all traits that were measured on the penguins are: ```{r echo = FALSE} penguins %&gt;% group_by(species) %&gt;% summarize(across(where(is.numeric), mean, na.rm = TRUE)) ``` 6) In another section, entitled ‚ÄòGraphical exploration‚Äô, build a figure with 3 superimposed histograms, each one corresponding to the body mass of a species. ## Graphical exploration A histogram of body mass per species: ```{r, fig.cap = &quot;Distribution of body mass by species of penguins&quot;} ggplot(data = penguins) + aes(x = body_mass_g) + geom_histogram(aes(fill = species), alpha = 0.5, position = &quot;identity&quot;) + scale_fill_manual(values = c(&quot;darkorange&quot;,&quot;purple&quot;,&quot;cyan4&quot;)) + theme_minimal() + labs(x = &quot;Body mass (g)&quot;, y = &quot;Frequency&quot;, title = &quot;Penguin body mass&quot;) ``` 7) In another section, entitled Linear regression, fit a model of bill length as a function of body size (flipper length), body mass and sex. Obtain the output and graphically evaluate the assumptions of the model. As reminder here is how you fit a linear regression. ```{r} model &lt;- lm(Y ~ X1 + X2, data = data) summary(model) plot(model) ``` ## Linear regression And here is a nice model with graphical output ```{r, fig.cap = &quot;Checking assumptions of the model&quot;} m1 &lt;- lm(bill_length_mm ~ flipper_length_mm + body_mass_g + sex, data = penguins) summary(m1) par(mfrow= c(2,2)) plot(m1) ``` 8) Add references manually or using citr in RStudio. Pick a recent publication from the researcher who shared the data, Dr Kristen Gorman. Import this publication in your favorite references manager (we use Zotero, no hard feeling), and create a bibtex reference that you will add to to the file mabiblio.bib. Add bibliography: mabiblio.bib at the beginning of your R Markdown document (YAML). Cite the reference iin the text using either typing the reference manually or using citr. To use citr, instal it first; if everything goes well, you should see it in the pulldown menu Addins üí™. Then simply use Insert citations in the pull-down menu Addins. Compile. 9) Change the default citation format (Chicago style) into the The American Naturalist format. It can be found here https://www.zotero.org/styles. To do soo, add csl: the-american-naturalist.csl in the YAML. 10) Build your report in html, pdf and docx format. üéâ Example of output You can see an example of the Rmarkdown source file and pdf output Figure 2.2: Happy coding "],["3-introduction-to-github-with-r.html", "3 Introduction to github with R ", " 3 Introduction to github with R "],["3.1-lecture-2.html", "3.1 Lecture", " 3.1 Lecture Figure 3.1: Dream pet dragon "],["3.2-git_practical.html", "3.2 Practical", " 3.2 Practical 3.2.1 Context We will configure Rstudio to work with our github account, then create a new project and start using github. To have some data I suggest to use the awesome palmerpenguins dataset üêß. 3.2.2 Information of the data These data have been collected and shared by Dr.¬†Kristen Gorman and Palmer Station, Antarctica LTER. The package was built by Drs Allison Horst and Alison Hill, check out the official website. The package palmerpenguins has two datasets. library(palmerpenguins) The dataset penguins is a simplified version of the raw data; see ?penguins for more info: head(penguins) ## # A tibble: 6 √ó 8 ## species island bill_length_mm bill_depth_mm ## &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Adelie Torgersen 39.1 18.7 ## 2 Adelie Torgersen 39.5 17.4 ## 3 Adelie Torgersen 40.3 18 ## 4 Adelie Torgersen NA NA ## 5 Adelie Torgersen 36.7 19.3 ## 6 Adelie Torgersen 39.3 20.6 ## # ‚Ä¶ with 4 more variables: flipper_length_mm &lt;int&gt;, ## # body_mass_g &lt;int&gt;, sex &lt;fct&gt;, year &lt;int&gt; The other dataset penguins_raw has the raw data; see ?penguins_raw for more info: head(penguins_raw) ## # A tibble: 6 √ó 17 ## studyName `Sample Number` Species Region Island Stage ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 PAL0708 1 Adelie Pen‚Ä¶ Anvers Torge‚Ä¶ Adul‚Ä¶ ## 2 PAL0708 2 Adelie Pen‚Ä¶ Anvers Torge‚Ä¶ Adul‚Ä¶ ## 3 PAL0708 3 Adelie Pen‚Ä¶ Anvers Torge‚Ä¶ Adul‚Ä¶ ## 4 PAL0708 4 Adelie Pen‚Ä¶ Anvers Torge‚Ä¶ Adul‚Ä¶ ## 5 PAL0708 5 Adelie Pen‚Ä¶ Anvers Torge‚Ä¶ Adul‚Ä¶ ## 6 PAL0708 6 Adelie Pen‚Ä¶ Anvers Torge‚Ä¶ Adul‚Ä¶ ## # ‚Ä¶ with 11 more variables: `Individual ID` &lt;chr&gt;, ## # `Clutch Completion` &lt;chr&gt;, `Date Egg` &lt;date&gt;, ## # `Culmen Length (mm)` &lt;dbl&gt;, `Culmen Depth (mm)` &lt;dbl&gt;, ## # `Flipper Length (mm)` &lt;dbl&gt;, `Body Mass (g)` &lt;dbl&gt;, ## # Sex &lt;chr&gt;, `Delta 15 N (o/oo)` &lt;dbl&gt;, ## # `Delta 13 C (o/oo)` &lt;dbl&gt;, Comments &lt;chr&gt; For this exercise, we‚Äôre gonna use the penguins dataset. 3.2.3 Questions 1) Create a github account if not done yet. 2) Configure Rstudio with your github account using the usethis package. usethis::git_sitrep() usethis::use_git_config( user.name = &quot;your_username&quot;, user.email = &quot;your_email@address.com&quot; ) 3) Create and Store your GITHUB Personal Authorisation Token usethis::create_github_token() gitcreds::gitcreds_set() 4) Create a new R Markdown project, initialize it for git, and create a new git repository #create R project usethis::use_git() #restart R usethis::use_github() usethis::git_vaccinate() 5) Create a new Rmarkdown document, in your project. Then save the file and stage it. 6) Create a new commit including the new file and push it to github (Check on github that it works). 7) Edit the file. Delete everything after line 12. Add a new section title, simple text and text in bold font. Then knit and compile. 8) Make a new commit (with a meaningful message), and push to github. 9) Create a new branch, and add a new section to the rmarkdown file in this branch. Whatever you want. I would suggest a graph of the data. 10) Create a commit and push it to the branch. 11) On github, create a pull request to merge the 2 different branches. 12) Check and accept the pull request to merge the 2 branches. You have successfully used all the essential tools of git üéâ . You are really to explore üïµ and discover its power üí™ Figure 3.2: Happy git(hub)-ing "],["4-generalized-linear-model-glm.html", "4 Generalized linear model, glm ", " 4 Generalized linear model, glm "],["4.1-lecture-3.html", "4.1 Lecture", " 4.1 Lecture Figure 4.1: Dream pet dragon m1 &lt;- glm(fish ~ french_captain, data = dads_joke, family = poisson) 4.1.1 Distributions 4.1.1.1 Continuous linear Gaussian 4.1.1.2 Count data poisson negative binomial quasi-poisson generalized poisson conway-maxwell poisson 4.1.1.3 censored distribution 4.1.1.4 zero-inflated / hurdle distribution zero-inflated/zero-truncated poisson censored poisson 4.1.1.5 zero-truncated distribution 4.1.1.6 zero-one-inflated distribution see https://cran.r-project.org/web/packages/brms/vignettes/brms_families.html see alo MCMCglmm coursenotes for help on description and to add some plots about those distribution "],["4.2-practical-1.html", "4.2 Practical", " 4.2 Practical ::: {.infobox .warning data-latex = ‚Äúwarning‚Äù} This section need to be severely updated ::: 4.2.1 Logistic regression library(tidyverse) library(DHARMa) library(performance) mouflon &lt;- read.csv(&quot;data/mouflon.csv&quot;) mouflonc &lt;- mouflon[order(mouflon$age),] mouflonc$reproduction &lt;- ifelse(mouflonc$age &lt; 13, mouflonc$reproduction, 0) mouflonc$reproduction &lt;- ifelse(mouflonc$age &gt; 4, mouflonc$reproduction, 1) plot(reproduction ~ age, mouflonc) plot(jitter(reproduction) ~ jitter(age), mouflonc) bubble &lt;- data.frame(age = rep(2:16, 2), reproduction = rep(0:1, each = 15), size = c(table(mouflonc$age, mouflonc$reproduction))) bubble$size &lt;- ifelse(bubble$size == 0 , NA, bubble$size) ggplot(data = bubble, aes(x = age, y = reproduction))+ geom_point(aes(size = size*10)) ## Warning: Removed 7 rows containing missing values (`geom_point()`). m1 &lt;- glm(reproduction ~ age, data = mouflonc, family = binomial) summary(m1) ## ## Call: ## glm(formula = reproduction ~ age, family = binomial, data = mouflonc) ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 3.19921 0.25417 12.59 &lt;2e-16 *** ## age -0.36685 0.03287 -11.16 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 928.86 on 715 degrees of freedom ## Residual deviance: 767.51 on 714 degrees of freedom ## (4 observations deleted due to missingness) ## AIC: 771.51 ## ## Number of Fisher Scoring iterations: 4 simulationOutput &lt;- simulateResiduals(m1) plot(simulationOutput) plotting the model prediction on the link (latent) scale mouflonc$logit_ypred &lt;- 3.19921 -0.36685 * mouflonc$age plot(logit_ypred ~ jitter(age), mouflonc) points(mouflonc$age, mouflonc$logit_ypred, col=&quot;red&quot;, type = &quot;l&quot;, lwd = 2) plotting on the observed scale mouflonc$ypred &lt;- exp(mouflonc$logit_ypred) / (1 + exp(mouflonc$logit_ypred)) # inverse of logit plot(reproduction ~ jitter(age), mouflonc) points(mouflonc$age, mouflonc$ypred, col=&quot;red&quot;, type = &quot;l&quot;, lwd = 2) Enfin, pour se simplifier la vie, il est aussi possible de r√©cup√©rer les valeurs pr√©dites de y directement plot(x,y) myreg &lt;- glm(y~x, family=binomial(link=logit)) ypredit &lt;- myreg$fitted o=order(x) points(x[o],ypredit[o], col=&quot;red&quot;, type=&quot;l&quot;, lwd=2) m2 &lt;- glm(reproduction ~ age + mass_sept + as.factor(sex_lamb) + mass_gain + density + temp, data = mouflon, family = binomial) summary(m2) ## ## Call: ## glm(formula = reproduction ~ age + mass_sept + as.factor(sex_lamb) + ## mass_gain + density + temp, family = binomial, data = mouflon) ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 1.622007 1.943242 0.835 0.403892 ## age -0.148567 0.033597 -4.422 9.78e-06 *** ## mass_sept 0.029878 0.016815 1.777 0.075590 . ## as.factor(sex_lamb)1 -0.428169 0.166156 -2.577 0.009969 ** ## mass_gain -0.094828 0.026516 -3.576 0.000348 *** ## density -0.018132 0.003518 -5.154 2.55e-07 *** ## temp 0.037244 0.138712 0.269 0.788313 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 916.06 on 674 degrees of freedom ## Residual deviance: 845.82 on 668 degrees of freedom ## (45 observations deleted due to missingness) ## AIC: 859.82 ## ## Number of Fisher Scoring iterations: 4 check_model(m2) simulationOutput &lt;- simulateResiduals(m2) plot(simulationOutput) 4.2.1.1 previous offspring sex effect pred.data &lt;- data.frame( age = mean(mouflon$age), mass_sept = mean(mouflon$mass_sept), sex_lamb = c(0,1), mass_gain = mean(mouflon$mass_gain), density = mean(mouflon$density), temp = mean(mouflon$temp, na.rm =TRUE)) predict(m2, newdata = pred.data) ## 1 2 ## 0.6225895 0.1944205 4.2.2 Poisson regression data on galapagos islands species richness model of total number of species model of proportion of native model of density of species Fit 3 models - model of total number of species - model of proportion of endemics to total - model of species density hist(rpois(10000,3)) # gala &lt;- read.delim2(&quot;data/gala.txt&quot;) plot(Species ~ Area, gala) plot(Species ~ log(Area), gala) hist(gala$Species) modpl &lt;- glm(Species ~ Area + Elevation + Nearest, family=poisson, gala) res &lt;- simulateResiduals(modpl) testDispersion(res) ## ## DHARMa nonparametric dispersion test via sd of residuals fitted vs. simulated ## ## data: simulationOutput ## dispersion = 110.32, p-value &lt; 2.2e-16 ## alternative hypothesis: two.sided testZeroInflation(res) ## ## DHARMa zero-inflation test via comparison to expected zeros with simulation under H0 = fitted model ## ## data: simulationOutput ## ratioObsSim = NaN, p-value = 1 ## alternative hypothesis: two.sided mean(gala$Species) ## [1] 85.23333 var(gala$Species) ## [1] 13140.74 hist(rpois(nrow(gala),mean(gala$Species))) plot(modpl) ## Warning in sqrt(crit * p * (1 - hh)/hh): NaNs produced ## Warning in sqrt(crit * p * (1 - hh)/hh): NaNs produced "],["5-introduction-to-linear-mixed-models.html", "5 Introduction to linear mixed models ", " 5 Introduction to linear mixed models "],["5.1-lecture-4.html", "5.1 Lecture", " 5.1 Lecture 5.1.1 Testing fixed effects making a note that LRT on fixed effects should not be the preferred method and more inportantly should eb done using ML and not REML Fitsee pinheiro &amp; Bates 2000 p76 5.1.2 Shrinkage The following is an example of shrinkage, sometimes called partial-pooling, as it occurs in mixed effects models. It is often the case that we have data such that observations are clustered in some way (e.g.¬†repeated observations for units over time, students within schools, etc.). In mixed models, we obtain cluster-specific effects in addition to those for standard coefficients of our regression model. The former are called random effects, while the latter are typically referred to as fixed effects or population-average effects. In other circumstances, we could ignore the clustering, and run a basic regression model. Unfortunately this assumes that all observations behave in the same way, i.e.¬†that there are no cluster-specific effects, which would often be an untenable assumption. Another approach would be to run separate models for each cluster. However, aside from being problematic due to potentially small cluster sizes in common data settings, this ignores the fact that clusters are not isolated and potentially have some commonality. Mixed models provide an alternative where we have cluster specific effects, but ‚Äòborrow strength‚Äô from the population-average effects. In general, this borrowing is more apparent for what would otherwise be more extreme clusters, and those that have less data. The following will demonstrate how shrinkage arises in different data situations. 5.1.2.1 Analysis For the following we run a basic mixed model with a random intercept and random slopes for a single predictor variable. There are a number of ways to write such models, and the following does so for a single cluster \\(c\\) and observation \\(i\\). \\(y\\) is a function of the covariate \\(x\\), and otherwise we have a basic linear regression model. In this formulation, the random effects for a given cluster (\\(u_{* c}\\)) are added to each fixed effect (intercept \\(b_0\\) and the effect of \\(x\\), \\(b_1\\)). The random effects are multivariate normally distributed with some covariance. The per observation noise \\(\\sigma\\) is assumed constant across observations. \\[\\mu_{ic} = (b_0 + \\mathrm{u}_{0c})+ (b_1+\\mathrm{u}_{1c}) * x_{ic}\\] \\[\\mathrm{u}_{0}, \\mathrm{u}_{1} \\sim \\mathcal{N}(0, \\Sigma)\\] \\[y \\sim \\mathcal{N}(\\mu, \\sigma^2)\\] Such models are highly flexible and have many extensions, but this simple model is enough for our purposes. 5.1.2.2 Data Default settings for data creation are as follows: obs_per_cluster (observations per cluster) = 10 n_cluster (number of clusters) = 100 intercept (intercept) = 1 beta (coefficient for x) = .5 sigma (observation level standard deviation) = 1 sd_int (standard deviation for intercept random effect)= .5 sd_slope (standard deviation for x random effect)= .25 cor (correlation of random effect) = 0 balanced (fraction of overall sample size) = 1 seed (for reproducibility) = 1024 In this setting, \\(x\\) is a standardized variable with mean zero and standard deviation of 1. Unless a fraction is provided for balanced, the \\(N\\), i.e.¬†the total sample size, is equal to n_cluster * obs_per_cluster. The following is the function that will be used to create the data, which tries to follow the model depiction above. It requires the tidyverse package to work. 5.1.2.3 Run the baseline model We will use lme4 to run the analysis. We can see that the model recovers the parameters fairly well, even with the default of only 1000 observations. df &lt;- create_data() library(lme4) mod &lt;- lmer(y ~ x + (x | cluster), df) summary(mod, cor = F) ## Linear mixed model fit by REML. t-tests use ## Satterthwaite&#39;s method [lmerModLmerTest] ## Formula: y ~ x + (x | cluster) ## Data: df ## ## REML criterion at convergence: 3012.2 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.9392 -0.6352 -0.0061 0.6156 2.8721 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## cluster (Intercept) 0.29138 0.5398 ## x 0.05986 0.2447 0.30 ## Residual 0.99244 0.9962 ## Number of obs: 1000, groups: cluster, 100 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 0.93647 0.06282 98.38512 14.91 &lt;2e-16 ## x 0.54405 0.04270 91.69469 12.74 &lt;2e-16 ## ## (Intercept) *** ## x *** ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 5.1.2.4 Visualize the baseline model Now it is time to visualize the results. We will use gganimate to bring the shrinkage into focus. We start with the estimates that would be obtained by a ‚Äòregression-by-cluster‚Äô approach or a linear regression for each cluster. The movement shown will be of those cluster-specific estimates toward the mixed model estimates. On the x axis is the estimate for the intercepts, on the y axis are the estimated slopes of the x covariate. We see more clearly what the mixed model does. The general result is that cluster-specific effects (lighter color) are shrunk back toward the population-average effects (the ‚Äòblack hole‚Äô), as the imposed normal distribution for the random effects makes the extreme values less probable. Likewise, those more extreme cluster-specific effects, some of which are not displayed as they are so far from the population average, will generally have the most shrinkage imposed. In terms of prediction, it is akin to introducing bias for the cluster specific effects while lowering variance for prediction of new data, and allows us to make predictions on new categories we have not previously seen - we just assume an ‚Äòaverage‚Äô cluster effect, i.e.¬†a random effect of 0. 5.1.2.5 Summary Mixed models incorporate some amount of shrinkage for cluster-specific effects. Data nuances will determine the relative amount of ‚Äòstrength borrowed‚Äô, but in general, such models provide a good way for the data to speak for itself when it should, and reflect an ‚Äòaverage‚Äô when there is little information. An additional benefit is that thinking about models in this way can be seen as a precursor to Bayesian approaches, which can allow for even more flexibility via priors, and more control over how shrinkage is added to the model. "],["5.2-practical-2.html", "5.2 Practical", " 5.2 Practical 5.2.1 Overview This practical is intended to get you started fitting some simple mixed models with so called random intercepts. The tutorial is derived from one that accompanied the paper (Houslay and Wilson 2017), ‚ÄúAvoiding the misuse of BLUP in behavioral ecology‚Äù. Here, you will be working through a simplified version in which I have taken more time to cover the basic mixed models and don‚Äôt cover multivariate models which were really the main point of that paper. So if you find this material interesting don‚Äôt worry we will go through a more advanced version of the original paper on multivariate models in chapter XX. The original version will be worth a work through to help you break into multivariate mixed models anyway! Here we will: Learn how to fit - and interpret the results of - a simple univariate mixed effect model See how to add fixed and random effects to your model, and to test their significance in the normal frequentists sense We are going to use the üì¶ lme4 (Bates et al. 2021) which is widely used and great for simple mixed models. However, since, for philosophical reasons, lme4 does not provide any p-values for either fixed or random effects, we are going to use the üì¶ lmerTest (Kuznetsova et al. 2020), which add a bunch a nice goodies to lme4 For slightly more complex models, including multivariate ones, generalised models, and random effects of things like shared space, pedigree, phylogeny I tend to use different üì¶ like MCMCglmm (Hadfield 2010) (which is Bayesian, look at Jarrod Hadfield‚Äôs excellent course notes (Hadfield 2022)) or ASReml-R (Butler 2021) (which is likelihood based/frequentist but sadly is not free). 5.2.2 R packages needed First we load required libraries library(lmerTest) library(performance) library(tidyverse) library(rptR) 5.2.3 The superb wild unicorns of the Scottish Highlands Unicorns, a legendary animal and also symbol or Scotland, are frequently described as extremely wild woodland creature but also a symbol of purity and grace. Here is one of most accurate representation of the lengendary animal. Figure 5.1: The superb unicorn of the Scottish Highlands Despite their image of purity and grace, unicorns (Unicornus legendaricus) are raging fighter when it comes to compete for the best sweets you can find at the bottom of rainbows (unicorn favourite source of food). We want to know: If aggressiveness differs among individuals If aggressive behaviour is plastic (change with the environment) If aggressive behaviour depends on body condition of focal animal With respect to plasticity, we will focus on rival size as an ‚Äòenvironment‚Äô. Common sense, and animal-contest theory, suggest a small animal would be wise not to escalate an aggressive contest against a larger, stronger rival. However, there are reports in the legendary beasty literature that they get more aggressive as rival size increases. Those reports are based on small sample sizes and uncontrolled field observations by foreigners Munro baggers enjoying their whisky after a long day in the hills. 5.2.3.1 Experimental design Here, we have measured aggression in a population of wild unicorns. We brought some (n=80) individual into the lab, tagged them so they were individually identifiable, then repeatedly observed their aggression when presented with model ‚Äòintruders‚Äô (animal care committe approved). There were three models; one of average unicorn (calculated as the population mean body length), one that was build to be 1 standard deviation below the population mean, and one that was 1 standard deviation above. Data were collected on all individuals in two block of lab work. Within each block, each animal was tested 3 times, once against an ‚Äòintruder‚Äô of each size. The test order in which each animal experienced the three instruder sizes was randomised in each block. The body size of all focal individuals was measured at the beginning of each block so we know that too (and have two separate measures per individual). 5.2.3.2 looking at the data Let‚Äôs load the data file unicorns_aggression.csv in a R object named unicorns and make sure we understand what it contains unicorns &lt;- read.csv(&quot;data/unicorns_aggression.csv&quot;) You can use summary(unicorns) to get an overview of the data and/or str(unicorns) to see the structure in the first few lines. This data frame has 6 variables: str(unicorns) ## &#39;data.frame&#39;: 480 obs. of 6 variables: ## $ ID : chr &quot;ID_1&quot; &quot;ID_1&quot; &quot;ID_1&quot; &quot;ID_1&quot; ... ## $ block : num -0.5 -0.5 -0.5 0.5 0.5 0.5 -0.5 -0.5 -0.5 0.5 ... ## $ assay_rep : int 1 2 3 1 2 3 1 2 3 1 ... ## $ opp_size : int -1 1 0 0 1 -1 1 -1 0 1 ... ## $ aggression: num 7.02 10.67 10.22 8.95 10.51 ... ## $ body_size : num 206 206 206 207 207 ... summary(unicorns) ## ID block assay_rep opp_size aggression body_size ## Length:480 Min. :-0.5 Min. :1 Min. :-1 Min. : 5.900 Min. :192.0 ## Class :character 1st Qu.:-0.5 1st Qu.:1 1st Qu.:-1 1st Qu.: 8.158 1st Qu.:229.7 ## Mode :character Median : 0.0 Median :2 Median : 0 Median : 8.950 Median :250.0 ## Mean : 0.0 Mean :2 Mean : 0 Mean : 9.002 Mean :252.5 ## 3rd Qu.: 0.5 3rd Qu.:3 3rd Qu.: 1 3rd Qu.: 9.822 3rd Qu.:272.0 ## Max. : 0.5 Max. :3 Max. : 1 Max. :12.170 Max. :345.2 So the different columns in the data set are: Individual ID Experimental Block, denoted for now as a continuous variable with possible values of -0.5 (first block) or +0.5 (second block) Individual body_size, as measured at the start of each block in kg The repeat number for each behavioural test, assay_rep Opponent size (opp_size), in standard deviations from the mean (i.e., -1,0,1) aggression, our behavioural trait, measured 6 times in total per individual (2 blocks of 3 tests) maybe add something on how to look at data structure closely using tables 5.2.4 Do unicorns differ in aggressiveness? Your first mixed model Fit a first mixed model with lmer that have only individual identity as a random effect and only a population mean. Why, so simple? Because we simply want to partition variance around the mean into a component that among-individual variance and one that is within-individual variance. ::: {.infobox .important data-latex = ‚Äúimportant‚Äù} We are going to use the function lmer() from the üì¶ lme4 package. The notation of the model formula is similar as the notation for a linear model but now we also add random effects using the notation (1 | r_effect) which indicates that we want to fit the variable r_effect as a random effect for the intercept. Thus, in lmer notation a simploe model would be : lmer(Y ~ x1 + x2 + (1 | r_effect), data = data) ::: A sensible researcher would probably take the time to do some exploratory data plots here. So let‚Äôs write a mixed model. This one is going to have no fixed effects except the mean, and just one random effect - individual identity. m_1 &lt;- lmer(aggression ~ 1 + (1 | ID), data = unicorns) ## boundary (singular) fit: see ?isSingular There is a warning‚Ä¶ something about ‚Äúsingularities‚Äù. Ignore that for a moment. Now you need to get the model output. By that I just mean use summary(model_name). summary(m_1) ## Linear mixed model fit by REML. t-tests use ## Satterthwaite&#39;s method [lmerModLmerTest] ## Formula: aggression ~ 1 + (1 | ID) ## Data: unicorns ## ## REML criterion at convergence: 1503.7 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.68530 -0.73094 -0.04486 0.71048 2.74276 ## ## Random effects: ## Groups Name Variance Std.Dev. ## ID (Intercept) 0.000 0.000 ## Residual 1.334 1.155 ## Number of obs: 480, groups: ID, 80 ## ## Fixed effects: ## Estimate Std. Error df t value ## (Intercept) 9.00181 0.05272 479.00000 170.7 ## Pr(&gt;|t|) ## (Intercept) &lt;2e-16 *** ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## optimizer (nloptwrap) convergence code: 0 (OK) ## boundary (singular) fit: see ?isSingular In the summary you will find a table of fixed effects. Fixed effects: Estimate Std. Error df t value Pr(&gt;|t|) (Intercept) 9.00181 0.05272 479.00000 170.7 &lt;2e-16 *** The intercept (here the mean) is about 9 and is significantly &gt;0 - fine, but not very interesting to us. You will also find a random effect table that contains estimates of the among individual (ID) and residual variances. Random effects: Groups Name Variance Std.Dev. ID (Intercept) 0.000 0.000 Residual 1.334 1.155 Number of obs: 480, groups: ID, 80 The among individual (ID) is estimated as zero. In fact this is what the cryptic warning was about: in most situations the idea of a random effect explaining less than zero variance is not sensible (strangely there are exception!). So by default the variance estimates are constrained to lie in positive parameter space. Here in trying to find the maximum likelihood solution for among-individual variance, our model has run up against this constraint. 5.2.4.1 Testing for random effects We can test the statistical significance of the random effect using the ranova() command in lmerTest. This function is actually doing a likelihood ratio test (LRT) of the random effect. The premise of which is that twice the difference in log-likelihood of the full and reduced (i.e.¬†with the random effect dropped) is itself distributed as \\(\\chi^2\\)$ with DF equal to the number of parameters dropped (here 1). Actually, there is a good argument that this is too conservative, but we can discuss that later. So let‚Äôs do the LRT for the random effect using ranova() ranova(m_1) ## ANOVA-like table for random-effects: Single term deletions ## ## Model: ## aggression ~ (1 | ID) ## npar logLik AIC LRT Df Pr(&gt;Chisq) ## &lt;none&gt; 3 -751.83 1509.7 ## (1 | ID) 2 -751.83 1507.7 0 1 1 There is apparently no among-individual variance in aggressiveness. So this is a fairly rubbish and underwhelming model. Let‚Äôs improve it. 5.2.5 Do unicorns differ in aggressiveness? A better mixed model The answer we got from our first model is not wrong, it estimated the parameters we asked for and that might be informative or not and that might be representative or not of the true biology. Anyway all models are wrong but as models go this one is fairly rubbish. In fact we have explained no variation at all as we have no fixed effects (except the mean) and our random effect variance is zero. We woud have seen just how pointless this model was if we‚Äôd plotted it plot(m_1) (#fig:mod1_plot)Fitted values vs residuals for a simple mixed model of unicorn aggression So we can probably do better at modelling the data, which may or may not change our view on whether there is any real variation among unicorns in aggressiveness. For instance, we can (and should have started with) an initial plot of the phenotypic data against opponent size indicates to have a look at our prediction. The code below uses the excellent üì¶ ggplot2 but the same figure can be done using base R code. ggplot(unicorns, aes(x = opp_size, y = aggression)) + geom_jitter( alpha = 0.5, width = 0.05 ) + scale_x_continuous(breaks = c(-1, 0, 1)) + labs( x = &quot;Opponent size (SD)&quot;, y = &quot;Aggression&quot; ) + theme_classic() ggplot(unicorns, aes(x = opp_size, y = aggression)) + geom_jitter( alpha = 0.5, width = 0.05 ) + scale_x_continuous(breaks = c(-1, 0, 1)) + labs( x = &quot;Opponent size (SD)&quot;, y = &quot;Aggression&quot; ) + theme_classic() Figure 5.2: Unicorn aggressivity as a function of opponent size when fighting for sweets As predicted, there is a general increase in aggression with opponent size (points are lightly jittered on the x-axis to show the spread of data a little better) You can see the same thing from a quick look at the population means for aggression at opponent size. Here we do it with the kable function that makes nice tables in rmarkdown documents. unicorns %&gt;% group_by(opp_size) %&gt;% summarise(mean_aggr = mean(aggression)) %&gt;% knitr::kable(digits = 2) opp_size mean_aggr -1 8.00 0 8.91 1 10.09 So, there does appear to be plasticity of aggression with changing size of the model opponent. But other things may explain variation in aggressiveness too - what about block for instance? Block effects may not be the subject of any biologically interesting hypotheses, but accounting for any differences between blocks could remove noise. There may also be systematic change in behaviour as an individual experiences more repeat observations (i.e.¬†exposure to the model). Do they get sensitised or habituated to the model intruder for example? So let‚Äôs run a mixed model with the same random effect of individual, but with a fixed effects of opponent size (our predictor of interest) and experimental block. m_2 &lt;- lmer(aggression ~ opp_size + block + (1 | ID), data = unicorns) 5.2.5.1 Diagnostic plots Run a few diagnostic plots before we look at the answers. In diagnostic plots, we want to check the condition of applications of the linear mixed model which are the same 4 as the linear model plus 2 extra: Linearity of the relation between covariates and the response Done with data exploration graph (i.e.¬†just plot the data see if it is linear) - see previous graph 5.2. No error on measurement of covariates assumed to be correct if measurement error is lower than 10% of variance in the variable - I know this sounds pretty bad Residual have a Gaussian distribution using quantile-quantile plot or histogram of residuals par(mfrow = c(1, 2)) # multiple graphs in a window qqnorm(residuals(m_2)) # a q-q plot qqline(residuals(m_2)) hist(resid(m_2)) # are the residuals roughly Gaussian? Figure 5.3: Checking residuals have Gaussian distribution Homoscedasticty (variance of residuals is constant across covariates) Using plot of residuals by fitted values plot(m_2) Figure 5.4: Residuals by fitted values for model m_2 to check homoscedasticity Random effects have a Gaussian distribution histogram of the predictions for the random effects (BLUPs) # extracting blups r1 &lt;- as.data.frame(ranef(m_2, condVar = TRUE)) par(mfrow = c(1, 2)) hist(r1$condval) qqnorm(r1$condval) qqline(r1$condval) Figure 5.5: Checking random effects are gaussian Residual variance is constant across all levels of a random effect No straightforward solution to deal with that. We can just do a plot is absolutely not-informative for that problem but I always like to look at. It is the plot of the sorted BLUPs with their associated errors. r1 &lt;- r1[order(r1$condval), ] # sorting the BLUPs ggplot(r1, aes(y = grp, x = condval)) + geom_point() + geom_pointrange( aes(xmin = condval - condsd * 1.96, xmax = condval + condsd * 1.96) ) + geom_vline(aes(xintercept = 0, color = &quot;red&quot;)) + theme_classic() + theme(legend.position = &quot;none&quot;) Here is a great magic trick üéá because 3-5 and more can be done in one step You need to use the function check_model() from the üì¶ performance package. check_model(m_2) Figure 5.6: Graphical check of model assumptions 5.2.5.2 Inferences Now summarise this model. We will pause here for you to think about and discuss a few things: * What can you take from the fixed effect table? * How do you interpret the intercept now that there are other effects in the model? * What would happen if we scaled our fixed covariates differently? Why? summary(m_2) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;] ## Formula: aggression ~ opp_size + block + (1 | ID) ## Data: unicorns ## ## REML criterion at convergence: 1129.9 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.79296 -0.64761 0.00155 0.67586 2.71456 ## ## Random effects: ## Groups Name Variance Std.Dev. ## ID (Intercept) 0.02478 0.1574 ## Residual 0.58166 0.7627 ## Number of obs: 480, groups: ID, 80 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 9.00181 0.03901 79.00000 230.778 &lt;2e-16 *** ## opp_size 1.04562 0.04263 398.00000 24.525 &lt;2e-16 *** ## block -0.02179 0.06962 398.00000 -0.313 0.754 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) opp_sz ## opp_size 0.000 ## block 0.000 0.000 ::: {.infobox .code data-latex = ‚Äúcode‚Äù} Try tweaking the fixed part of your model: What happens if you add more fixed effects? Try it! Could focal body size also matter? If so, should you rescale before adding it to the model? Should you add interactions (e.g.¬†block:opp_size)? Should you drop non-significant fixed effects? ::: ::: {.infobox .code data-latex = ‚Äúcode‚Äù} Having changed the fixed part of your model, do the variance estimates change at all? Is among-individual variance always estimated as zero regardless of fixed effects? Is among-individual variance significant with some fixed effets structures but not others? ::: 5.2.6 What is the repeatability? As a reminder, repeatability is the proportion of variance explained by a random effect and it is estimate as the ratio of the variance associated to a random effect by the total variance, or the sum of the residual variance and the different variance compoentn associated with the random effects. In our first model among-individual variance was zero, so R was zero. If we have a different model of aggression and get a non-zero value of the random effect variance, we can obviously calculate a repeatability estimate (R). So we are all working from the same starting point, let‚Äôs all stick with a common set of fixed effects from here on: m_3 &lt;- lmer( aggression ~ opp_size + scale(body_size, center = TRUE, scale = TRUE) + scale(assay_rep, scale = FALSE) + block + (1 | ID), data = unicorns ) summary(m_3) ## Linear mixed model fit by REML. t-tests use ## Satterthwaite&#39;s method [lmerModLmerTest] ## Formula: ## aggression ~ opp_size + scale(body_size, center = TRUE, scale = TRUE) + ## scale(assay_rep, scale = FALSE) + block + (1 | ID) ## Data: unicorns ## ## REML criterion at convergence: 1136.5 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.85473 -0.62831 0.02545 0.68998 2.74064 ## ## Random effects: ## Groups Name Variance Std.Dev. ## ID (Intercept) 0.02538 0.1593 ## Residual 0.58048 0.7619 ## Number of obs: 480, groups: ID, 80 ## ## Fixed effects: ## Estimate ## (Intercept) 9.00181 ## opp_size 1.05141 ## scale(body_size, center = TRUE, scale = TRUE) 0.03310 ## scale(assay_rep, scale = FALSE) -0.05783 ## block -0.02166 ## Std. Error ## (Intercept) 0.03907 ## opp_size 0.04281 ## scale(body_size, center = TRUE, scale = TRUE) 0.03896 ## scale(assay_rep, scale = FALSE) 0.04281 ## block 0.06955 ## df ## (Intercept) 78.07315 ## opp_size 396.99857 ## scale(body_size, center = TRUE, scale = TRUE) 84.21144 ## scale(assay_rep, scale = FALSE) 396.99857 ## block 397.00209 ## t value ## (Intercept) 230.395 ## opp_size 24.562 ## scale(body_size, center = TRUE, scale = TRUE) 0.850 ## scale(assay_rep, scale = FALSE) -1.351 ## block -0.311 ## Pr(&gt;|t|) ## (Intercept) &lt;2e-16 *** ## opp_size &lt;2e-16 *** ## scale(body_size, center = TRUE, scale = TRUE) 0.398 ## scale(assay_rep, scale = FALSE) 0.177 ## block 0.756 ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) opp_sz sc=Ts=T s(_s=F ## opp_size 0.000 ## s(_,c=TRs=T 0.000 0.000 ## s(_,s=FALSE 0.000 -0.100 0.000 ## block 0.000 0.000 0.002 0.000 So we‚Äôd probably calculate R using the individual and residual variance simply as: 0.02538 / (0.02538 + 0.58048) ## [1] 0.04189087 ::: {.infobox .code data-latex = ‚Äúcode‚Äù} Do you see where I took the numbers ? ::: We can use some more fancy coding to extract the estimates and plugged them in a formula to estimate the repeatbility v_id &lt;- VarCorr(m_3)$ID[1, 1] v_r &lt;- attr(VarCorr(m_3), &quot;sc&quot;)^2 r_man &lt;- v_id / (v_id + v_r) r_man ## [1] 0.04188879 Which yields an estimate of approximately R=4%. Strictly speaking we should make clear this a conditional repeatability estimate. Conditional on what you might ask‚Ä¶ on the fixed effects in your model. So our best estimate of 4% refers to the proportion of variance in aggressiveness not explained by fixed effects that is explained by individual identity. This isn‚Äôt much and still won‚Äôt be significant, but illustrates the point that conditional repeatabilities often have a tendency to go up as people explain more of the residual variance by adding fixed effects. This is fine and proper, but can mislead the unwary reader. It also means that decisions about which fixed effects to include in your model need to be based on how you want to interpret R not just on, for instance, whether fixed effects are deemed significant. 5.2.7 A quick note on uncertainty Using lmer in the üì¶ lme4 üì¶ there isn‚Äôt a really simple way to put some measure of uncertainty (SE or CI) on derived parameters like repeatabilities. This is a bit annoying. Such things are more easily done with other mixed model üì¶ like MCMCglmm and asreml which are a bit more specialist. If you are using lmer for models you want to publish then you could look into the üì¶ rptR (Stoffel et al. 2019). This acts as a ‚Äòwrapper‚Äô for lmer models and adds some nice functionality including options to boostrap confidence intervals. Regardless, of how you do it, if you want to put a repeatability in one of your papers as a key result - it really should be accompanied by a measure of uncertainty just like any other effect size estimate. Here I am estimating the repeatability and using bootstrap to estimate a confidence interval and a probability associated with the repeatability with the rptR üì¶. For more information about the use of the package and the theory behind it suggest the excellent paper associated with the package (Stoffel et al. 2017) r_rpt &lt;- rptGaussian( aggression ~ opp_size + block + (1 | ID), grname = &quot;ID&quot;, data = unicorns ) ## Bootstrap Progress: r_rpt ## ## ## Repeatability estimation using the lmm method ## ## Repeatability for ID ## R = 0.041 ## SE = 0.031 ## CI = [0, 0.107] ## P = 0.0966 [LRT] ## NA [Permutation] 5.2.8 An easy way to mess up your mixed models We will try some more advanced mixed models in a moment to explore plasticity in aggressiveness a bit more. First let‚Äôs quickly look for among-individual variance in focal body size. Why not? We have the data handy, everyone says morphological traits are very repeatable and - lets be honest - who wouldn‚Äôt like to see a small P value after striking out with aggressiveness. Include a random effect of ID as before and maybe a fixed effect of block, just to see if the beasties were growing a bit between data collection periods. lmer_size &lt;- lmer(body_size ~ block + (1 | ID), data = unicorns ) Summarise and test the random effect. summary(lmer_size) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;] ## Formula: body_size ~ block + (1 | ID) ## Data: unicorns ## ## REML criterion at convergence: 3460.7 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -1.80452 -0.71319 0.00718 0.70280 1.81747 ## ## Random effects: ## Groups Name Variance Std.Dev. ## ID (Intercept) 936.01 30.594 ## Residual 34.32 5.858 ## Number of obs: 480, groups: ID, 80 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 252.5031 3.4310 79.0000 73.595 &lt;2e-16 *** ## block -0.1188 0.5348 399.0000 -0.222 0.824 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) ## block 0.000 ranova(lmer_size) ## ANOVA-like table for random-effects: Single term deletions ## ## Model: ## body_size ~ block + (1 | ID) ## npar logLik AIC LRT Df Pr(&gt;Chisq) ## &lt;none&gt; 4 -1730.4 3468.7 ## (1 | ID) 3 -2325.6 4657.1 1190.4 1 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ::: {.infobox .code data-latex = ‚Äúcode‚Äù} What might you conclude, and why would this be foolish? ::: Hopefully you spotted the problem here. You have fed in a data set with 6 records per individual (with 2 sets of 3 identical values per unicorns), when you know size was only measured twice in reality. This means you‚Äôd expect to get a (potentially very) upwardly biased estimate of R and a (potentially very) downwardly biased P value when testing among-individual variance. ::: {.infobox .code data-latex = ‚Äúcode‚Äù} How can we do it properly? ::: We can prune the data to the two actual observations per unicorns by just selecting the first assay in each block. unicorns2 &lt;- unicorns[unicorns$assay_rep == 1, ] lmer_size2 &lt;- lmer(body_size ~ block + (1 | ID), data = unicorns2 ) summary(lmer_size2) ## Linear mixed model fit by REML. t-tests use ## Satterthwaite&#39;s method [lmerModLmerTest] ## Formula: body_size ~ block + (1 | ID) ## Data: unicorns2 ## ## REML criterion at convergence: 1373.4 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -1.54633 -0.56198 0.01319 0.56094 1.42095 ## ## Random effects: ## Groups Name Variance Std.Dev. ## ID (Intercept) 912.84 30.213 ## Residual 57.78 7.601 ## Number of obs: 160, groups: ID, 80 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 252.5031 3.4310 79.0000 73.595 &lt;2e-16 ## block -0.1188 1.2019 79.0000 -0.099 0.922 ## ## (Intercept) *** ## block ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) ## block 0.000 ranova(lmer_size2) ## ANOVA-like table for random-effects: Single term deletions ## ## Model: ## body_size ~ block + (1 | ID) ## npar logLik AIC LRT Df Pr(&gt;Chisq) ## &lt;none&gt; 4 -686.68 1381.3 ## (1 | ID) 3 -771.93 1549.9 170.51 1 &lt; 2.2e-16 *** ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Summarise and test your random effect and you‚Äôll see the qualitative conclusions will actually be very similar using the pruned data set. Of course this won‚Äôt generallty but be true, so just be careful. Mixed models are intended to help you model repeated measures data with non-independence, but they won‚Äôt get you out of trouble if you mis-represent the true structure of observations on your dependent variable. 5.2.9 Happy mixed-modelling Figure 5.7: The superb unicorn References "],["6-introduction-to-glmm.html", "6 Introduction to GLMM ", " 6 Introduction to GLMM "],["6.1-lecture-5.html", "6.1 Lecture", " 6.1 Lecture theoretical intro to glmm and introduce DHarma package to evaluate fit of glmm Figure 6.1: Dream pet dragon "],["6.2-practical-3.html", "6.2 Practical", " 6.2 Practical This is an adapted version largely inspired by the tutorial in (Bolker et al. 2009). Spatial variation in nutrient availability and herbivory is likely to cause population differentiation and maintain genetic diversity in plant populations.Here we measure the extent to which mouse-ear cress (Arabidopsis thaliana)exhibits population and genotypic variation in their responses to these im-portant environmental factors. We are particularly interested in whether these populations exhibit nutrient mediated compensation, where higher nutrient levels allow genotypes to better tolerate herbivory (Banta et al. 2010). We use GLMMs to estimate the effect of nutrient levels, simulated herbivory, and their interaction on fruit production in Arabidopsis thaliana(fixed effects), and the extent to which populations vary in their responses(random effects, or variance components) 6.2.1 Packages and functions You need to download the ‚Äúextra_funs.R‚Äù script for some functions used in the Practical library(lme4) library(tidyverse) library(patchwork) library(lattice) library(DHARMa) source(&quot;data/extra_funs.R&quot;) 6.2.2 The data set In this data set, the response variable is the number of fruits (i.e.¬†seed capsules) per plant. The number of fruits produced by an individual plant(the experimental unit) was hypothesized to be a function of fixed effects,including nutrient levels (low vs.¬†high), simulated herbivory (none vs.¬†apical meristem damage), region (Sweden, Netherlands, Spain), and interactions among these. Fruit number was also a function of random effects including both the population and individual genotype. Because Arabidopsis is highly selfing, seeds of a single individual served as replicates of that individual.There were also nuisance variables, including the placement of the plant in the greenhouse, and the method used to germinate seeds. These were estimated as fixed effects but interactions were excluded. X observation number (we will use this observation number later, when we are accounting for overdispersion) reg a factor for region (Netherlands, Spain, Sweden). popu a factor with a level for each population. gen a factor with a level for each genotype. rack a nuisance factor for one of two greenhouse racks. nutrient a factor with levels for minimal or additional nutrients. amd a factor with levels for no damage or simulated herbivory (apical meristem damage; we will sometimes refer to this as ‚Äúclipping‚Äù) status a nuisance factor for germination method. total.fruits the response; an integer count of the number of fruits per plant. 6.2.3 Specifying fixed and random Effects Here we need to select a realistic full model, based on the scientific questions and the data actually at hand. We first load the data set and make sure that each variable is appropriately designated as numeric or factor (i.e.categorical variable). dat_tf &lt;- read.csv(&quot;data/Banta_TotalFruits.csv&quot;) str(dat_tf) ## &#39;data.frame&#39;: 625 obs. of 9 variables: ## $ X : int 1 2 3 4 5 6 7 8 9 10 ... ## $ reg : chr &quot;NL&quot; &quot;NL&quot; &quot;NL&quot; &quot;NL&quot; ... ## $ popu : chr &quot;3.NL&quot; &quot;3.NL&quot; &quot;3.NL&quot; &quot;3.NL&quot; ... ## $ gen : int 4 4 4 4 4 4 4 4 4 5 ... ## $ rack : int 2 1 1 2 2 2 2 1 2 1 ... ## $ nutrient : int 1 1 1 1 8 1 1 1 8 1 ... ## $ amd : chr &quot;clipped&quot; &quot;clipped&quot; &quot;clipped&quot; &quot;clipped&quot; ... ## $ status : chr &quot;Transplant&quot; &quot;Petri.Plate&quot; &quot;Normal&quot; &quot;Normal&quot; ... ## $ total.fruits: int 0 0 0 0 0 0 0 3 2 0 ... The X, gen, rack and nutrient variables are coded as integers, but we want them to be factors.  We use mutate() dplyr üì¶, which operates within the data set, to avoid typing lots of commands like dat_tf$rack &lt;- factor(dat_tf$rack)  At the same time, we reorder the clipping variable so that \"unclipped\" is the reference level (we could also have used relevel(amd,\"unclipped\")). dat_tf &lt;- mutate( dat_tf, X = factor(X), gen = factor(gen), rack = factor(rack), amd = factor(amd, levels = c(&quot;unclipped&quot;, &quot;clipped&quot;)), nutrient = factor(nutrient, label = c(&quot;Low&quot;, &quot;High&quot;)) ) Now we check replication for each genotype (columns) within each population (rows). (reptab &lt;- with(dat_tf, table(popu, gen))) ## gen ## popu 4 5 6 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 27 28 30 34 35 36 ## 1.SP 0 0 0 0 0 39 26 35 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## 1.SW 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 28 20 0 0 0 0 0 ## 2.SW 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 18 14 0 0 0 ## 3.NL 31 11 13 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## 5.NL 0 0 0 35 26 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## 5.SP 0 0 0 0 0 0 0 0 43 22 12 0 0 0 0 0 0 0 0 0 0 0 0 0 ## 6.SP 0 0 0 0 0 0 0 0 0 0 0 13 24 14 0 0 0 0 0 0 0 0 0 0 ## 7.SW 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 45 47 45 ## 8.SP 0 0 0 0 0 0 0 0 0 0 0 0 0 0 13 16 35 0 0 0 0 0 0 0 ::: {.infobox .code data-latex = ‚Äúcode‚Äù} Exercise: this mode of inspection is OK for this data set but might fail for much larger data sets or for more levels of nesting. See if you can think of some other numerical or graphical methods for inspecting the structure of data sets. plot(reptab) gives a mosaic plot of the two-way table; examine this, see if you can figure out how to interpret it, and decide whether you think it might be useful try the commands colSums(reptab&gt;0) (and the equivalent for rowSums) and figure out what they are telling you. Using this recipe, how would you compute the range of number of genotypes per treatment combination? ::: Do you find the mosaic plot you obtained ugly and super hard to read? Me too ü§£ plot(reptab) Figure 6.2: A truly useless plot no one can understand colSums() do the sum of all the rows for each columns of a table. So colSums(reptab&gt;0) gives you for each genotype the number of populations (lines) where you have at least 1 observations. colSums(reptab &gt; 0) ## 4 5 6 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 27 28 30 34 35 36 ## 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 rowSums(reptab &gt; 0) ## 1.SP 1.SW 2.SW 3.NL 5.NL 5.SP 6.SP 7.SW 8.SP ## 3 2 2 3 2 3 3 3 3 You firts need to create a new table of number of observations per treatment and genotypes reptab2 &lt;- with(dat_tf, table(paste(amd, nutrient, sep = &quot;_&quot;), gen)) range(reptab2) ## [1] 2 13 This reveals that we have only 2‚Äì4 populations per region and 2‚Äì3 genotypes per population. However, we also have 2‚Äì13 replicates per genotype for each treatment combination (four unique treatment combinations: 2 levels of nutrients by 2 levels of simulated herbivory). Thus, even though this was a reasonably large experiment (625 plants), there were a very small number of replicates with which to estimate variance components, and many more potential interactions than our data can support. Therefore, judicious selection of model terms, based on both biology and the data, is warranted. We note that we don‚Äôt really have enough levels per random effect, nor enough replication per unique treatment combination. Therefore, we decide to omit the fixed effect of ‚Äúregion‚Äù, although we recognize that populations in different regions are widely geographically separated. However, as in all GLMMs where the scale parameter is treated as fixed and deviations from the fixed scale parameter would be identifiable (i.e.¬†Poisson and binomial (N &gt; 1), but not binary, models) we may have to deal with overdispersion. 6.2.4 Look at overall patterns in data I usually like to start with a relatively simple overall plot of the data, disregarding the random factors, just to see what‚Äôs going on. For reasons to be discussed below, we choose to look at the data on the log (or log(1 + x) scale. Let‚Äôs plot either box-and-whisker plots (useful summaries) or dot plots (more detailed, good for seeing if we missed anything). Figure 6.3: Number of fruits (log + 1) as a function of treatments ::: {.infobox .code data-latex = ‚Äúcode‚Äù} Exercise generate these plots and figure out how they work before continuing. Try conditioning/faceting on population rather than region: for facet_wrap you might want to take out the nrow = 1 specification. If you want try reorder the subplots by overall mean fruit set and/or colour the points according to the region they come from. ::: p1 &lt;- qplot( interaction(nutrient, amd), log(1 + total.fruits), data = dat_tf, geom = &quot;boxplot&quot;) + facet_wrap(~reg, nrow = 1) + theme(axis.text.x = element_text(angle = 45)) + ggtitle(&quot;Boxplot&quot;) p2 &lt;- qplot( interaction(nutrient, amd), log(1 + total.fruits), data = dat_tf) + facet_wrap(~reg, nrow = 1) + stat_sum() + theme(axis.text.x = element_text(angle = 45)) + ggtitle(&quot;Dot plot&quot;) p1 + p2 6.2.5 Choose an error distribution The data are non-normal in principle (i.e., count data, so our first guess would be a Poisson distribution). If we transform total fruits with the canonical link function (log), we hope to see relatively homogeneous variances across categories and groups. First we define a new factor that represents every combination of genotype and treatment (nutrient √ó clipping) treatment, and sort it in order of increasing mean fruit set. dat_tf &lt;- dat_tf %&gt;% mutate( gna = reorder(interaction(gen, nutrient, amd), total.fruits, mean) ) Now time to plot it ggplot(dat_tf, aes(x = gna, y = log(1 + total.fruits))) + geom_boxplot() + theme_bw() + theme(axis.text.x = element_text(angle = 90)) Figure 6.4: Boxplot of total fruits (log + 1) per genotypes and treatments We could also calculate the variance for each genotype √ó treatment combination and provide a statistical summary of these variances. This reveals substantial variation among the sample variances on the transformed data. In addition to heterogeneous variances across groups, Figure 1 reveals many zeroes in groups, and some groups with a mean and variance of zero, further suggesting we need a non-normal error distribution, and perhaps something other than a Poisson distribution. We could calculate Œª(mean) for each genotype √ó treatment combination and provide a statistical summary of each group‚Äôs Œª. grp_means &lt;- with(dat_tf, tapply(total.fruits, list(gna), mean)) summary(grp_means) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.00 11.35 23.16 31.86 49.74 122.40 A core property of the Poisson distribution is that the variance is equal to the mean. A simple diagnostic is a plot of the group variances against the group means: Poisson-distributed data will result in a linear pattern with slope = 1 as long as the variance is generally greater than the mean, we call the data overdispersed. Overdispersion comes in various forms: a linear mean-variance relationship with Var = œÜ¬µ (a line through the origin) with œÜ &gt; 1 is called a quasi-Poisson pattern (this term describes the mean-variance relationship, not any particular proability distribution); we can implement it statistically via quasilikelihood (Venables and Ripley, 2002) or by using a particular parameterization of the negative binomial distribution (‚ÄúNB1‚Äù inthe terminology of Hardin and Hilbe (2007)) a semi-quadratic pattern, Var = ¬µ(1 + Œ±¬µ) or ¬µ(1 + ¬µ/k), is characteristic of overdispersed data that is driven by underlying heterogeneity among samples, either the negative binomial (gamma-Poisson) or the lognormal-Poisson (Elston et al. 2001) We‚Äôve already calculated the group (genotype √ó treatment) means, we calculate the variances in the same way. grp_vars &lt;- with( dat_tf, tapply( total.fruits, list(gna), var ) ) We can get approximate estimates of the quasi-Poisson (linear) and negative binomial (linear/quadratic) pattern using lm. lm1 &lt;- lm(grp_vars ~ grp_means - 1) ## `quasi-Poisson&#39; fit phi_fit &lt;- coef(lm1) lm2 &lt;- lm((grp_vars - grp_means) ~ I(grp_means^2) - 1) k_fit &lt;- 1 / coef(lm2) Now we can plot them. plot(grp_vars ~ grp_means, xlab = &quot;group means&quot;, ylab = &quot;group variances&quot;) abline(c(0, 1), lty = 2) text(105, 500, &quot;Poisson&quot;) curve(phi_fit * x, col = 2, add = TRUE) ## bquote() is used to substitute numeric values ## in equations with symbols text(110, 3900, bquote(paste(&quot;QP: &quot;, sigma^2 == .(round(phi_fit, 1)) * mu)), col = 2 ) curve(x * (1 + x / k_fit), col = 4, add = TRUE) text(104, 7200, paste(&quot;NB: k=&quot;, round(k_fit, 1), sep = &quot;&quot;), col = 4) l_fit &lt;- loess(grp_vars ~ grp_means) mvec &lt;- 0:120 lines(mvec, predict(l_fit, mvec), col = 5) text(100, 2500, &quot;loess&quot;, col = 5) Figure 6.5: Graphical evaluation of distribution to use Same with ggplot ggplot( data.frame(grp_means, grp_vars), aes(x = grp_means, y = grp_vars)) + geom_point() + geom_smooth( aes(colour = &quot;Loess&quot;), se = FALSE) + geom_smooth( method = &quot;lm&quot;, formula = y ~ x - 1, se = FALSE, aes(colour = &quot;Q_Pois&quot;)) + stat_function( fun = function(x) x * (1 + x / k_fit), aes(colour = &quot;Neg_bin&quot;) ) + geom_abline( aes(intercept = 0, slope = 1, colour = &quot;Poisson&quot;)) + scale_colour_manual( name = &quot;legend&quot;, values = c(&quot;blue&quot;, &quot;purple&quot;, &quot;black&quot;, &quot;red&quot;)) + scale_fill_manual( name = &quot;legend&quot;, values = c(&quot;blue&quot;, &quot;purple&quot;, &quot;black&quot;, &quot;red&quot;)) + guides(fill = FALSE) ## `geom_smooth()` using method = &#39;loess&#39; and formula = &#39;y ~ x&#39; Figure 6.6: Graphical evaluation of distribution to use with ggplot These fits are not rigorous statistical tests ‚Äî they violate a variety of assumptions of linear regression (e.g.¬†constant variance, independence), but they are good enough to give us an initial guess about what distributions we should use. Exercise compare a simple quadratic fit to the data (i.e., without the linear part) with the negative binomial and quasipoisson fits lm3 &lt;- lm(grp_vars ~ I(grp_means)^2 - 1) ## quadratic fit quad_fit &lt;- coef(lm3) ggplot( data.frame(grp_means, grp_vars), aes(x = grp_means, y = grp_vars)) + geom_point() + geom_smooth( method = &quot;lm&quot;, formula = y ~ x - 1, se = FALSE, aes(colour = &quot;Q_Pois&quot;)) + stat_function( fun = function(x) x * (1 + x / k_fit), aes(colour = &quot;Neg_bin&quot;) ) + geom_smooth( method = &quot;lm&quot;, formula = y ~ I(x^2) - 1, se = FALSE, aes(colour = &quot;Quad&quot;)) + scale_colour_manual( name = &quot;legend&quot;, values = c(&quot;blue&quot;, &quot;purple&quot;, &quot;black&quot;)) + scale_fill_manual( name = &quot;legend&quot;, values = c(&quot;blue&quot;, &quot;purple&quot;, &quot;black&quot;)) + guides(fill = FALSE) Figure 6.7: Graphical evaluation of distribution to use including quadratic effect 6.2.5.1 Plotting the response vs treatments Just to avoid surprises ggplot(dat_tf, aes(x = amd, y = log(total.fruits + 1), colour = nutrient)) + geom_point() + ## need to use as.numeric(amd) to get lines stat_summary(aes(x = as.numeric(amd)), fun = mean, geom = &quot;line&quot;) + theme_bw() + theme(panel.spacing = unit(0, &quot;lines&quot;)) + facet_wrap(~popu) Figure 6.8: Fruit production by treatments by population ggplot(dat_tf, aes(x = amd, y = log(total.fruits + 1), colour = gen)) + geom_point() + stat_summary(aes(x = as.numeric(amd)), fun = mean, geom = &quot;line&quot;) + theme_bw() + ## label_both adds variable name (&#39;nutrient&#39;) to facet labels facet_grid(. ~ nutrient, labeller = label_both) Figure 6.9: Fruit production by genotype by treatments 6.2.6 Fitting group-wise GLM Another general starting approach is to fit GLMs to each group of data separately, equivalent to treating the grouping variables as fixed effects. This should result in reasonable variation among treatment effects. We first fit the models, and then examine the coefficients. glm_lis &lt;- lmList( total.fruits ~ nutrient * amd | gen, data = dat_tf, family = &quot;poisson&quot;) plot.lmList(glm_lis) ## Using grp as id variables Figure 6.10: Model coefficients for GLM fits on each genotype Three genotypes (5, 6, 34) have extreme coefficients (Fig. 5). A mixed model assumes that the underlying random effects are normally distributed, although we shouldn‚Äôt take these outliers too seriously at this point ‚Äî we are not actually plotting the random effects, or even estimates of random effects (which are not themselves guaranteed to be normally distributed), but rather separate estimates for each group. Create a plotting function for Q-Q plots of these coefficients to visualize the departure from normality. qqmath.lmList(glm_lis) ## Using as id variables Figure 6.11: Q-Q plots of model coefficients for GLM fits on each genotype We see that these extreme coefficients fall far outside a normal error distribution. We shouldn‚Äôt take these outliers too seriously at this point ‚Äî we are not actually plotting the random effects, or even estimates of random effects, but rather separate estimates for each group. Especially if these groups have relatively small sample sizes, the estimates may eventually be ‚Äúshrunk‚Äù closer to the mean when we do the mixed model. We should nonetheless take care to see if the coefficients for these genotypes from the GLMM are still outliers, and take the same precautions as we usually do for outliers. For example, we can look back at the original data to see if there is something weird about the way those genotypes were collected, or try re-running the analysis without those genotypes to see if the results are robust. 6.2.7 Fitting and evaluating GLMMs Now we (try to) build and fit a full model, using glmer in the emo::ji(\"pacakage\") lme4. This model has random effects for all genotype and population √ó treatment random effects, and for the nuisance variables for the rack and germination method (status). (Given the mean-variance relationship we saw it‚Äôs pretty clear that we are going to have to proceed eventually to a model with overdispersion, but we fit the Poisson model first for illustration.) mp1 &lt;- glmer(total.fruits ~ nutrient * amd + rack + status + (amd * nutrient | popu) + (amd * nutrient | gen), data = dat_tf, family = &quot;poisson&quot; ) ## Warning in checkConv(attr(opt, &quot;derivs&quot;), opt$par, ctrl = control$checkConv, : Model failed to converge with max|grad| = 0.0185742 ## (tol = 0.002, component 1) overdisp_fun(mp1) ## chisq ratio p ## 13909.47140 23.25999 0.00000 The overdisp_fun() is described [here] https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#testing-for-overdispersioncomputing-overdispersion-factor) on the absolutely fantastic FAQ about GLMMs by Ben Bolker https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html We can ignore the model convergence for the moment. This shows that the data are (extremely) over-dispersed, given the model. We can also use the excellent DHARMa üì¶ (Hartig 2022) to evaluate fit of glm and glmm. So instead of using the function overdisp_fun(), we can simply use the function testDispersion(). testDispersion(mp1) ## ## DHARMa nonparametric dispersion test via sd of residuals fitted vs. simulated ## ## data: simulationOutput ## dispersion = 1.2934, p-value = 0.384 ## alternative hypothesis: two.sided As you can see, DHARMa suggests that there is no overdispersion based on the distribution of residuals from simulated data. We are going to consider that we have overdispersion and adjust the model accordingly. Now we add the observation-level random effect to the model to account for overdispersion (Elston et al. 2001). mp2 &lt;- update(mp1, . ~ . + (1 | X)) ## Warning in checkConv(attr(opt, &quot;derivs&quot;), opt$par, ctrl = control$checkConv, : Model failed to converge with max|grad| = 0.159305 ## (tol = 0.002, component 1) The model takes much longer to fit (and gives warnings). We look just at the variance components. In particular, if we look at the correlation matrix among the genotype random effects, we see a perfect correlation. attr(VarCorr(mp2)$gen, &quot;correlation&quot;) ## (Intercept) amdclipped nutrientHigh amdclipped:nutrientHigh ## (Intercept) 1.0000000 -0.9965313 -0.9877088 0.8321072 ## amdclipped -0.9965313 1.0000000 0.9882474 -0.8426404 ## nutrientHigh -0.9877088 0.9882474 1.0000000 -0.9076218 ## amdclipped:nutrientHigh 0.8321072 -0.8426404 -0.9076218 1.0000000 We‚Äôll try getting rid of the correlations between clipping (amd) and nutrients, using amd+nutrient instead of amd*nutrient in the random effects specification (here it seems easier to re-do the model rather than using update to add and subtract terms). mp3 &lt;- glmer(total.fruits ~ nutrient * amd + rack + status + (amd + nutrient | popu) + (amd + nutrient | gen) + (1 | X), data = dat_tf, family = &quot;poisson&quot; ) ## Warning in checkConv(attr(opt, &quot;derivs&quot;), opt$par, ctrl = control$checkConv, : Model failed to converge with max|grad| = 0.226429 ## (tol = 0.002, component 1) attr(VarCorr(mp3)$gen, &quot;correlation&quot;) ## (Intercept) amdclipped nutrientHigh ## (Intercept) 1.0000000 -0.9981776 -0.9966490 ## amdclipped -0.9981776 1.0000000 0.9955458 ## nutrientHigh -0.9966490 0.9955458 1.0000000 attr(VarCorr(mp3)$popu, &quot;correlation&quot;) ## (Intercept) amdclipped nutrientHigh ## (Intercept) 1.0000000 0.9970406 0.9974900 ## amdclipped 0.9970406 1.0000000 0.9937833 ## nutrientHigh 0.9974900 0.9937833 1.0000000 Unfortunately, we still have perfect correlations among the random effects terms. For some models (e.g.¬†random-slope models), it is possible to fit random effects models in such a way that the correlation between the different parameters (intercept and slope in the case of random-slope models) is constrained to be zero, by fitting a model like (1|f)+(0+x|f); unfortunately, because of the way lme4 is set up, this is considerably more difficult with categorical predictors (factors). We have to reduce the model further in some way in order not to overfit (i.e., in order to not have perfect ¬±1 correlations among random effects). It looks like we can‚Äôt allow both nutrients and clipping in the random effect model at either the population or the genotype level. However, it‚Äôs hard to know whether we should proceed with amd or nutrient, both, or neither in the model. A convenient way to proceed if we are going to try fitting several different combinations of random effects is to fit the model with all the fixed effects but only observation-level random effects, and then to use update to add various components to it. mp_obs &lt;- glmer(total.fruits ~ nutrient * amd + rack + status + (1 | X), data = dat_tf, family = &quot;poisson&quot; ) Now, for example, update(mp_obs,.~.+(1|gen)+(amd|popu)) fits the model with intercept random effects at the genotype level and variation in clipping effects across populations. ::: {.infobox .code data-latex = ‚Äúcode‚Äù} Exercise using update, fit the models with clipping variation at both genotype and population levels; nutrient variation at both genotype and populations; convince yourself that trying to fit variation in either clipping or nutrients leads to overfitting (perfect correlations). Fit the model with only intercept variation at the population and genotype levels, saving it as mp4; show that there is non-zero variance estimated ::: mpcli &lt;- update(mp_obs, . ~ . + (amd | gen) + (amd | popu)) ## Warning in checkConv(attr(opt, &quot;derivs&quot;), opt$par, ctrl = control$checkConv, : Model failed to converge with max|grad| = 0.0882114 ## (tol = 0.002, component 1) VarCorr(mpcli) ## Groups Name Std.Dev. Corr ## X (Intercept) 1.431001 ## gen (Intercept) 0.296711 ## amdclipped 0.038708 -0.887 ## popu (Intercept) 0.754243 ## amdclipped 0.130903 0.997 mpnut &lt;- update(mp_obs, . ~ . + (nutrient | gen) + (nutrient | popu)) ## Warning in checkConv(attr(opt, &quot;derivs&quot;), opt$par, ctrl = control$checkConv, : Model failed to converge with max|grad| = 0.029394 ## (tol = 0.002, component 1) VarCorr(mpnut) ## Groups Name Std.Dev. Corr ## X (Intercept) 1.41977 ## gen (Intercept) 0.47882 ## nutrientHigh 0.32631 -1.000 ## popu (Intercept) 0.74639 ## nutrientHigh 0.12083 1.000 mp4 &lt;- update(mp_obs, . ~ . + (1 | gen) + (1 | popu)) VarCorr(mp4) ## Groups Name Std.Dev. ## X (Intercept) 1.43127 ## gen (Intercept) 0.28582 ## popu (Intercept) 0.80598 In other words, while it‚Äôs biologically plausible that there is some variation in the nutrient or clipping effect at the genotype or population levels, with this modeling approach we really don‚Äôt have enough data to speak confidently about these effects. Let‚Äôs check that mp4 no longer incorporates overdispersion (the observationlevel random effect should have taken care of it): overdisp_fun(mp4) ## chisq ratio p ## 177.5249980 0.2886585 1.0000000 Using the DHARMa üì¶, we will also check the model. To do so we first need to simulate some data and get the scaled residuals following the DHARMa notation. Then we can check the distributional properties of the scaled residuals and see if they follow the classic assumption using the different functions provided. scaled_res &lt;- simulateResiduals(mp4) plot(scaled_res) ## DHARMa:testOutliers with type = binomial may have inflated Type I error rates for integer-valued distributions. To get a more exact result, it is recommended to re-run testOutliers with type = &#39;bootstrap&#39;. See ?testOutliers for details testZeroInflation(mp4, plot = TRUE) ## ## DHARMa zero-inflation test via comparison to expected zeros with simulation under H0 = fitted model ## ## data: simulationOutput ## ratioObsSim = 1.9768, p-value &lt; 2.2e-16 ## alternative hypothesis: two.sided # note about overdispersion sum(dat_tf$total.fruits == 0) ## [1] 126 a &lt;- predict(mp4, type = &quot;response&quot;) b &lt;- rep(0, 500) for (j in 1:500) { b[j] &lt;- sum(sapply(seq(nrow(dat_tf)), function(i) rpois(1, a[i])) == 0) } hist(b) 6.2.8 Inference 6.2.8.1 Random effects glmer (lmer) does not return information about the standard errors or confidence intervals of the variance components. VarCorr(mp4) ## Groups Name Std.Dev. ## X (Intercept) 1.43127 ## gen (Intercept) 0.28582 ## popu (Intercept) 0.80598 6.2.8.1.1 Testing for random Effects If we want to test the significance of the random effects we can fit reduced models and run likelihood ratio tests via anova, keeping in mind that in this case (testing a null hypothesis of zero variance, where the parameter is on the boundary of its feasible region) the reported p value is approximately twice what it should be. mp4v1 &lt;- update(mp_obs, . ~ . + (1 | popu)) ## popu only (drop gen) mp4v2 &lt;- update(mp_obs, . ~ . + (1 | gen)) ## gen only (drop popu) ## Warning in checkConv(attr(opt, &quot;derivs&quot;), opt$par, ctrl = control$checkConv, : unable to evaluate scaled gradient ## Warning in checkConv(attr(opt, &quot;derivs&quot;), opt$par, ctrl = control$checkConv, : Model failed to converge: degenerate Hessian with 2 ## negative eigenvalues anova(mp4, mp4v1) ## Data: dat_tf ## Models: ## mp4v1: total.fruits ~ nutrient + amd + rack + status + (1 | X) + (1 | popu) + nutrient:amd ## mp4: total.fruits ~ nutrient + amd + rack + status + (1 | X) + (1 | gen) + (1 | popu) + nutrient:amd ## npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) ## mp4v1 9 5017.4 5057.4 -2499.7 4999.4 ## mp4 10 5015.4 5059.8 -2497.7 4995.4 4.0639 1 0.04381 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 anova(mp4, mp4v2) ## Data: dat_tf ## Models: ## mp4v2: total.fruits ~ nutrient + amd + rack + status + (1 | X) + (1 | gen) + nutrient:amd ## mp4: total.fruits ~ nutrient + amd + rack + status + (1 | X) + (1 | gen) + (1 | popu) + nutrient:amd ## npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) ## mp4v2 9 5031.6 5071.5 -2506.8 5013.6 ## mp4 10 5015.4 5059.8 -2497.7 4995.4 18.212 1 1.976e-05 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 For various forms of linear mixed models, the RLRsim package can do efficient simulation-based hypothesis testing of variance components ‚Äî un- fortunately, that doesn‚Äôt include GLMMs. If we are sufficiently patient we can do hypothesis testing via brute-force parametric bootstrapping where we repeatedly simulate data from the reduced (null) model, fit both the re- duced and full models to the simulated data, and compute the distribution of the deviance (change in -2 log likelihood). The code below took about half an hour on a reasonably modern desktop computer. simdev &lt;- function() { newdat &lt;- simulate(mp4v1) reduced &lt;- lme4::refit(mp4v1, newdat) full &lt;- lme4::refit(mp4, newdat) 2 * (c(logLik(full) - logLik(reduced))) } set.seed(101) nulldist0 &lt;- replicate(2, simdev()) ## zero spurious (small) negative values nulldist[nulldist &lt; 0 &amp; abs(nulldist) &lt; 1e-5] &lt;- 0 obsdev &lt;- 2 * c(logLik(mp4) - logLik(mp4v1)) mean(c(nulldist, obsdev) &gt;= obsdev) ## [1] 0.01492537 The true p-value is actually closer to 0.05 than 0.02. In other words, here the deviations from the original statistical model from that for which the original ‚Äúp value is inflated by 2‚Äù rule of thumb was derived ‚Äî fitting a GLMM instead of a LMM, and using a moderate-sized rather than an arbitrarily large (asymptotic) data set ‚Äî have made the likelihood ratio test liberal (increased type I error) rather than conservative (decreased type I error). We can also inspect the random effects estimates themselves (in proper statistical jargon, these might be considered ‚Äúpredictions‚Äù rather than ‚Äúestimates‚Äù (Robinson, 1991)). We use the built-in dotplot method for the random effects extracted from glmer fits (i.e.¬†ranef(model,condVar=TRUE)), which returns a list of plots, one for each random effect level in the model. r1 &lt;- as.data.frame(ranef(mp4, condVar = TRUE, whichel = c(&quot;gen&quot;, &quot;popu&quot;))) p1 &lt;- ggplot(subset(r1, grpvar == &quot;gen&quot;), aes(y = grp, x = condval)) + geom_point() + geom_pointrange( aes(xmin = condval - condsd * 1.96, xmax = condval + condsd * 1.96) ) + geom_vline(aes(xintercept = 0, color = &quot;red&quot;)) + theme_classic() + theme(legend.position = &quot;none&quot;) p2 &lt;- ggplot(subset(r1, grpvar == &quot;popu&quot;), aes(y = grp, x = condval)) + geom_point() + geom_pointrange( aes(xmin = condval - condsd * 1.96, xmax = condval + condsd * 1.96) ) + geom_vline(aes(xintercept = 0, color = &quot;red&quot;)) + theme_classic() + theme(legend.position = &quot;none&quot;) p1 + p2 Figure 6.12: Distribution of BLUPs for genotypes and populations As expected from the similarity of the variance estimates, the population-level estimates (the only shared component) do not differ much between the two models. There is a hint of regional differentiation ‚Äî the Spanish populations have higher fruit sets than the Swedish and Dutch populations. Genotype 34 again looks a little bit unusual. 6.2.8.2 Fixed effects Now we want to do inference on the fixed effects. We use the drop1 func- tion to assess both the AIC difference and the likelihood ratio test between models. (In glmm_funs.R we define a convenience function dfun to convert the AIC tables returned by drop1 (which we will create momentarily) into ‚àÜAIC tables.) Although the likelihood ratio test (and the AIC) are asymptotic tests, comparing fits between full and reduced models is still more accurate than the Wald (curvature-based) tests shown in the summary tables for glmer fits. (dd_aic &lt;- dfun(drop1(mp4))) ## Warning in checkConv(attr(opt, &quot;derivs&quot;), opt$par, ctrl = control$checkConv, : Model failed to converge with max|grad| = 0.00959403 ## (tol = 0.002, component 1) ## Single term deletions ## ## Model: ## total.fruits ~ nutrient + amd + rack + status + (1 | X) + (1 | ## gen) + (1 | popu) + nutrient:amd ## npar dAIC ## &lt;none&gt; 0.000 ## rack 1 55.083 ## status 2 1.612 ## nutrient:amd 1 1.444 (dd_lrt &lt;- drop1(mp4, test = &quot;Chisq&quot;)) ## Warning in checkConv(attr(opt, &quot;derivs&quot;), opt$par, ctrl = control$checkConv, : Model failed to converge with max|grad| = 0.00959403 ## (tol = 0.002, component 1) ## Single term deletions ## ## Model: ## total.fruits ~ nutrient + amd + rack + status + (1 | X) + (1 | ## gen) + (1 | popu) + nutrient:amd ## npar AIC LRT Pr(Chi) ## &lt;none&gt; 5015.4 ## rack 1 5070.5 57.083 4.179e-14 *** ## status 2 5017.0 5.612 0.06044 . ## nutrient:amd 1 5016.8 3.444 0.06349 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 On the basis of these comparisons, there appears to be a very strong effect of rack and weak effects of status and of the interaction term. Dropping the nutrient:amd interaction gives a (slightly) increased AIC (‚àÜAIC = 1.4), so the full model has the best expected predictive capability (by a small margin). On the other hand, the p-value is slightly above 0.05 (p = 0.06). At this point we remove the non-significant interaction term so we can test the main effects. (We don‚Äôt worry about removing status because it measures an aspect of experimental design that we want to leave in the model whether it is significant or not.) Once we have fitted the reduced model, we can run the LRT via anova. mp5 &lt;- update(mp4, . ~ . - amd:nutrient) ## Warning in checkConv(attr(opt, &quot;derivs&quot;), opt$par, ctrl = control$checkConv, : Model failed to converge with max|grad| = 0.00959403 ## (tol = 0.002, component 1) anova(mp5, mp4) ## Data: dat_tf ## Models: ## mp5: total.fruits ~ nutrient + amd + rack + status + (1 | X) + (1 | gen) + (1 | popu) ## mp4: total.fruits ~ nutrient + amd + rack + status + (1 | X) + (1 | gen) + (1 | popu) + nutrient:amd ## npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) ## mp5 9 5016.8 5056.8 -2499.4 4998.8 ## mp4 10 5015.4 5059.8 -2497.7 4995.4 3.4439 1 0.06349 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Exercise Test now the reduced model. In the reduced model, we find that both nutrients and clipping have strong effects, whether measured by AIC or LRT. If we wanted to be still more careful about our interpretation, we would try to relax the asymptotic assumption. In classical linear models, we would do this by doing F tests with the appropriate denominator degrees of freedom. In ‚Äúmodern‚Äù mixed model approaches, we might try to use denominator-degree-of-freedom approximations such as the Kenward-Roger (despite the controversy over these approximations, they are actually available in lmerTest, but they do not apply to GLMMs. We can use a parametric bootstrap comparison between nested models to test fixed effects, as we did above for random effects, with the caveat that is computationally slow. In addition, we can check the normality of the random effects and find they are reasonable (Fig. 10). r5 &lt;- as.data.frame(ranef(mp5)) ggplot(data = r5, aes(sample = condval)) + geom_qq() + geom_qq_line() + facet_wrap(~ grpvar) + theme_classic() Figure 6.13: Q-Q plot of BLUPs from model mp5 Checking everything with DHARMa also scaled_res &lt;- simulateResiduals(mp5) plot(scaled_res) testZeroInflation(mp5, plot = TRUE) ## ## DHARMa zero-inflation test via comparison to expected zeros with simulation under H0 = fitted model ## ## data: simulationOutput ## ratioObsSim = 1.9883, p-value = 0.008 ## alternative hypothesis: two.sided It is better than before but not perfect. I think this is completely OK and that it will extremely rarely be perfect. You need to learn what is acceptable (by that I mean you find acceptable) and be happy to justify and discuss your decisions. 6.2.9 Conclusions Our final model includes fixed effects of nutrients and clipping, as well as the nuisance variables rack and status; observation-level random effects to ac- count for overdispersion; and variation in overall fruit set at the population and genotype levels. However, we don‚Äôt (apparently) have quite enough in- formation to estimate the variation in clipping and nutrient effects, or their interaction, at the genotype or population levels. There is a strong overall positive effect of nutrients and a slightly weaker negative effect of clipping. The interaction between clipping and nutrients is only weakly supported (i.e.¬†the p-value is not very small), but it is positive and about the same magnitude as the clipping effect, which is consistent with the statement that ‚Äúnutrients cancel out the effect of herbivory‚Äù. ::: {.infobox .code data-latex = ‚Äúcode‚Äù} Exercise Re-do the analysis with region as a fixed effect. Re-do the analysis with a one-way layout as suggested above ::: 6.2.10 Happy generalized mixed-modelling Figure 6.14: A GLMM character References "],["7-introduction-to-bayesian-inference.html", "7 Introduction to Bayesian Inference ", " 7 Introduction to Bayesian Inference "],["7.1-lecture-6.html", "7.1 Lecture", " 7.1 Lecture Amazing beasties and crazy animals Figure 7.1: Dream pet dragon 7.1.1 Bayes‚Äô theorem First, let‚Äôs review the theorem. Mathematically, it says how to convert one conditional probability into another one. \\[ P(B \\mid A) = \\frac{ P(A \\mid B) * P(B)}{P(A)} \\] The formula becomes more interesting in the context of statistical modeling. We have some model that describes a data-generating process and we have some observed data, but we want to estimate some unknown model parameters. In that case, the formula reads like: \\[ P(\\text{hypothesis} \\mid \\text{data}) = \\frac{ P(\\text{data} \\mid \\text{hypothesis}) * P(\\text{hypothesis})}{P(\\text{data})} \\] These terms have conventional names: \\[ \\text{posterior} = \\frac{ \\text{likelihood} * \\text{prior}}{\\text{evidence}} \\] Prior and posterior describe when information is obtained: what we know pre-data is our prior information, and what we learn post-data is the updated information (‚Äúposterior‚Äù). The likelihood in the equation says how likely the data is given the model parameters. I think of it as fit: How well do the parameters fit the data? Classical regression‚Äôs line of best fit is the maximum likelihood line. The likelihood also encompasses the data-generating process behind the model. For example, if we assume that the observed data is normally distributed, then we evaluate the likelihood by using the normal probability density function. You don‚Äôt need to know what that last sentence means. What‚Äôs important is that the likelihood contains our built-in assumptions about how the data is distributed. The evidence (sometimes called average likelihood) is hareder to grasp. I am not sure how to describe it in an intuitive way. It‚Äôs there to make sure the math works out so that the posterior probabilities sum to 1. Some presentations of Bayes‚Äô theorem gloss over it and I am not the exception üòÑ. The important thing to note is that the posterior is proportional to the likelihood and prior information. \\[ \\text{posterior information} \\propto \\text{likelihood of data} * \\text{prior information} \\] So simply put, you update your prior information in proportion to how well it fits the observed data. So essentially you are doing that on a daily basis for everything except when you ar doing frequentist stats üòÑ. Figure 7.2: Bayesian Triptych ::: {.infobox .warning data-latex = ‚Äúwarning‚Äù} A word of encouragement! The prior is an intimidating part of Bayesian statistics. It seems highly subjective, as though we are pulling numbers from thin air, and it can be overwhelming for complex models. But if we are familiar with the kind of data we are modeling, we have prior information. We can have the model simulate new observations using the prior distribution and then plot the hypothetical data. Does anything look wrong or implausible about the simulated data? If so, then we have some prior information that we can include in our model. Note that we do not evaluate the plausibility of the simulated data based on the data we have in hand (the data we want to model); that‚Äôs not ::: 7.1.2 Intro to MCMC We will now walk through a simple example coded in R to illustrate how an MCMC algorithm works. Suppose you are interested in the mean heart rate is of students when asked a question in a stat course. You are not sure what the exact mean value is, but you know the values are normally distributed with a standard deviation of 15. You have observed 5 individuals to have heart rate of 104, 120,160,90,130. You could use MCMC sampling to draw samples from the target distribution. We need to specify: the starting value for the chain. the length of the chain. In general, more iterations will give you more accurate output. set.seed(170) hr_obs &lt;- c(104, 112, 132, 115, 110) start_value &lt;- 250 n_iter &lt;- 2500 # define number of iterations pd_mean &lt;- numeric(n_iter) # create vector for sample values pd_mean[1] &lt;- start_value # define starting value for (i in 2:n_iter) { proposal &lt;- pd_mean[i - 1] + MASS::mvrnorm(1, 0, 5) # proposal lprop &lt;- sum(dnorm(proposal, hr_obs, 15)) # likelihood of proposed parameter lprev &lt;- sum(dnorm(pd_mean[i - 1], hr_obs, 15)) if (lprop / lprev &gt; runif(1)) { # if likelihood of prosposed &gt; likehood previous accept # and if likelihood is lower accept with random noise pd_mean[i] &lt;- proposal } # if true sample the proposal else { (pd_mean[i] &lt;- pd_mean[i - 1]) } # if false sample the current value } pd_mean &lt;- as.mcmc(data.frame(mean = pd_mean)) mcmc_combo(pd_mean, combo = c(&quot;trace&quot;, &quot;dens&quot;)) summary(pd_mean) ## ## Iterations = 1:2500 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 2500 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## 125.8105 32.8672 0.6573 13.3046 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## 75.53 108.03 122.19 136.12 225.46 set.seed(170) hr_obs &lt;- c(104, 112, 132, 115, 110) n_iter &lt;- 2500 # define number of iterations n_chain &lt;- 3 start_value &lt;- c(250, 100, 50) pd_mean &lt;- array(NA, dim = c(n_iter, n_chain, 1), dimnames = list(iter = NULL, chain = NULL, params = &quot;beta&quot;)) # create vector for sample values for (j in seq_len(n_chain)) { pd_mean[1, j, 1] &lt;- start_value[j] # define starting value for (i in 2:n_iter) { proposal &lt;- pd_mean[i - 1, j, 1] + MASS::mvrnorm(1, 0, 5) # proposal if (sum(dnorm(proposal, hr_obs, 15)) # likelihood of proposed parameter / sum(dnorm(pd_mean[i - 1, j, 1], hr_obs, 15)) &gt; runif(1, 0, 1)) { pd_mean[i, j, 1] &lt;- proposal } # if true sample the proposal else { (pd_mean[i, j, 1] &lt;- pd_mean[i - 1, j, 1]) } # if false sample the current value } } color_scheme_set(&quot;mix-blue-red&quot;) mcmc_combo(pd_mean, combo = c(&quot;trace&quot;, &quot;dens_overlay&quot;)) summary(pd_mean) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 41.65 99.32 109.68 112.71 122.52 250.00 mcmc_combo(pd_mean, combo = c(&quot;trace&quot;, &quot;dens_overlay&quot;), n_warmup = 500) pd_burn &lt;- pd_mean[-c(1:500), , , drop = FALSE] summary(pd_burn) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 51.98 100.71 110.38 111.42 122.69 163.58 mcmc_combo(pd_burn, combo = c(&quot;trace&quot;, &quot;dens_overlay&quot;), iter1 = 501) 7.1.3 Inferences 7.1.3.1 Fixed effects Easy peazy lemon squeezy just have a look at the posteriro distribution, does it overlap 0 yes or no. talk about mean, median and mode of a distribution as well as credible intervals 7.1.3.2 Random effects Quite a bit more harder. because constrained to be positive Interpreting posterior distribution DIC WAIC "],["7.2-practical-4.html", "7.2 Practical", " 7.2 Practical In this practical, we will revisit our analysis on unicorn aggressivity. Honestly, we can use any other data with repeated measures for this exercise but I just love unicorns ‚ù§Ô∏è. However, instead of fittng the model using lmer() from the lmerTest üì¶ (Kuznetsova et al. 2020), we will refit the model using 2 excellent softwares fitting models with a Bayesian approach: MCMCglmm (Hadfield 2010) and brms (B√ºrkner 2021). 7.2.1 R packages needed First we load required libraries library(lmerTest) library(tidyverse) library(rptR) library(brms) library(MCMCglmm) library(bayesplot) 7.2.2 A refresher on unicorn ecology The last model on unicorns was: aggression ~ opp_size + scale(body_size, center = TRUE, scale = TRUE) + scale(assay_rep, scale = FALSE) + block + (1 | ID) Those scaled terms are abit a sore for my eyes and way too long if we need to type them multiple times in this practical. So first let‚Äôs recode them. - unicorns &lt;- read.csv(&quot;data/unicorns_aggression.csv&quot;) unicorns &lt;- unicorns %&gt;% mutate( body_size_sc = scale(body_size), assay_rep_sc = scale(assay_rep, scale = FALSE) ) Ok now we can fit the same model by just using: aggression ~ opp_size + body_size_sc + assay_rep_sc + block + (1 | ID) We can now fit a model using lmer(). Since we want to compare a bit REML and Bayesian aproaches, I am going to wrap the model function in a function called system.time(). This function simply estimate the user and computer time use by the function. mer_time &lt;- system.time( m_mer &lt;- lmer( aggression ~ opp_size + body_size_sc + assay_rep_sc + block + (1 | ID), data = unicorns ) ) mer_time ## user system elapsed ## 0.071 0.000 0.071 summary(m_mer) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;] ## Formula: aggression ~ opp_size + body_size_sc + assay_rep_sc + block + (1 | ID) ## Data: unicorns ## ## REML criterion at convergence: 1136.5 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.85473 -0.62831 0.02545 0.68998 2.74064 ## ## Random effects: ## Groups Name Variance Std.Dev. ## ID (Intercept) 0.02538 0.1593 ## Residual 0.58048 0.7619 ## Number of obs: 480, groups: ID, 80 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 9.00181 0.03907 78.07315 230.395 &lt;2e-16 *** ## opp_size 1.05141 0.04281 396.99857 24.562 &lt;2e-16 *** ## body_size_sc 0.03310 0.03896 84.21144 0.850 0.398 ## assay_rep_sc -0.05783 0.04281 396.99857 -1.351 0.177 ## block -0.02166 0.06955 397.00209 -0.311 0.756 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) opp_sz bdy_s_ assy__ ## opp_size 0.000 ## body_siz_sc 0.000 0.000 ## assay_rp_sc 0.000 -0.100 0.000 ## block 0.000 0.000 0.002 0.000 Ok so it took no time at all to do it and we got our ‚Äúclassic‚Äù results. 7.2.3 MCMCglmm What makes MCMCglmm so useful and powerful üí™ in ecology and for practical Bayesian people is that: it is blazing fast ‚è© (for Bayesian analysis) for some models particularly models with structured covariances it is fairly intuitive to code but it also has some inconvenients: it is blazing fast for Bayesian analysis meaning it is üêå compared to maximum likelihood approaches it has some limitations in terms of functionality, distribution availability and model specifications compared to other Bayesian softwares the priors, oh, the priors üò≠, are a bit tricky to code and understand ü§Ø. 7.2.3.1 Fitting the Model So here is how we can code the model in MCMCglmm(). It is fairly similar to lmer() except that the random effects are specified in a different argument. mcglm_time &lt;- system.time( m_mcmcglmm &lt;- MCMCglmm( aggression ~ opp_size + body_size_sc + assay_rep_sc + block, random = ~ID, data = unicorns ) ) ## ## MCMC iteration = 0 ## ## MCMC iteration = 1000 ## ## MCMC iteration = 2000 ## ## MCMC iteration = 3000 ## ## MCMC iteration = 4000 ## ## MCMC iteration = 5000 ## ## MCMC iteration = 6000 ## ## MCMC iteration = 7000 ## ## MCMC iteration = 8000 ## ## MCMC iteration = 9000 ## ## MCMC iteration = 10000 ## ## MCMC iteration = 11000 ## ## MCMC iteration = 12000 ## ## MCMC iteration = 13000 summary(m_mcmcglmm) ## ## Iterations = 3001:12991 ## Thinning interval = 10 ## Sample size = 1000 ## ## DIC: 1128.004 ## ## G-structure: ~ID ## ## post.mean l-95% CI u-95% CI eff.samp ## ID 0.003686 9.807e-14 0.0262 45.81 ## ## R-structure: ~units ## ## post.mean l-95% CI u-95% CI eff.samp ## units 0.6044 0.5228 0.6819 1000 ## ## Location effects: aggression ~ opp_size + body_size_sc + assay_rep_sc + block ## ## post.mean l-95% CI u-95% CI eff.samp pMCMC ## (Intercept) 9.00152 8.93150 9.07158 1000 &lt;0.001 *** ## opp_size 1.04940 0.96813 1.12946 1000 &lt;0.001 *** ## body_size_sc 0.03154 -0.03985 0.09563 1000 0.410 ## assay_rep_sc -0.05620 -0.13196 0.03546 893 0.184 ## block -0.02069 -0.16186 0.11553 1000 0.774 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 mcglm_time ## user system elapsed ## 2.03 0.00 2.03 Model is slow and not good. We need more iteration and maybe even a longer burnin, and honestly maybe better priors. We can still take the time to have a look at the R object output from MCMCglmm(). The 2 main parts we are interrested in are: Sol which stand for the model solution and includes the posteriro distribution of the fixed effects VCV, for the variance covariance estimates, which includes the posterior distribution of all (co)variances estimates for both random effects and residual variance. plot(m_mcmcglmm$Sol) Figure 7.3: Posterior trace and distribution of the paremeters in m_mcmcglmm using default settings Figure 7.4: Posterior trace and distribution of the paremeters in m_mcmcglmm using default settings plot(m_mcmcglmm$VCV) Figure 7.5: Posterior trace and distribution of the paremeters in m_mcmcglmm using default settings autocorr.diag(m_mcmcglmm$VCV) ## ID units ## Lag 0 1.0000000 1.00000000 ## Lag 10 0.8042405 -0.02074155 ## Lag 50 0.4807583 -0.04264317 ## Lag 100 0.1951356 0.04422296 ## Lag 500 0.1254589 0.04401956 Talk about autocorrelation, mixing, convergence and priors here n_samp &lt;- 1000 thin &lt;- 500 burnin &lt;- 20000 mcglm_time &lt;- system.time( m_mcmcglmm &lt;- MCMCglmm( aggression ~ opp_size + body_size_sc + assay_rep_sc + block, random = ~ID, data = unicorns, nitt = n_samp * thin + burnin, thin = thin, burnin = burnin, verbose = FALSE, prior = list( R = list(V = 1, nu = 0.002), G = list( G1 = list(V = 1, nu = 0.002) ) ) ) ) summary(m_mcmcglmm) ## ## Iterations = 20001:519501 ## Thinning interval = 500 ## Sample size = 1000 ## ## DIC: 1126.66 ## ## G-structure: ~ID ## ## post.mean l-95% CI u-95% CI eff.samp ## ID 0.01987 0.0002904 0.05458 1000 ## ## R-structure: ~units ## ## post.mean l-95% CI u-95% CI eff.samp ## units 0.5917 0.5188 0.6763 1000 ## ## Location effects: aggression ~ opp_size + body_size_sc + assay_rep_sc + block ## ## post.mean l-95% CI u-95% CI eff.samp pMCMC ## (Intercept) 9.00136 8.92221 9.07383 1000 &lt;0.001 *** ## opp_size 1.05363 0.96382 1.13650 1000 &lt;0.001 *** ## body_size_sc 0.03373 -0.03781 0.10686 1000 0.396 ## assay_rep_sc -0.05861 -0.14186 0.02882 1000 0.182 ## block -0.02709 -0.16061 0.11441 1000 0.698 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 mcglm_time ## user system elapsed ## 88.783 0.020 88.934 evaluate model here plot(m_mcmcglmm$Sol) Figure 7.6: Posterior trace and distribution of the paremeters in m_mcmcglmm with better settings Figure 7.7: Posterior trace and distribution of the paremeters in m_mcmcglmm with better settings plot(m_mcmcglmm$VCV) Figure 7.8: Posterior trace and distribution of the paremeters in m_mcmcglmm with better settings autocorr.diag(m_mcmcglmm$VCV) ## ID units ## Lag 0 1.000000000 1.000000000 ## Lag 500 0.013876043 -0.044235206 ## Lag 2500 0.026120260 -0.048012241 ## Lag 5000 -0.049357725 0.021158672 ## Lag 25000 0.002544256 -0.003722595 7.2.4 Inferences 7.2.4.1 Fixed effects Easy peazy lemon squeezy just have a look at the posterior distribution, does it overlap 0 yes or no. posterior.mode(m_mcmcglmm$Sol) ## (Intercept) opp_size body_size_sc assay_rep_sc block ## 9.00632282 1.07353252 0.03500916 -0.04048582 -0.03276275 HPDinterval(m_mcmcglmm$Sol) ## lower upper ## (Intercept) 8.92221005 9.07383400 ## opp_size 0.96382086 1.13649873 ## body_size_sc -0.03781276 0.10685606 ## assay_rep_sc -0.14185602 0.02882443 ## block -0.16060691 0.11440706 ## attr(,&quot;Probability&quot;) ## [1] 0.95 7.2.4.2 Random effects Quite a bit more harder. because constrained to be positive posterior.mode(m_mcmcglmm$VCV) ## ID units ## 0.00096263 0.59129362 HPDinterval(m_mcmcglmm$VCV) ## lower upper ## ID 0.0002903938 0.05458376 ## units 0.5188238599 0.67634529 ## attr(,&quot;Probability&quot;) ## [1] 0.95 7.2.5 brms brms is an acronym for Bayesian Regression Models using ‚ÄòStan‚Äô (B√ºrkner 2021). It is a package developed to fit regression models with a Bayesian approach using the amazing stan software (Stan Development Team 2021). What makes brms so useful and powerful üí™ in ecology is that: it is really intuitive to code (same syntax as glmer()) it is incredibly flexible since it is essentially a front end for stan via its rstan interface (Guo et al. 2021) but with great powers come great responsability üï∑ brm_time &lt;- system.time( m_brm &lt;- brm( aggression ~ opp_size + body_size_sc + assay_rep_sc + block + (1 | ID), data = unicorns, iter = 4750, warmup = 1000, thin = 15, cores = 4 # refresh = 0 ) ) ## Compiling Stan program... ## Start sampling ## VSCode WebView has restricted access to local file. ## Opening in external browser... ## Browsing file:///tmp/RtmpIwThis/file41046617c061d_StanProgress.html brm_time ## user system elapsed ## 109.998 6.708 137.578 summary(m_brm) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: aggression ~ opp_size + body_size_sc + assay_rep_sc + block + (1 | ID) ## Data: unicorns (Number of observations: 480) ## Draws: 4 chains, each with iter = 4750; warmup = 1000; thin = 15; ## total post-warmup draws = 1000 ## ## Group-Level Effects: ## ~ID (Number of levels: 80) ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sd(Intercept) 0.14 0.07 0.01 0.26 1.00 984 898 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 9.00 0.04 8.92 9.08 1.00 1021 903 ## opp_size 1.05 0.04 0.96 1.14 1.00 992 881 ## body_size_sc 0.03 0.04 -0.05 0.11 1.00 982 903 ## assay_rep_sc -0.06 0.04 -0.14 0.03 1.00 953 940 ## block -0.02 0.07 -0.15 0.12 1.00 1145 951 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 0.77 0.03 0.71 0.82 1.00 1113 898 ## ## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). mcmc_acf_bar(m_brm, regex_pars = c(&quot;sd&quot;)) Figure 7.9: Autocorrelation in the chain for variance parameters in model m_brm 7.2.5.1 Hunder the hood have a look at the stan code stancode(m_brm) ## // generated with brms 2.20.4 ## functions { ## } ## data { ## int&lt;lower=1&gt; N; // total number of observations ## vector[N] Y; // response variable ## int&lt;lower=1&gt; K; // number of population-level effects ## matrix[N, K] X; // population-level design matrix ## int&lt;lower=1&gt; Kc; // number of population-level effects after centering ## // data for group-level effects of ID 1 ## int&lt;lower=1&gt; N_1; // number of grouping levels ## int&lt;lower=1&gt; M_1; // number of coefficients per level ## array[N] int&lt;lower=1&gt; J_1; // grouping indicator per observation ## // group-level predictor values ## vector[N] Z_1_1; ## int prior_only; // should the likelihood be ignored? ## } ## transformed data { ## matrix[N, Kc] Xc; // centered version of X without an intercept ## vector[Kc] means_X; // column means of X before centering ## for (i in 2:K) { ## means_X[i - 1] = mean(X[, i]); ## Xc[, i - 1] = X[, i] - means_X[i - 1]; ## } ## } ## parameters { ## vector[Kc] b; // regression coefficients ## real Intercept; // temporary intercept for centered predictors ## real&lt;lower=0&gt; sigma; // dispersion parameter ## vector&lt;lower=0&gt;[M_1] sd_1; // group-level standard deviations ## array[M_1] vector[N_1] z_1; // standardized group-level effects ## } ## transformed parameters { ## vector[N_1] r_1_1; // actual group-level effects ## real lprior = 0; // prior contributions to the log posterior ## r_1_1 = (sd_1[1] * (z_1[1])); ## lprior += student_t_lpdf(Intercept | 3, 8.9, 2.5); ## lprior += student_t_lpdf(sigma | 3, 0, 2.5) ## - 1 * student_t_lccdf(0 | 3, 0, 2.5); ## lprior += student_t_lpdf(sd_1 | 3, 0, 2.5) ## - 1 * student_t_lccdf(0 | 3, 0, 2.5); ## } ## model { ## // likelihood including constants ## if (!prior_only) { ## // initialize linear predictor term ## vector[N] mu = rep_vector(0.0, N); ## mu += Intercept; ## for (n in 1:N) { ## // add more terms to the linear predictor ## mu[n] += r_1_1[J_1[n]] * Z_1_1[n]; ## } ## target += normal_id_glm_lpdf(Y | Xc, mu, b, sigma); ## } ## // priors including constants ## target += lprior; ## target += std_normal_lpdf(z_1[1]); ## } ## generated quantities { ## // actual population-level intercept ## real b_Intercept = Intercept - dot_product(means_X, b); ## } 7.2.5.2 using shiny launch_shinystan(m_brm) Figure 7.10: Shinystan interface 7.2.6 Inferences 7.2.6.1 Fixed effects summary(m_brm) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: aggression ~ opp_size + body_size_sc + assay_rep_sc + block + (1 | ID) ## Data: unicorns (Number of observations: 480) ## Draws: 4 chains, each with iter = 4750; warmup = 1000; thin = 15; ## total post-warmup draws = 1000 ## ## Group-Level Effects: ## ~ID (Number of levels: 80) ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sd(Intercept) 0.14 0.07 0.01 0.26 1.00 984 898 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 9.00 0.04 8.92 9.08 1.00 1021 903 ## opp_size 1.05 0.04 0.96 1.14 1.00 992 881 ## body_size_sc 0.03 0.04 -0.05 0.11 1.00 982 903 ## assay_rep_sc -0.06 0.04 -0.14 0.03 1.00 953 940 ## block -0.02 0.07 -0.15 0.12 1.00 1145 951 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 0.77 0.03 0.71 0.82 1.00 1113 898 ## ## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). mcmc_plot(m_brm, regex_pars = &quot;b_&quot;) Figure 7.11: Fixed effect estimates (with 95% credible intervals) from model m_brm 7.2.6.2 Random effects summary(m_brm) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: aggression ~ opp_size + body_size_sc + assay_rep_sc + block + (1 | ID) ## Data: unicorns (Number of observations: 480) ## Draws: 4 chains, each with iter = 4750; warmup = 1000; thin = 15; ## total post-warmup draws = 1000 ## ## Group-Level Effects: ## ~ID (Number of levels: 80) ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sd(Intercept) 0.14 0.07 0.01 0.26 1.00 984 898 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 9.00 0.04 8.92 9.08 1.00 1021 903 ## opp_size 1.05 0.04 0.96 1.14 1.00 992 881 ## body_size_sc 0.03 0.04 -0.05 0.11 1.00 982 903 ## assay_rep_sc -0.06 0.04 -0.14 0.03 1.00 953 940 ## block -0.02 0.07 -0.15 0.12 1.00 1145 951 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 0.77 0.03 0.71 0.82 1.00 1113 898 ## ## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). mcmc_plot(m_brm, pars = c(&quot;sd_ID__Intercept&quot;, &quot;sigma&quot;)) ## Warning: Argument &#39;pars&#39; is deprecated. Please use &#39;variable&#39; instead. Figure 7.12: Among-individual and residual standard deviance ( with 95% credible intervals) estimated from model m_brm 7.2.7 Happy Bayesian stats Figure 7.13: Sherlock Holmes, a truly bayesian detective References "],["8-multivariate-mixed-models.html", "8 Multivariate mixed models ", " 8 Multivariate mixed models "],["8.1-lecture-7.html", "8.1 Lecture", " 8.1 Lecture Amazing beasties and crazy animals Figure 8.1: Dream pet dragon add a comparison of lrt "],["8.2-practical-5.html", "8.2 Practical", " 8.2 Practical In this practical, we have collected data on the amazing blue dragon of the East that roam the sky at night. We will use two different üì¶ to fit more complex models that are not possible with lmer() from lme4 üì¶ (Bates et al. 2021). We will use: asreml-R which is a commercial software developed by VSNi (Butler 2021). ASReml fit models using a maximum likelihood approach, is quite flexible and fast. MCMCglmm which is free and open-source and fit model using a Bayesian approach (Hadfield 2010). It is super flexible and allow to fit a wide diversity of distribution. The aims of the practical are to learn: How to phrase questions of interest in terms of variances and covariances (or derived correlations or regressions); How to incorporate more advanced model structures, such as: Fixed effects that apply only to a subset of the response traits; Traits which are measured a different number of times (e.g., repeated measures of behaviour and a single value of breeding success); Hypothesis testing using likelihood ratio tests. 8.2.1 R packages needed First we load required libraries library(lmerTest) library(tidyverse) library(asreml) library(MCMCglmm) library(nadiv) 8.2.2 The blue dragon of the East For this practical, we have collected data on the amazing blue dragon of the East that roam the sky at night. Figure 8.2: Blue dragon male We tagged all dragons individually when they hatch from their eggs. Here, we concentrate on female dragon that produce a single clucth of eggs per mating seasons. Adult femlae blue dragons need to explore vast amount of land to find a compatible male. We thus hypothesized that maximum flight speed as well as exploration are key traits to determine fitness. We were able to obtain repeated measures of flying speed and exploration on 80 adult females during one mating season and also measure the number of egg layed at the end of the season. Each females was capture 4 times during the season and each time we measured the maximum flying speed using a wind tunnel and exploration using a openfield test. The data frame has 6 variables: ID: Individual identity assay_rep: the repeat number of the behavioural assay max_speed: maximum flying speed exploration: eggs: measure of reproductive succes measured only once per individual body_size: individual body size measured on the day of the test df_dragons &lt;- read.csv(&quot;data/dragons.csv&quot;) str(df_dragons) ## &#39;data.frame&#39;: 320 obs. of 6 variables: ## $ ID : chr &quot;S_1&quot; &quot;S_1&quot; &quot;S_1&quot; &quot;S_1&quot; ... ## $ assay_rep : int 1 2 3 4 1 2 3 4 1 2 ... ## $ max_speed : num 58.7 57.9 64.3 61.4 65.5 ... ## $ exploration: num 126 125 127 127 125 ... ## $ eggs : int 39 NA NA NA 56 NA NA NA 51 NA ... ## $ body_size : num 21.7 21.5 21.3 20.8 25.7 ... To help with convergence of the model, and also help with parameter interpretation, we will first scale our covariates. df_dragons &lt;- df_dragons %&gt;% mutate( body_size_sc = scale(body_size), assay_rep_sc = scale(assay_rep, scale = FALSE) ) 8.2.3 Multiple univariate models We first use the lme4 üì¶ to determine the proportion of phenotypic variation (adjusted for fixed effects) that is due to differences among individuals, separately for each trait with repeated measures. 8.2.3.1 Flying speed Our model includes fixed effects of the assay repeat number (centred) and individual body size (centred and scaled to standard deviation units), as we wish to control for any systematic effects of these variables on individual behaviour. Be aware that controlling variables are at your discretion ‚Äî for example, while we want to characterise among-individual variance in flying speed after controlling for size effects in this study, others may wish to characterise among-individual variance in flying speed without such control. Using techniques shown later in the practical, it would be entirely possible to characterise both among-individual variance in flying speed and in size, and the among-individual covariance between these measurements. lmer_f &lt;- lmer(max_speed ~ assay_rep_sc + body_size_sc + (1 | ID), data = df_dragons ) par(mfrow = c(1, 3)) plot(resid(lmer_f, type = &quot;pearson&quot;) ~ fitted(lmer_f)) qqnorm(residuals(lmer_f)) qqline(residuals(lmer_f)) hist(residuals(lmer_f)) Figure 8.3: Checking assumptions of model lmer_f summary(lmer_f) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;] ## Formula: max_speed ~ assay_rep_sc + body_size_sc + (1 | ID) ## Data: df_dragons ## ## REML criterion at convergence: 1791.4 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.3645 -0.6496 -0.1154 0.6463 2.6894 ## ## Random effects: ## Groups Name Variance Std.Dev. ## ID (Intercept) 6.951 2.636 ## Residual 11.682 3.418 ## Number of obs: 320, groups: ID, 80 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 63.5344 0.3513 78.0954 180.870 &lt;2e-16 *** ## assay_rep_sc -0.1519 0.1709 238.9807 -0.889 0.375 ## body_size_sc 0.4468 0.3445 88.0328 1.297 0.198 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) assy__ ## assay_rp_sc 0.000 ## body_siz_sc 0.000 -0.002 Having examined diagnostic plots of the model fit, we can check the model summary. We are interested in the random effects section of the lme4 model output (specifically the variance component ‚Äî note that the standard deviation here is simply the square root of the variance). Evidence for ‚Äòanimal personality‚Äô (or ‚Äòconsistent among-individual differences in behaviour‚Äô) in the literature is largely taken from the repeatability of behaviorual traits: we can compute this repeatability (also known as the intraclass correlation coefficient) by dividing the variance in the trait due to differences among individuals (\\(V_{ID}\\)) by the total phenotypic variance after accounting for the fixed effects (\\(V_{ID} + V_{residual}\\) ). rep_flying &lt;- as.data.frame(VarCorr(lmer_f)) %&gt;% select(grp, vcov) %&gt;% spread(grp, vcov) %&gt;% mutate(repeatability = ID / (ID + Residual)) rep_flying Table 8.1: Variance components and repeatbility for the maximum flying speed of blue dragons ID Residual repeatability 6.951 11.682 0.373 So we can see that 37.31% of the phenotypic variation in boldness (having controlled for body size and assay repeat number) is due to differences among individuals. 8.2.3.2 Exploration lmer_e &lt;- lmer(exploration ~ assay_rep_sc + body_size_sc + (1 | ID), data = df_dragons ) par(mfrow = c(1, 3)) plot(resid(lmer_e, type = &quot;pearson&quot;) ~ fitted(lmer_e)) qqnorm(residuals(lmer_e)) qqline(residuals(lmer_e)) hist(residuals(lmer_e)) Figure 8.4: Checking assumptions of model lmer_e summary(lmer_e) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;] ## Formula: exploration ~ assay_rep_sc + body_size_sc + (1 | ID) ## Data: df_dragons ## ## REML criterion at convergence: 1691.2 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.73290 -0.62520 0.01635 0.55523 2.95896 ## ## Random effects: ## Groups Name Variance Std.Dev. ## ID (Intercept) 3.623 1.903 ## Residual 9.091 3.015 ## Number of obs: 320, groups: ID, 80 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 127.22524 0.27148 78.08871 468.639 &lt;2e-16 *** ## assay_rep_sc -0.07811 0.15076 238.99943 -0.518 0.605 ## body_size_sc 0.26114 0.26806 85.68180 0.974 0.333 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) assy__ ## assay_rp_sc 0.000 ## body_siz_sc 0.000 -0.002 So the model looks good and we can see our estimates for both fixed and random effects. We can now estimate the repeatbility of exploration. rep_expl &lt;- as.data.frame(VarCorr(lmer_e)) %&gt;% select(grp, vcov) %&gt;% spread(grp, vcov) %&gt;% mutate(repeatability = ID / (ID + Residual)) rep_expl Table 8.2: Variance components and repeatability for exploration behaviour of blue dragons ID Residual repeatability 3.623 9.091 0.285 Both of traits of interest are repeatable at the among-individual level. So, the remaining question is estimating the relation between these two traits. Are individuals that are consistently faster than average also more exploratory than average (and vice versa)? 8.2.3.3 Correlation using BLUPs Using BLUPs to estimate correlations between traits or to further investigate biological associations can lead to spurious results and anticonservative hypothesis tests and narrow confidence intervals. Hadfield et al. (2010) discuss the problem as well as present some alternative method to avoid the problem using Bayesian methods. However, it is always preferable to use multivariate models when possible. We need to create a data frame that contain the BLUPs from both univariate models. df_blups_fe &lt;- merge( as.data.frame(ranef(lmer_f)), as.data.frame(ranef(lmer_e)), by = &quot;grp&quot; ) %&gt;% mutate( speed = condval.x, exploration = condval.y ) We can now test the correlation among-individual between flying speed and exploration. (cor_blups &lt;- with(df_blups_fe, cor.test(speed, exploration))) ## ## Pearson&#39;s product-moment correlation ## ## data: speed and exploration ## t = 3.2131, df = 78, p-value = 0.00191 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.1320924 0.5223645 ## sample estimates: ## cor ## 0.3418867 ggplot(df_blups_fe, aes(x = exploration, y = speed)) + geom_point() + labs(xlab = &quot;Exploration (BLUP)&quot;, ylab = &quot;Flying speed (BLUP)&quot;) + theme_classic() Figure 8.5: Relation between exploration and flying speed using BLUPs from univariate models As you can see, we get a positive correlation with a very small p-value (P = 0.00191), indicating that these traits are involved in a behavioural syndrome. While the correlation itself is fairly weak ($r = 0.342), it appears to be highly significant, and suggests that individuals that are faster than average also tend to be more exploratory than average. However, as discussed in Hadfield et al. (2010) and Houslay and Wilson (2017), using BLUPs in this way leads to anticonservative significance tests. This is because the error inherent in their prediction is not carried forward from the lmer models to the subsequent analysis (in this case, a correlation test). To illustrate this point quickly, below we plot the individual estimates along with their associated standard errors. ggplot(df_blups_fe, aes(x = exploration, y = speed)) + geom_point() + geom_linerange(aes( xmin = exploration - condsd.x, xmax = exploration + condsd.x )) + geom_linerange(aes( ymin = speed - condsd.y, ymax = speed + condsd.y )) + labs( xlab = &quot;Exploration (BLUP +/- SE)&quot;, ylab = &quot;Flying speed (BLUP +/- SE)&quot; ) + theme_classic() Figure 8.6: Relation between exploration and flying speed using BLUPs from univariate models including +/- SE as error bars 8.2.4 Multivariate approach 8.2.4.1 Based on ASRemlR The correct approach for testing the hypothesised relation between speed and exploration uses both response variables in a two-trait (‚Äòbivariate‚Äô) mixed model. This model estimates the among-individual variance for each response variable (and the covariance between them). Separate (co)variances are also fitted for the residual variation. The bivariate model also allows for fixed effects to be fitted on both response variables. We set up our model using the asreml function call, with our bivariate response variable being exploration and flying speed bound together using cbind. You will also note that we scale our response variables, meaning that each is centred at their mean value and standardised to units of 1 standard deviation. This is not essential, but simply makes it easier for the model to be fit. Scaling the response variables also aids our understanding of the output, as both flying speed and exploration are now on the same scale. asreml can be a bit specific sometime and random effects should absolutely be factor and not character or integer df_dragons &lt;- df_dragons %&gt;% mutate( ID = as.factor(ID), speed_sc = scale(max_speed), exploration_sc = scale(exploration) ) asr_us &lt;- asreml( cbind(speed_sc, exploration_sc) ~ trait + trait:assay_rep_sc + trait:body_size_sc, random = ~ ID:us(trait), residual = ~ units:us(trait), data = df_dragons, maxiter = 100 ) ## Model fitted using the sigma parameterization. ## ASReml 4.1.0 Wed Jan 17 14:11:28 2024 ## LogLik Sigma2 DF wall cpu ## 1 -333.105 1.0 634 14:11:28 0.0 ## 2 -303.637 1.0 634 14:11:28 0.0 ## 3 -274.849 1.0 634 14:11:28 0.0 ## 4 -260.243 1.0 634 14:11:28 0.0 ## 5 -256.118 1.0 634 14:11:28 0.0 ## 6 -255.891 1.0 634 14:11:28 0.0 ## 7 -255.889 1.0 634 14:11:28 0.0 On the right hand side of our model formula, we use the trait keyword to specify that this is a multivariate model ‚Äî trait itself tells the model to give us the intercept for each trait. We then interact trait with the fixed effects, assay_rep_sc and body_size_sc, so that we get estimates for the effect of these variables on each of teh 2 traits. The random effects structure starts with the random effects, where we tell the model to fit an unstructured (us) covariance matrix for the grouping variable ID. This means that the variance in exploration due to differences among individuals, the variance in boldness due to differences among individuals, and the covariance between these variances will be estimated. Next, we set a structure for the residual variation (residual), which is also sometimes known as the within-individual variation. As we have repeated measures for both traits at the individual level, we also set an unstructured covariance matrix, which estimates the residual variance for each trait and also allows the residuals to covary across the two traits. Finally, we provide the name of the data frame, and a maximum number of iterations for ASReml to attempt to fit the model. After the model has been fit by ASReml, we can check the fit using the same type of model diagnostic plots as we use for lme4: par(mfrow = c(1, 3)) plot(residuals(asr_us) ~ fitted(asr_us)) qqnorm(residuals(asr_us)) qqline(residuals(asr_us)) hist(residuals(asr_us)) Figure 8.7: Checking assumptions of model asr_us The summary part of the ASReml model fit contains a large amount of information, so it is best to look only at certain parts of it at a single time. While we are not particularly interested in the fixed effects for current purposes, you can inspect these using the following code to check whether there were any large effects of assay repeat or body size on either trait: summary(asr_us, coef = TRUE)$coef.fixed ## solution std error z.ratio ## trait_speed_sc:body_size_sc 1.040579e-01 0.07972962 1.305135e+00 ## trait_exploration_sc:body_size_sc 7.269022e-02 0.07533421 9.649033e-01 ## trait_speed_sc:assay_rep_sc -3.521261e-02 0.03960492 -8.890967e-01 ## trait_exploration_sc:assay_rep_sc -2.195541e-02 0.04238056 -5.180538e-01 ## trait_speed_sc -1.820461e-16 0.08140684 -2.236251e-15 ## trait_exploration_sc -2.853753e-16 0.07631479 -3.739449e-15 wald(asr_us, ssType = &quot;conditional&quot;, denDF = &quot;numeric&quot;) ## Model fitted using the sigma parameterization. ## ASReml 4.1.0 Wed Jan 17 14:11:28 2024 ## LogLik Sigma2 DF wall cpu ## 1 -255.889 1.0 634 14:11:28 0.0 ## 2 -255.889 1.0 634 14:11:28 0.0 ## Calculating denominator DF ## $Wald ## [0;34m ## Wald tests for fixed effects.[0m ## [0;34mResponse: cbind(speed_sc, exploration_sc)[0m ## ## Df denDF F.inc F.con Margin Pr ## trait 2 77.1 0.0000 0.0000 1.00000 ## trait:assay_rep_sc 2 237.9 0.3955 0.3984 B 0.67184 ## trait:body_size_sc 2 86.6 0.9871 0.9871 B 0.37679 ## ## $stratumVariances ## NULL We can see that there is a separate intercept for both personality traits (no surprise that these are very close to zero, given that we mean-centred and scaled each trait before fitting the model), and an estimate of the effect of assay repeat and body size on both traits. None of these appear to be large effects, so let‚Äôs move on to the more interesting parts ‚Äî the random effects estimates: summary(asr_us)$varcomp ## component std.error z.ratio bound %ch ## ID:trait!trait_speed_sc:speed_sc 0.37333063 0.08607123 4.337461 P 0 ## ID:trait!trait_exploration_sc:speed_sc 0.08838639 0.06067006 1.456837 P 0 ## ID:trait!trait_exploration_sc:exploration_sc 0.28631012 0.07637247 3.748865 P 0 ## units:trait!R 1.00000000 NA NA F 0 ## units:trait!trait_speed_sc:speed_sc 0.62741689 0.05740281 10.930073 P 0 ## units:trait!trait_exploration_sc:speed_sc 0.32632113 0.04829175 6.757286 P 0 ## units:trait!trait_exploration_sc:exploration_sc 0.71844189 0.06572780 10.930563 P 0 In the above summary table, we have the among-individual (co)variances listed first (starting with ID), then the residual (or within-individual) (co)variances (starting with R). You will notice that the variance estimates here are actually close to the lme4 repeatability estimates, because our response variables were scaled to phenotypic standard deviations. We can also find the ‚Äòadjusted repeatability‚Äô (i.e., the repeatability conditional on the fixed effects) for each trait by dividing its among-individual variance estimate by the sum of its among-individual and residual variances. Here, we use the vpredict function to estimate the repeatability and its standard error for each trait, conditional on the effects of assay repeat and body size. For this function, we provide the name of the model object, followed by a name that we want to give the estimate being returned, and a formula for the calculation. Each ‚ÄòV‚Äô term in the formula refers to a variance component, using its position in the model summary shown above. vpredict(asr_us, rep_speed ~ V1 / (V1 + V5)) ## Estimate SE ## rep_speed 0.3730518 0.06124032 vpredict(asr_us, rep_expl ~ V3 / (V3 + V7)) ## Estimate SE ## rep_expl 0.284956 0.06113539 We can also use this function to calculate the estimate and standard error of the correlation from our model (co)variances. We do this by specifying the formula for the correlation: (cor_fe &lt;- vpredict(asr_us, cor_expl_speed ~ V2 / (sqrt(V1 * V3)))) ## Estimate SE ## cor_expl_speed 0.2703462 0.1594097 In this case, the estimate is similar (here, slightly lower) than our correlation estimate using BLUPs. However, if we consider confidence intervals as +/- 1.96 SE around the estimate, the lower bound of the confidence interval would actually be -0.0421. With confidence intervals straddling zero, we would conclude that this correlation is likely non-significant. As the use of standard errors in this way is only approximate, we should also test our hypothesis formally using likelihood ratio tests. 8.2.4.1.1 Hypothesis testing We can now test the statistical significance of this correlation directly, by fitting a second model without the among-individual covariance between our two traits, and then using a likelihood ratio test to determine whether the model with the covariance produces a better fit. Here, we use the idh structure for our random effects. This stands for ‚Äòidentity matrix‚Äô (i.e., with 0s on the off-diagonals) with heterogeneous variances (i.e., the variance components for our two response traits are allowed to be different from one another). The rest of the model is identical to the previous version. asr_idh &lt;- asreml( cbind(speed_sc, exploration_sc) ~ trait + trait:assay_rep_sc + trait:body_size_sc, random = ~ ID:idh(trait), residual = ~ units:us(trait), data = df_dragons, maxiter = 100 ) ## Model fitted using the sigma parameterization. ## ASReml 4.1.0 Wed Jan 17 14:11:29 2024 ## LogLik Sigma2 DF wall cpu ## 1 -327.051 1.0 634 14:11:29 0.0 ## 2 -299.874 1.0 634 14:11:29 0.0 ## 3 -273.689 1.0 634 14:11:29 0.0 ## 4 -260.838 1.0 634 14:11:29 0.0 ## 5 -257.331 1.0 634 14:11:29 0.0 ## 6 -257.120 1.0 634 14:11:29 0.0 ## 7 -257.118 1.0 634 14:11:29 0.0 The likelihood ratio test is calculated as twice the difference between model log-likelihoods, on a single degree of freedom (the covariance term): (p_biv &lt;- pchisq(2 * (asr_us$loglik - asr_idh$loglik), df = 1, lower.tail = FALSE )) ## [1] 0.1170385 In sharp contrast to the highly-significant P-value given by a correlation test using BLUPs, here we find no evidence for a correlation between flying speed and exploration. To better understand why BLUPs produce an anticonservative p-value in comparison to multivariate models, we should plot the correlation estimates and their confidence intervals. The confidence intervals are taken directly from the cor.test function for BLUPs, and for ASReml they are calculated as 1.96 times the standard error from the vpredict function. df_cor &lt;- data.frame( Method = c(&quot;ASReml&quot;, &quot;BLUPs&quot;), Correlation = c(as.numeric(cor_fe[1]), cor_blups$estimate), low = c(as.numeric(cor_fe[1] - 1.96 * cor_fe[2]), cor_blups$conf.int[1]), high = c(as.numeric(cor_fe[1] + 1.96 * cor_fe[2]), cor_blups$conf.int[2]) ) ggplot(df_cor, aes(x = Method, y = Correlation)) + geom_point() + geom_linerange(aes(ymin = low, ymax = high)) + ylim(-1, 1) + geom_hline(yintercept = 0, linetype = 2) + theme_classic() Figure 8.8: Correlation estimates (with CI) using 2 different methods Here we can clearly see that the BLUPs method - having failed to carry through the error around the predictions of individual-level estimates - is anticonservative, with small confidence intervals and a correspondingly small P-value (P = 0.00191). Testing the syndrome directly in a bivariate model that retains all the data, by comparison, enables us to capture the true uncertainty about the estimate of the correlation. This is reflected in the larger confidence intervals and, in this case, the non-significant P-value (P = 0.117). 8.2.4.1.2 Conclusions To conclude, then: we found that the correlation between flying speed and exploration tends to be positive among female blue dragon. This correlation is not statistically significant, and thus does not provide strong evidence. However, inappropriate analysis of BLUP extracted from univariate models would lead to a different (erroneous) conclusion. 8.2.4.2 Using MCMCglmm In this section I present the code needed to fit the model and explain only the specific aspect of fittign and evaluating the models with MCMCglmm. To be completed. with more details First, we need to create a ‚Äòprior‚Äô for our model. We recommend reading up on the use of priors (see the course notes of MCMCglmm Hadfield 2022); briefly, we use a parameter-expanded prior here that should be uninformative for our model. One of the model diagnostic steps that should be used later is to check that the model is robust to multiple prior specifications. prior_1ex &lt;- list( R = list(V = diag(2), nu = 0.002), G = list(G1 = list( V = diag(2) * 0.02, nu = 3, alpha.mu = rep(0, 2), alpha.V = diag(1000, 2, 2) )) ) mcmc_us &lt;- MCMCglmm(cbind(speed_sc, exploration_sc) ~ trait - 1 + trait:assay_rep_sc + trait:body_size_sc, random = ~ us(trait):ID, rcov = ~ us(trait):units, family = c(&quot;gaussian&quot;, &quot;gaussian&quot;), prior = prior_1ex, nitt = 420000, burnin = 20000, thin = 100, verbose = FALSE, data = df_dragons ) plot(mcmc_us$VCV[, c(1, 2, 4)]) Figure 8.9: MCMC trace and Posterior distribution of the (co)variance estimates of model mcmc_us plot(mcmc_us$VCV[, c(5, 6, 8)]) Figure 8.10: MCMC trace and Posterior distribution of the (co)variance estimates of model mcmc_us summary(mcmc_us) ## ## Iterations = 20001:419901 ## Thinning interval = 100 ## Sample size = 4000 ## ## DIC: 1596.532 ## ## G-structure: ~us(trait):ID ## ## post.mean l-95% CI u-95% CI eff.samp ## traitspeed_sc:traitspeed_sc.ID 0.38683 0.21533 0.5734 4000 ## traitexploration_sc:traitspeed_sc.ID 0.08094 -0.03047 0.2075 4000 ## traitspeed_sc:traitexploration_sc.ID 0.08094 -0.03047 0.2075 4000 ## traitexploration_sc:traitexploration_sc.ID 0.29561 0.15601 0.4674 4000 ## ## R-structure: ~us(trait):units ## ## post.mean l-95% CI u-95% CI eff.samp ## traitspeed_sc:traitspeed_sc.units 0.6393 0.5280 0.7595 4000 ## traitexploration_sc:traitspeed_sc.units 0.3347 0.2389 0.4325 4000 ## traitspeed_sc:traitexploration_sc.units 0.3347 0.2389 0.4325 4000 ## traitexploration_sc:traitexploration_sc.units 0.7338 0.5978 0.8588 4000 ## ## Location effects: cbind(speed_sc, exploration_sc) ~ trait - 1 + trait:assay_rep_sc + trait:body_size_sc ## ## post.mean l-95% CI u-95% CI eff.samp pMCMC ## traitspeed_sc 0.0001628 -0.1603883 0.1615571 4000 0.998 ## traitexploration_sc -0.0007606 -0.1554177 0.1500096 4000 0.996 ## traitspeed_sc:assay_rep_sc -0.0359780 -0.1146608 0.0392440 4000 0.367 ## traitexploration_sc:assay_rep_sc -0.0218757 -0.1055696 0.0588048 4000 0.621 ## traitspeed_sc:body_size_sc 0.1032654 -0.0536780 0.2660416 4000 0.205 ## traitexploration_sc:body_size_sc 0.0707995 -0.0932983 0.2144463 4345 0.343 mcmc_prop_f &lt;- mcmc_us$VCV[, 1] / (mcmc_us$VCV[, 1] + mcmc_us$VCV[, 5]) plot(mcmc_prop_f) Figure 8.11: Posterior trace and distribution of the repeatability in flying speed posterior.mode(mcmc_prop_f) ## var1 ## 0.3919935 HPDinterval(mcmc_prop_f) ## lower upper ## var1 0.2523954 0.4946682 ## attr(,&quot;Probability&quot;) ## [1] 0.95 mcmc_prop_e &lt;- mcmc_us$VCV[, 4] / (mcmc_us$VCV[, 4] + mcmc_us$VCV[, 8]) plot(mcmc_prop_e) Figure 8.12: Posterior trace and distribution of the repeatbility of exploration posterior.mode(mcmc_prop_e) ## var1 ## 0.2874671 HPDinterval(mcmc_prop_e) ## lower upper ## var1 0.1642797 0.4043109 ## attr(,&quot;Probability&quot;) ## [1] 0.95 mcmc_cor_fe &lt;- mcmc_us$VCV[, 2] / sqrt(mcmc_us$VCV[, 1] * mcmc_us$VCV[, 4]) plot(mcmc_cor_fe) Figure 8.13: Posterior trace and distribution of the correlation between flying speed and exploration posterior.mode(mcmc_cor_fe) ## var1 ## 0.2605385 HPDinterval(mcmc_cor_fe) ## lower upper ## var1 -0.08695933 0.5211489 ## attr(,&quot;Probability&quot;) ## [1] 0.95 df_cor[3, 1] &lt;- &quot;MCMCglmm&quot; df_cor[3, -1] &lt;- c(posterior.mode(mcmc_cor_fe), HPDinterval(mcmc_cor_fe)) rownames(df_cor) &lt;- NULL ggplot(df_cor, aes(x = Method, y = Correlation)) + geom_point() + geom_linerange(aes(ymin = low, ymax = high)) + ylim(-1, 1) + geom_hline(yintercept = 0, linetype = 2) + theme_classic() Figure 8.14: Correlation estimates (with CI) using 3 different methods Table 8.3: Correlation (with 95% intervals) between flying speed and exploration estimated with 3 different methods Method Correlation low high ASReml 0.270 -0.042 0.583 BLUPs 0.342 0.132 0.522 MCMCglmm 0.261 -0.087 0.521 8.2.5 Happy multivariate models Figure 8.15: A female blue dragon of the West References "],["9-random-regression-and-character-state-approaches.html", "9 Random regression and character state approaches ", " 9 Random regression and character state approaches "],["9.1-lecture-8.html", "9.1 Lecture", " 9.1 Lecture Amazing beasties and crazy animals Figure 9.1: Dream pet dragon "],["9.2-practical-6.html", "9.2 Practical", " 9.2 Practical In this practical, we will revisit our analysis on unicorn aggressivity. Honestly, we can use any other data with repeated measures for this exercise but I just ‚ù§Ô∏è unicorns. 9.2.1 R packages needed First we load required libraries library(lme4) library(tidyverse) library(broom.mixed) library(asreml) library(MCMCglmm) library(bayesplot) 9.2.2 Refresher on unicorn aggression In the previous, practical on linear mixed models, we simply explored the differences among individuals in their mean aggression (Intercept), but we assumed that the response to the change in aggression with the opponent size (i.e.¬†plasticity) was the same for all individuals. However, this plastic responses can also vary amon individuals. This is called IxE, or individual by environment interaction. To test if individuals differ in their plasticity we can use a random regression, whcih is simply a mixed-model where we fit both a random intercept and a random slope effect. Following analysis from the previous pratical, our model of interest using scaled covariate was: aggression ~ opp_size + body_size_sc + assay_rep_sc + block + (1 | ID) We should start by loading the data and refitting the model using lmer(). unicorns &lt;- read.csv(&quot;data/unicorns_aggression.csv&quot;) unicorns &lt;- unicorns %&gt;% mutate( body_size_sc = scale(body_size), assay_rep_sc = scale(assay_rep, scale = FALSE) ) m_mer &lt;- lmer( aggression ~ opp_size + body_size_sc + assay_rep_sc + block + (1 | ID), data = unicorns ) summary(m_mer) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;] ## Formula: aggression ~ opp_size + body_size_sc + assay_rep_sc + block + (1 | ID) ## Data: unicorns ## ## REML criterion at convergence: 1136.5 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.85473 -0.62831 0.02545 0.68998 2.74064 ## ## Random effects: ## Groups Name Variance Std.Dev. ## ID (Intercept) 0.02538 0.1593 ## Residual 0.58048 0.7619 ## Number of obs: 480, groups: ID, 80 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 9.00181 0.03907 78.07315 230.395 &lt;2e-16 *** ## opp_size 1.05141 0.04281 396.99857 24.562 &lt;2e-16 *** ## body_size_sc 0.03310 0.03896 84.21144 0.850 0.398 ## assay_rep_sc -0.05783 0.04281 396.99857 -1.351 0.177 ## block -0.02166 0.06955 397.00209 -0.311 0.756 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) opp_sz bdy_s_ assy__ ## opp_size 0.000 ## body_siz_sc 0.000 0.000 ## assay_rp_sc 0.000 -0.100 0.000 ## block 0.000 0.000 0.002 0.000 We can now plot the predictions for each of our observations and plot for the observed and the fitted data for each individuals. Todo so we will use the augment() function from the üì¶ broom.mixed. Below, we plot the raw data for each individual in one panel, with the fitted slopes in a second panel. Because we have 2 blocks of data, and block is fitted as a fixed effect, for ease of presentation we need to either select only 1 block for representation, take teh avaerage over the block effect or do a more complex graph with the two blocks. Here I have selected only one of the blocks for this plot pred_m_mer &lt;- augment(m_mer) %&gt;% select(ID, block, opp_size, .fitted, aggression) %&gt;% filter(block == -0.5) %&gt;% gather( type, aggression, `.fitted`:aggression ) ggplot(pred_m_mer, aes(x = opp_size, y = aggression, group = ID)) + geom_line(alpha = 0.3) + theme_classic() + facet_grid(. ~ type) Figure 9.2: Predicted (from m_mer) and observed value of aggression as a function of opponent size in unicorns This illustrates the importance of using model predictions to see whether the model actually fits the individual-level data well or not ‚Äî while the diagnostic plots looked fine, and the model captures mean plasticity, here we can see that the model really doesn‚Äôt fit the actual data very well at all. 9.2.3 Random regression 9.2.3.1 with lme4 rr_mer &lt;- lmer( aggression ~ opp_size + body_size_sc + assay_rep_sc + block + (1 + opp_size | ID), data = unicorns ) pred_rr_mer &lt;- augment(rr_mer) %&gt;% select(ID, block, opp_size, .fitted, aggression) %&gt;% filter(block == -0.5) %&gt;% gather(type,aggression, `.fitted`:aggression) ggplot(pred_rr_mer, aes(x = opp_size, y = aggression, group = ID)) + geom_line(alpha = 0.3) + theme_classic() + facet_grid(. ~ type) We can test the improvement of the model fit using the overloaded anova function in R to perform a likelihood ratio test (LRT): anova(rr_mer, m_mer, refit = FALSE) npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) m_mer 7 1150.477 1179.693 -568.2383 1136.477 NA NA NA rr_mer 9 1092.356 1129.920 -537.1780 1074.356 62.1206 2 0 We can see here that the LRT uses a chi-square test with 2 degrees of freedom, and indicates that the random slopes model shows a statistically significant improvement in model fit. The 2df are because there are two additional (co)variance terms estimated in the random regression model: a variance term for individual slopes, and the covariance (or correlation) between the slopes and intercepts. Let‚Äôs look at those values, and also the fixed effects parameters, via the model summary: summary(rr_mer) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;] ## Formula: aggression ~ opp_size + body_size_sc + assay_rep_sc + block + (1 + opp_size | ID) ## Data: unicorns ## ## REML criterion at convergence: 1074.4 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.04932 -0.59780 -0.02002 0.59574 2.68010 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## ID (Intercept) 0.05043 0.2246 ## opp_size 0.19167 0.4378 0.96 ## Residual 0.42816 0.6543 ## Number of obs: 480, groups: ID, 80 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 9.00181 0.03902 78.44088 230.707 &lt;2e-16 *** ## opp_size 1.05033 0.06123 79.50694 17.153 &lt;2e-16 *** ## body_size_sc 0.02725 0.03377 84.34959 0.807 0.422 ## assay_rep_sc -0.04702 0.03945 387.69415 -1.192 0.234 ## block -0.02169 0.05973 318.19553 -0.363 0.717 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) opp_sz bdy_s_ assy__ ## opp_size 0.495 ## body_siz_sc 0.000 0.000 ## assay_rp_sc 0.000 -0.064 -0.006 ## block 0.000 0.000 0.002 0.000 9.2.3.2 with asreml unicorns &lt;- unicorns %&gt;% mutate( ID = as.factor(ID)) rr_asr &lt;- asreml( aggression ~ opp_size + body_size_sc + assay_rep_sc + block, random = ~str(~ ID + ID:opp_size, ~us(2):id(ID)), residual = ~ units, data = unicorns, maxiter = 200 ) ## Model fitted using the gamma parameterization. ## ASReml 4.1.0 Wed Jan 17 14:13:39 2024 ## LogLik Sigma2 DF wall cpu ## 1 -109.426 0.463232 475 14:13:39 0.0 ## 2 -105.050 0.454593 475 14:13:39 0.0 ## 3 -101.814 0.443662 475 14:13:39 0.0 ## 4 -100.814 0.433873 475 14:13:39 0.0 ## 5 -100.683 0.428596 475 14:13:39 0.0 ## 6 -100.682 0.428170 475 14:13:39 0.0 plot(rr_asr) summary(rr_asr, coef = TRUE)$coef.fixed ## solution std error z.ratio ## block -0.02168725 0.05973354 -0.3630665 ## assay_rep_sc -0.04702032 0.03944594 -1.1920191 ## body_size_sc 0.02725092 0.03377443 0.8068506 ## opp_size 1.05032703 0.06123110 17.1534907 ## (Intercept) 9.00181250 0.03901766 230.7112239 wald(rr_asr, ssType = &quot;conditional&quot;, denDF = &quot;numeric&quot;) ## Model fitted using the gamma parameterization. ## ASReml 4.1.0 Wed Jan 17 14:13:40 2024 ## LogLik Sigma2 DF wall cpu ## 1 -100.682 0.428168 475 14:13:40 0.0 ## 2 -100.682 0.428168 475 14:13:40 0.0 ## Calculating denominator DF ## $Wald ## [0;34m ## Wald tests for fixed effects.[0m ## [0;34mResponse: aggression[0m ## ## Df denDF F.inc F.con Margin Pr ## (Intercept) 1 78.3 65490 53230 0.00000 ## opp_size 1 79.5 293 294 A 0.00000 ## body_size_sc 1 84.3 1 1 A 0.42202 ## assay_rep_sc 1 387.6 1 1 A 0.23398 ## block 1 318.1 0 0 A 0.71680 ## ## $stratumVariances ## df Variance ID+ID:opp_size!us(2)_1:1 ID+ID:opp_size!us(2)_2:1 ID+ID:opp_size!us(2)_2:2 units!R ## ID+ID:opp_size!us(2)_1:1 78.00483 0.4790737 5.216311 -3.301137 0.5221955 1 ## ID+ID:opp_size!us(2)_2:1 0.00000 0.0000000 0.000000 0.000000 0.0000000 1 ## ID+ID:opp_size!us(2)_2:2 78.94046 1.1937287 0.000000 0.000000 3.9943993 1 ## units!R 318.05470 0.4281680 0.000000 0.000000 0.0000000 1 summary(rr_asr)$varcomp ## component std.error z.ratio bound %ch ## ID+ID:opp_size!us(2)_1:1 0.05042932 0.02027564 2.487187 P 0 ## ID+ID:opp_size!us(2)_2:1 0.09458336 0.02400745 3.939751 P 0 ## ID+ID:opp_size!us(2)_2:2 0.19165924 0.04832059 3.966409 P 0 ## units!R 0.42816954 0.03395320 12.610582 P 0 rio_asr &lt;- asreml( aggression ~ opp_size + body_size_sc + assay_rep_sc + block, random = ~ ID, residual = ~units, data = unicorns, maxiter = 200 ) ## Model fitted using the gamma parameterization. ## ASReml 4.1.0 Wed Jan 17 14:13:40 2024 ## LogLik Sigma2 DF wall cpu ## 1 -132.611 0.560353 475 14:13:40 0.0 ## 2 -132.106 0.567043 475 14:13:40 0.0 ## 3 -131.796 0.575157 475 14:13:40 0.0 ## 4 -131.743 0.580762 475 14:13:40 0.0 ## 5 -131.742 0.580480 475 14:13:40 0.0 pchisq(2 * (rr_asr$loglik - rio_asr$loglik), 2, lower.tail = FALSE ) ## [1] 3.241026e-14 vpredict(rr_asr, cor_is ~ V2 / (sqrt(V1) * sqrt(V3))) ## Estimate SE ## cor_is 0.9620736 0.1773965 pred_rr_asr &lt;- as.data.frame(predict(rr_asr, classify = &quot;opp_size:ID&quot;, levels = list( &quot;opp_size&quot; = c(opp_size = -1:1) ) )$pvals) ## Model fitted using the gamma parameterization. ## ASReml 4.1.0 Wed Jan 17 14:13:41 2024 ## LogLik Sigma2 DF wall cpu ## 1 -100.682 0.428168 475 14:13:41 0.1 ## 2 -100.682 0.428168 475 14:13:41 0.0 ## 3 -100.682 0.428168 475 14:13:41 0.0 p_rr &lt;- ggplot(pred_rr_asr, aes(x = opp_size, y = predicted.value, group = ID)) + geom_line(alpha = 0.2) + scale_x_continuous(breaks = c(-1, 0, 1)) + labs( x = &quot;Opponent size (SDU)&quot;, y = &quot;Aggression&quot; ) + theme_classic() p_rr 9.2.3.3 with MCMCglmm prior_RR &lt;- list( R = list(V = 1, nu = 0.002), G = list( G1 = list(V = diag(2)*0.02, nu = 3, alpha.mu = rep(0, 2), alpha.V= diag(1000, 2, 2)))) rr_mcmc &lt;- MCMCglmm( aggression ~ opp_size + assay_rep_sc + body_size_sc + block, random = ~ us(1 + opp_size):ID, rcov = ~ units, family = &quot;gaussian&quot;, prior = prior_RR, nitt=750000, burnin=50000, thin=350, verbose = FALSE, data = unicorns, pr = TRUE, saveX = TRUE, saveZ = TRUE) plot(rr_mcmc$VCV) posterior.mode(rr_mcmc$VCV[, &quot;opp_size:opp_size.ID&quot;]) # mean ## var1 ## 0.2040523 HPDinterval(rr_mcmc$VCV[, &quot;opp_size:opp_size.ID&quot;]) ## lower upper ## var1 0.1172616 0.3094872 ## attr(,&quot;Probability&quot;) ## [1] 0.95 rr_cor_mcmc &lt;- rr_mcmc$VCV[, &quot;opp_size:(Intercept).ID&quot;] / (sqrt(rr_mcmc$VCV[, &quot;(Intercept):(Intercept).ID&quot;]) * sqrt(rr_mcmc$VCV[, &quot;opp_size:opp_size.ID&quot;])) posterior.mode(rr_cor_mcmc) ## var1 ## 0.8466038 HPDinterval(rr_cor_mcmc) ## lower upper ## var1 0.5169232 0.9749839 ## attr(,&quot;Probability&quot;) ## [1] 0.95 df_rand &lt;- cbind(unicorns, rr_fit = predict(rr_mcmc, marginal = NULL) ) %&gt;% select(ID, opp_size, rr_fit, aggression) %&gt;% group_by(ID, opp_size) %&gt;% summarise( rr_fit = mean(rr_fit), aggression = mean(aggression) ) %&gt;% gather( Type, Value, rr_fit:aggression ) ## `summarise()` has grouped output by &#39;ID&#39;. You can override using the `.groups` argument. # Plot separate panels for individual lines of each type ggplot(df_rand, aes(x = opp_size, y = Value, group = ID)) + geom_line(alpha = 0.3) + scale_x_continuous(breaks = c(-1, 0, 1)) + theme_classic() + facet_grid(. ~ Type) Table 9.1: Variance estimated from random regression models using 3 different softwares Method v_int cov v_sl v_r lmer 0.0504347 0.0945863 0.1916653 0.4281625 asreml 0.0504293 0.0945834 0.1916592 0.4281695 MCMCglmm 0.0446102 0.0768445 0.2040523 0.4181750 9.2.4 Character-State approach Need to pivot to a wider format unicorns_cs &lt;- unicorns %&gt;% select(ID, body_size, assay_rep, block, aggression, opp_size) %&gt;% mutate( opp_size = recode(as.character(opp_size), &quot;-1&quot; = &quot;s&quot;, &quot;0&quot; = &quot;m&quot;, &quot;1&quot; = &quot;l&quot;) ) %&gt;% dplyr::rename(agg = aggression) %&gt;% pivot_wider(names_from = opp_size, values_from = c(agg, assay_rep)) %&gt;% mutate( body_size_sc = scale(body_size), opp_order = as.factor(paste(assay_rep_s, assay_rep_m, assay_rep_l, sep = &quot;_&quot;)) ) str(unicorns_cs) ## tibble [160 √ó 11] (S3: tbl_df/tbl/data.frame) ## $ ID : Factor w/ 80 levels &quot;ID_1&quot;,&quot;ID_10&quot;,..: 1 1 2 2 3 3 4 4 5 5 ... ## $ body_size : num [1:160] 206 207 283 288 229 ... ## $ block : num [1:160] -0.5 0.5 -0.5 0.5 -0.5 0.5 -0.5 0.5 -0.5 0.5 ... ## $ agg_s : num [1:160] 7.02 8.44 7.73 8.08 8.06 8.16 8.16 8.51 7.59 6.67 ... ## $ agg_l : num [1:160] 10.67 10.51 10.81 10.67 9.77 ... ## $ agg_m : num [1:160] 10.22 8.95 9.43 9.46 7.63 ... ## $ assay_rep_s : int [1:160] 1 3 2 2 1 1 3 3 1 1 ... ## $ assay_rep_l : int [1:160] 2 2 1 1 2 2 2 1 2 2 ... ## $ assay_rep_m : int [1:160] 3 1 3 3 3 3 1 2 3 3 ... ## $ body_size_sc: num [1:160, 1] -1.504 -1.456 0.988 1.143 -0.76 ... ## ..- attr(*, &quot;scaled:center&quot;)= num 253 ## ..- attr(*, &quot;scaled:scale&quot;)= num 31.1 ## $ opp_order : Factor w/ 6 levels &quot;1_2_3&quot;,&quot;1_3_2&quot;,..: 2 5 4 4 2 2 5 6 2 2 ... head(unicorns_cs) ## # A tibble: 6 √ó 11 ## ID body_size block agg_s agg_l agg_m assay_rep_s assay_rep_l assay_rep_m body_size_sc[,1] opp_order ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;fct&gt; ## 1 ID_1 206. -0.5 7.02 10.7 10.2 1 2 3 -1.50 1_3_2 ## 2 ID_1 207. 0.5 8.44 10.5 8.95 3 2 1 -1.46 3_1_2 ## 3 ID_10 283. -0.5 7.73 10.8 9.43 2 1 3 0.988 2_3_1 ## 4 ID_10 288 0.5 8.08 10.7 9.46 2 1 3 1.14 2_3_1 ## 5 ID_11 229. -0.5 8.06 9.77 7.63 1 2 3 -0.760 1_3_2 ## 6 ID_11 236. 0.5 8.16 10.8 8.23 1 2 3 -0.525 1_3_2 cs_asr &lt;- asreml( cbind(agg_s, agg_m, agg_l) ~ trait + trait:body_size_sc + trait:block + trait:opp_order, random =~ ID:us(trait), residual =~ units:us(trait), data = unicorns_cs, maxiter = 200 ) ## Model fitted using the sigma parameterization. ## ASReml 4.1.0 Wed Jan 17 14:17:13 2024 ## LogLik Sigma2 DF wall cpu ## 1 -150.172 1.0 456 14:17:13 0.0 ## 2 -129.658 1.0 456 14:17:13 0.0 ## 3 -110.454 1.0 456 14:17:13 0.0 ## 4 -101.879 1.0 456 14:17:13 0.0 ## 5 -100.092 1.0 456 14:17:13 0.0 ## 6 -100.054 1.0 456 14:17:13 0.0 ## 7 -100.054 1.0 456 14:17:13 0.0 plot(residuals(cs_asr) ~ fitted(cs_asr)) qqnorm(residuals(cs_asr)) qqline(residuals(cs_asr)) hist(residuals(cs_asr)) summary(cs_asr, all = T)$coef.fixed ## NULL wald(cs_asr, ssType = &quot;conditional&quot;, denDF = &quot;numeric&quot;) ## Model fitted using the sigma parameterization. ## ASReml 4.1.0 Wed Jan 17 14:17:13 2024 ## LogLik Sigma2 DF wall cpu ## 1 -100.054 1.0 456 14:17:13 0.0 ## 2 -100.054 1.0 456 14:17:13 0.0 ## Calculating denominator DF ## $Wald ## [0;34m ## Wald tests for fixed effects.[0m ## [0;34mResponse: cbind(agg_s, agg_m, agg_l)[0m ## ## Df denDF F.inc F.con Margin Pr ## trait 3 73.2 21080.0 21080.0 0.00000 ## trait:body_size_sc 3 86.6 0.4 0.5 B 0.68324 ## trait:block 3 75.2 0.6 0.3 B 0.82418 ## trait:opp_order 15 240.5 1.3 1.3 B 0.23282 ## ## $stratumVariances ## NULL summary(cs_asr)$varcomp[, c(&quot;component&quot;, &quot;std.error&quot;)] ## component std.error ## ID:trait!trait_agg_s:agg_s 0.192959991 0.06321872 ## ID:trait!trait_agg_m:agg_s -0.168519644 0.05085583 ## ID:trait!trait_agg_m:agg_m 0.245594370 0.07096325 ## ID:trait!trait_agg_l:agg_s -0.151990204 0.05660748 ## ID:trait!trait_agg_l:agg_m 0.158418588 0.06374995 ## ID:trait!trait_agg_l:agg_l 0.312548090 0.09125168 ## units:trait!R 1.000000000 NA ## units:trait!trait_agg_s:agg_s 0.318089965 0.05198135 ## units:trait!trait_agg_m:agg_s 0.010362390 0.03695483 ## units:trait!trait_agg_m:agg_m 0.322379911 0.05248291 ## units:trait!trait_agg_l:agg_s -0.009311656 0.04168455 ## units:trait!trait_agg_l:agg_m 0.159240476 0.04569305 ## units:trait!trait_agg_l:agg_l 0.405942147 0.06679700 cs_idh_asr &lt;- asreml( cbind(agg_s, agg_m, agg_l) ~ trait + trait:body_size_sc + trait:block + trait:opp_order, random = ~ ID:idh(trait), residual = ~ units:us(trait), data = unicorns_cs, maxiter = 200 ) ## Model fitted using the sigma parameterization. ## ASReml 4.1.0 Wed Jan 17 14:17:14 2024 ## LogLik Sigma2 DF wall cpu ## 1 -147.068 1.0 456 14:17:14 0.0 ## 2 -131.268 1.0 456 14:17:14 0.0 ## 3 -116.908 1.0 456 14:17:14 0.0 ## 4 -110.996 1.0 456 14:17:14 0.0 ## 5 -109.905 1.0 456 14:17:14 0.0 ## 6 -109.866 1.0 456 14:17:14 0.0 ## 7 -109.863 1.0 456 14:17:14 0.0 pchisq(2 * (cs_asr$loglik - cs_idh_asr$loglik), 3, lower.tail = FALSE ) ## [1] 0.0002038324 vpredict(cs_asr, cor_S_M ~ V2 / (sqrt(V1) * sqrt(V3))) ## Estimate SE ## cor_S_M -0.7741189 0.1869789 vpredict(cs_asr, cor_M_L ~ V5 / (sqrt(V3) * sqrt(V6))) ## Estimate SE ## cor_M_L 0.5717926 0.1469504 vpredict(cs_asr, cor_S_L ~ V4 / (sqrt(V1) * sqrt(V6))) ## Estimate SE ## cor_S_L -0.6189044 0.1912133 vpredict(cs_asr, prop_S ~ V1 / (V1 + V8)) ## Estimate SE ## prop_S 0.3775756 0.09950306 vpredict(cs_asr, prop_M ~ V3 / (V3 + V10)) ## Estimate SE ## prop_M 0.432404 0.0934477 vpredict(cs_asr, prop_L ~ V6 / (V6 + V13)) ## Estimate SE ## prop_L 0.4350067 0.09498512 init_CS_cor1_tri &lt;- c( 0.999, 0.999, 0.999, 1, 1, 1 ) names(init_CS_cor1_tri) &lt;- c( &quot;F&quot;, &quot;F&quot;, &quot;F&quot;, &quot;U&quot;, &quot;U&quot;, &quot;U&quot; ) cs_asr_cor1_tri &lt;- asreml( cbind(agg_s, agg_m, agg_l) ~ trait + trait:body_size_sc + trait:block + trait:opp_order, random = ~ ID:corgh(trait, init = init_CS_cor1_tri), residual = ~ units:us(trait), data = unicorns_cs, maxiter = 500 ) ## Model fitted using the sigma parameterization. ## ASReml 4.1.0 Wed Jan 17 14:17:14 2024 ## LogLik Sigma2 DF wall cpu ## 1 -228.016 1.0 456 14:17:14 0.0 (3 restrained) ## 2 -150.014 1.0 456 14:17:14 0.0 ## 3 -129.580 1.0 456 14:17:14 0.0 ## 4 -119.992 1.0 456 14:17:14 0.0 (1 restrained) ## 5 -116.907 1.0 456 14:17:14 0.0 (1 restrained) ## 6 -115.772 1.0 456 14:17:14 0.0 ## 7 -115.647 1.0 456 14:17:14 0.0 ## 8 -115.588 1.0 456 14:17:14 0.0 ## 9 -115.533 1.0 456 14:17:14 0.0 ## 10 -115.479 1.0 456 14:17:14 0.0 ## 11 -115.427 1.0 456 14:17:14 0.0 ## 12 -115.378 1.0 456 14:17:14 0.0 ## 13 -115.331 1.0 456 14:17:14 0.0 ## 14 -115.289 1.0 456 14:17:14 0.0 ## 15 -115.251 1.0 456 14:17:14 0.0 ## 16 -115.217 1.0 456 14:17:14 0.0 ## 17 -115.188 1.0 456 14:17:14 0.0 ## 18 -115.162 1.0 456 14:17:14 0.0 ## 19 -115.141 1.0 456 14:17:14 0.0 ## 20 -115.122 1.0 456 14:17:14 0.0 ## 21 -115.107 1.0 456 14:17:14 0.0 ## 22 -115.093 1.0 456 14:17:14 0.0 ## 23 -115.082 1.0 456 14:17:14 0.0 ## 24 -115.073 1.0 456 14:17:14 0.0 (1 restrained) ## 25 -115.064 1.0 456 14:17:14 0.0 ## 26 -115.064 1.0 456 14:17:14 0.0 pchisq(2 * (cs_asr$loglik - cs_asr_cor1_tri$loglik), 3, lower.tail = FALSE ) ## [1] 1.367792e-06 df_CS_pred &lt;- as.data.frame(predict(cs_asr, classify = &quot;trait:ID&quot; )$pvals) ## Model fitted using the sigma parameterization. ## ASReml 4.1.0 Wed Jan 17 14:17:15 2024 ## LogLik Sigma2 DF wall cpu ## 1 -100.054 1.0 456 14:17:15 0.1 ## 2 -100.054 1.0 456 14:17:15 0.0 ## 3 -100.054 1.0 456 14:17:15 0.0 # Add numeric variable for easier plotting # of opponent size df_CS_pred &lt;- df_CS_pred %&gt;% mutate(sizeNum = ifelse(trait == &quot;agg_s&quot;, -1, ifelse(trait == &quot;agg_m&quot;, 0, 1) )) p_cs &lt;- ggplot(df_CS_pred, aes( x = sizeNum, y = predicted.value, group = ID )) + geom_line(alpha = 0.2) + scale_x_continuous(breaks = c(-1, 0, 1)) + labs( x = &quot;Opponent size (SDU)&quot;, y = &quot;Aggression&quot; ) + theme_classic() p_cs unicorns &lt;- arrange(unicorns, opp_size, by_group = ID) p_obs &lt;- ggplot(unicorns[unicorns$block==-0.5,], aes(x = opp_size, y = aggression, group = ID)) + geom_line(alpha = 0.3) + scale_x_continuous(breaks = c(-1, 0, 1)) + labs( x = &quot;Opponent size (SDU)&quot;, y = &quot;Aggression&quot; ) + ggtitle(&quot;Observed&quot;) + ylim(5.9, 12) + theme_classic() p_rr &lt;- p_rr + ggtitle(&quot;Random regression&quot;) + ylim(5.9, 12) p_cs &lt;- p_cs + ggtitle(&quot;Character-State&quot;) + ylim(5.9, 12) p_obs + p_rr + p_cs ## Warning: Removed 2 rows containing missing ## values (`geom_line()`). 9.2.5 From random regression to character-state var_mat_asr &lt;- function(model, var_names, pos){ size &lt;- length(var_names) v_out &lt;- matrix(NA, ncol = size, nrow = size) rownames(v_out) &lt;- var_names colnames(v_out) &lt;- var_names v_out[upper.tri(v_out, diag = TRUE)] &lt;- summary(model)$varcomp[pos, 1] v_out &lt;- forceSymmetric(v_out, uplo = &quot;U&quot;) as.matrix(v_out) } v_id_rr &lt;- var_mat_asr(rr_asr, c(&quot;v_int&quot;, &quot;v_sl&quot;), 1:3) knitr::kable(v_id_rr, digits = 3) v_int v_sl v_int 0.050 0.095 v_sl 0.095 0.192 v_id_cs &lt;- var_mat_asr(cs_asr, c(&quot;v_s&quot;, &quot;v_m&quot;, &quot;v_l&quot;), 1:6) knitr::kable(v_id_cs, digits = 3) v_s v_m v_l v_s 0.193 -0.169 -0.152 v_m -0.169 0.246 0.158 v_l -0.152 0.158 0.313 We also need to make a second matrix, let‚Äôs call it Q (no particular reason, pick something else if you want). This is going to contain the values needed to turn an individual‚Äôs intercept (mean) and slope (plasticity) deviations into estimates of environment-specific individual merit in a character state model. What do we mean by this? Well if an individual i has an intercept deviation of IDint(i) and a slope deviation of IDslp(i) for a given value of the environment opp_size we might be interested in: IDi = (1 x IDint(i)) + (opp_size x IDslp(i)) We want to look at character states representing the three observed values of opp_size here so Q &lt;- as.matrix(cbind(c(1, 1, 1), c(-1, 0, 1))) Then we can generate our among-individual covariance matrix environment specific aggresiveness, which we can call ID_cs_rr by matrix multiplication: ID_cs_rr&lt;- Q %*% v_id_rr %*%t(Q) #where t(Q) is the transpose of Q #and %*% is matrix multiplication ID_cs_rr #rows and columns correspond to aggressiveness at opp_size=-1,0,1 in that order ## [,1] [,2] [,3] ## [1,] 0.05292184 -0.04415404 -0.1412299 ## [2,] -0.04415404 0.05042932 0.1450127 ## [3,] -0.14122993 0.14501267 0.4312553 cov2cor(ID_cs_rr) #Converting to a correlation scale ## [,1] [,2] [,3] ## [1,] 1.0000000 -0.8546956 -0.9348503 ## [2,] -0.8546956 1.0000000 0.9833253 ## [3,] -0.9348503 0.9833253 1.0000000 cov2cor(v_id_cs) ## v_s v_m v_l ## v_s 1.0000000 -0.7741189 -0.6189044 ## v_m -0.7741189 1.0000000 0.5717926 ## v_l -0.6189044 0.5717926 1.0000000 9.2.6 Conclusions 9.2.7 Happy multivariate models Figure 9.3: A female blue dragon of the West "],["10-beyond-p-0.html", "10 Beyond P &lt; 0.05", " 10 Beyond P &lt; 0.05 cite a bunch a must read paper on the subject and maybe summarize the big point of Do and Don‚Äôt library(ggplot2) alpha &lt;- 0.05 beta &lt;- 0.2 p_h1_true &lt;- seq(0, 1, length = 100) p_fp &lt;- alpha * (1 - p_h1_true) / (alpha * (1 - p_h1_true) + (1 - beta) * p_h1_true) p_fn &lt;- beta * p_h1_true / (beta * p_h1_true + (1 - alpha) * (1 - p_h1_true)) dat &lt;- rbind( data.frame(p_h1 = p_h1_true, prob = p_fp, result = &quot;positive&quot; ), data.frame(p_h1 = p_h1_true, prob = p_fn, result = &quot;negative&quot;) ) ggplot(dat, aes(x = p_h1, y = prob, colour = result)) + geom_line() + geom_vline(xintercept = 0.5, linetype = 2) + xlab(&quot;Probability alternative hypothesis is true&quot;) + ylab(&quot;Probabilitity of false results&quot;) + xlim(0, 1) + theme_classic() "],["11-pca.html", "11 PCA", " 11 PCA grabbed from http://www.sthda.com/english/articles/31-principal-component-methods-in-r-practical-guide/112-pca-principal-component-analysis-essentials/ need to be modified and personnalized and give credit to It "],["11.1-lecture-9.html", "11.1 Lecture", " 11.1 Lecture Basics. Understanding the details of PCA requires knowledge of linear algebra. Here, we‚Äôll explain only the basics with simple graphical representation of the data. In the Plot 1A below, the data are represented in the X-Y coordinate system. The dimension reduction is achieved by identifying the principal directions, called principal components, in which the data varies. PCA assumes that the directions with the largest variances are the most ‚Äúimportant‚Äù (i.e, the most principal). In the figure below, the PC1 axis is the first principal direction along which the samples show the largest variation. The PC2 axis is the second most important direction and it is orthogonal to the PC1 axis. The dimensionality of our two-dimensional data can be reduced to a single dimension by projecting each sample onto the first principal component (Plot 1B) Technically speaking, the amount of variance retained by each principal component is measured by the so-called eigenvalue. Note that, the PCA method is particularly useful when the variables within the data set are highly correlated. Correlation indicates that there is redundancy in the data. Due to this redundancy, PCA can be used to reduce the original variables into a smaller number of new variables ( = principal components) explaining most of the variance in the original variables. ::: {.infobox .important data-latex = ‚Äúimportant‚Äù} Taken together, the main purpose of principal component analysis is to: identify hidden pattern in a data set, reduce the dimensionnality of the data by removing the noise and redundancy in the data, identify correlated variables ::: "],["11.2-practical-7.html", "11.2 Practical", " 11.2 Practical Several functions from different packages are available in the R software for computing PCA: prcomp() and princomp() [built-in R stats package], PCA() [FactoMineR package], dudi.pca() [ade4 package], and epPCA() [ExPosition package] No matter what function you decide to use, you can easily extract and visualize the results of PCA using R functions provided in the factoextra R package. library(&quot;FactoMineR&quot;) library(&quot;factoextra&quot;) ## Welcome! Want to learn more? See two factoextra-related books at https://goo.gl/ve3WBa Data format We‚Äôll use the demo data sets decathlon2 from the factoextra package: data(decathlon2) head(decathlon2) ## X100m Long.jump Shot.put High.jump X400m X110m.hurdle Discus Pole.vault Javeline X1500m Rank Points Competition ## SEBRLE 11.04 7.58 14.83 2.07 49.81 14.69 43.75 5.02 63.19 291.7 1 8217 Decastar ## CLAY 10.76 7.40 14.26 1.86 49.37 14.05 50.72 4.92 60.15 301.5 2 8122 Decastar ## BERNARD 11.02 7.23 14.25 1.92 48.93 14.99 40.87 5.32 62.77 280.1 4 8067 Decastar ## YURKOV 11.34 7.09 15.19 2.10 50.42 15.31 46.26 4.72 63.44 276.4 5 8036 Decastar ## ZSIVOCZKY 11.13 7.30 13.48 2.01 48.62 14.17 45.67 4.42 55.37 268.0 7 8004 Decastar ## McMULLEN 10.83 7.31 13.76 2.13 49.91 14.38 44.41 4.42 56.37 285.1 8 7995 Decastar As illustrated in Figure 3.1, the data used here describes athletes‚Äô performance during two sporting events (Desctar and OlympicG). It contains 27 individuals (athletes) described by 13 variables. The function PCA() [FactoMineR package] can be used. A simplified format is : PCA(X, scale.unit = TRUE, ncp = 5, graph = TRUE) X: a data frame. Rows are individuals and columns are numeric variables scale.unit: a logical value. If TRUE, the data are scaled to unit variance before the analysis. This standardization to the same scale avoids some variables to become dominant just because of their large measurement units. It makes variable comparable. ncp: number of dimensions kept in the final results. graph: a logical value. If TRUE a graph is displayed. The R code below, computes principal component analysis on the active individuals/variables: library(‚ÄúFactoMineR‚Äù) res.pca &lt;- PCA(decathlon2.active, graph = FALSE) The output of the function PCA() is a list, including the following components : print(res.pca) Visualization and Interpretation We‚Äôll use the factoextra R package to help in the interpretation of PCA. No matter what function you decide to use [stats::prcomp(), FactoMiner::PCA(), ade4::dudi.pca(), ExPosition::epPCA()], you can easily extract and visualize the results of PCA using R functions provided in the factoextra R package. These functions include: get_eigenvalue(res.pca): Extract the eigenvalues/variances of principal components fviz_eig(res.pca): Visualize the eigenvalues get_pca_ind(res.pca), get_pca_var(res.pca): Extract the results for individuals and variables, respectively. fviz_pca_ind(res.pca), fviz_pca_var(res.pca): Visualize the results individuals and variables, respectively. fviz_pca_biplot(res.pca): Make a biplot of individuals and variables. In the next sections, we‚Äôll illustrate each of these functions. Eigenvalues / Variances As described in previous sections, the eigenvalues measure the amount of variation retained by each principal component. Eigenvalues are large for the first PCs and small for the subsequent PCs. That is, the first PCs corresponds to the directions with the maximum amount of variation in the data set. We examine the eigenvalues to determine the number of principal components to be considered. The eigenvalues and the proportion of variances (i.e., information) retained by the principal components (PCs) can be extracted using the function get_eigenvalue() [factoextra package]. library(‚Äúfactoextra‚Äù) eig.val &lt;- get_eigenvalue(res.pca) eig.val The sum of all the eigenvalues give a total variance of 10. The proportion of variation explained by each eigenvalue is given in the second column. For example, 4.124 divided by 10 equals 0.4124, or, about 41.24% of the variation is explained by this first eigenvalue. The cumulative percentage explained is obtained by adding the successive proportions of variation explained to obtain the running total. For instance, 41.242% plus 18.385% equals 59.627%, and so forth. Therefore, about 59.627% of the variation is explained by the first two eigenvalues together. Eigenvalues can be used to determine the number of principal components to retain after PCA (Kaiser 1961): An eigenvalue &gt; 1 indicates that PCs account for more variance than accounted by one of the original variables in standardized data. This is commonly used as a cutoff point for which PCs are retained. This holds true only when the data are standardized. You can also limit the number of component to that number that accounts for a certain fraction of the total variance. For example, if you are satisfied with 70% of the total variance explained then use the number of components to achieve that. Unfortunately, there is no well-accepted objective way to decide how many principal components are enough. This will depend on the specific field of application and the specific data set. In practice, we tend to look at the first few principal components in order to find interesting patterns in the data. In our analysis, the first three principal components explain 72% of the variation. This is an acceptably large percentage. An alternative method to determine the number of principal components is to look at a Scree Plot, which is the plot of eigenvalues ordered from largest to the smallest. The number of component is determined at the point, beyond which the remaining eigenvalues are all relatively small and of comparable size (Jollife 2002, Peres-Neto, Jackson, and Somers (2005)). The scree plot can be produced using the function fviz_eig() or fviz_screeplot() [factoextra package]. fviz_eig(res.pca, addlabels = TRUE, ylim = c(0, 50)) Graph of variables Results A simple method to extract the results, for variables, from a PCA output is to use the function get_pca_var() [factoextra package]. This function provides a list of matrices containing all the results for the active variables (coordinates, correlation between variables and axes, squared cosine and contributions) var &lt;- get_pca_var(res.pca) var The components of the get_pca_var() can be used in the plot of variables as follow: var$coord: coordinates of variables to create a scatter plot var$cos2: represents the quality of representation for variables on the factor map. It‚Äôs calculated as the squared coordinates: var.cos2 = var.coord * var.coord. var$contrib: contains the contributions (in percentage) of the variables to the principal components. The contribution of a variable (var) to a given principal component is (in percentage) : (var.cos2 * 100) / (total cos2 of the component). Note that, it‚Äôs possible to plot variables and to color them according to either i) their quality on the factor map (cos2) or ii) their contribution values to the principal components (contrib). The different components can be accessed as follow: "],["12-coordinates.html", "12 Coordinates", " 12 Coordinates head(var\\(coord) # Cos2: quality on the factore map head(var\\)cos2) # Contributions to the principal components head(var$contrib) In this section, we describe how to visualize variables and draw conclusions about their correlations. Next, we highlight variables according to either i) their quality of representation on the factor map or ii) their contributions to the principal components. Correlation circle The correlation between a variable and a principal component (PC) is used as the coordinates of the variable on the PC. The representation of variables differs from the plot of the observations: The observations are represented by their projections, but the variables are represented by their correlations (Abdi and Williams 2010). "],["13-coordinates-of-variables.html", "13 Coordinates of variables", " 13 Coordinates of variables head(var$coord, 4) To plot variables, type this: fviz_pca_var(res.pca, col.var = ‚Äúblack‚Äù) he plot above is also known as variable correlation plots. It shows the relationships between all variables. It can be interpreted as follow: Positively correlated variables are grouped together. Negatively correlated variables are positioned on opposite sides of the plot origin (opposed quadrants). The distance between variables and the origin measures the quality of the variables on the factor map. Variables that are away from the origin are well represented on the factor map. Quality of representation The quality of representation of the variables on factor map is called cos2 (square cosine, squared coordinates) . You can access to the cos2 as follow: head(var$cos2, 4) You can visualize the cos2 of variables on all the dimensions using the corrplot package: library(‚Äúcorrplot‚Äù) corrplot(var$cos2, is.corr=FALSE) It‚Äôs also possible to create a bar plot of variables cos2 using the function fviz_cos2()[in factoextra]: "],["14-total-cos2-of-variables-on-dim.1-and-dim.html", "14 Total cos2 of variables on Dim.1 and Dim.2", " 14 Total cos2 of variables on Dim.1 and Dim.2 fviz_cos2(res.pca, choice = ‚Äúvar‚Äù, axes = 1:2) Note that, A high cos2 indicates a good representation of the variable on the principal component. In this case the variable is positioned close to the circumference of the correlation circle. A low cos2 indicates that the variable is not perfectly represented by the PCs. In this case the variable is close to the center of the circle. For a given variable, the sum of the cos2 on all the principal components is equal to one. If a variable is perfectly represented by only two principal components (Dim.1 &amp; Dim.2), the sum of the cos2 on these two PCs is equal to one. In this case the variables will be positioned on the circle of correlations. For some of the variables, more than 2 components might be required to perfectly represent the data. In this case the variables are positioned inside the circle of correlations. In summary: The cos2 values are used to estimate the quality of the representation The closer a variable is to the circle of correlations, the better its representation on the factor map (and the more important it is to interpret these components) Variables that are closed to the center of the plot are less important for the first components. It‚Äôs possible to color variables by their cos2 values using the argument col.var = ‚Äúcos2‚Äù. This produces a gradient colors. In this case, the argument gradient.cols can be used to provide a custom color. For instance, gradient.cols = c(‚Äúwhite‚Äù, ‚Äúblue‚Äù, ‚Äúred‚Äù) means that: variables with low cos2 values will be colored in ‚Äúwhite‚Äù variables with mid cos2 values will be colored in ‚Äúblue‚Äù variables with high cos2 values will be colored in red "],["15-color-by-cos2-values-quality-on-the-factor-map.html", "15 Color by cos2 values: quality on the factor map", " 15 Color by cos2 values: quality on the factor map fviz_pca_var(res.pca, col.var = ‚Äúcos2‚Äù, gradient.cols = c(‚Äú#00AFBB‚Äù, ‚Äú#E7B800‚Äù, ‚Äú#FC4E07‚Äù), repel = TRUE # Avoid text overlapping ) Note that, it‚Äôs also possible to change the transparency of the variables according to their cos2 values using the option alpha.var = ‚Äúcos2‚Äù. For example, type this: "],["16-change-the-transparency-by-cos2-values.html", "16 Change the transparency by cos2 values", " 16 Change the transparency by cos2 values fviz_pca_var(res.pca, alpha.var = ‚Äúcos2‚Äù) Contributions of variables to PCs The contributions of variables in accounting for the variability in a given principal component are expressed in percentage. Variables that are correlated with PC1 (i.e., Dim.1) and PC2 (i.e., Dim.2) are the most important in explaining the variability in the data set. Variables that do not correlated with any PC or correlated with the last dimensions are variables with low contribution and might be removed to simplify the overall analysis. The contribution of variables can be extracted as follow : head(var$contrib, 4) The larger the value of the contribution, the more the variable contributes to the component. It‚Äôs possible to use the function corrplot() [corrplot package] to highlight the most contributing variables for each dimension: library(‚Äúcorrplot‚Äù) corrplot(var$contrib, is.corr=FALSE) The function fviz_contrib() [factoextra package] can be used to draw a bar plot of variable contributions. If your data contains many variables, you can decide to show only the top contributing variables. The R code below shows the top 10 variables contributing to the principal components: "],["17-contributions-of-variables-to-pc1.html", "17 Contributions of variables to PC1", " 17 Contributions of variables to PC1 fviz_contrib(res.pca, choice = ‚Äúvar‚Äù, axes = 1, top = 10) # Contributions of variables to PC2 fviz_contrib(res.pca, choice = ‚Äúvar‚Äù, axes = 2, top = 10) The total contribution to PC1 and PC2 is obtained with the following R code: fviz_contrib(res.pca, choice = ‚Äúvar‚Äù, axes = 1:2, top = 10) The red dashed line on the graph above indicates the expected average contribution. If the contribution of the variables were uniform, the expected value would be 1/length(variables) = 1/10 = 10%. For a given component, a variable with a contribution larger than this cutoff could be considered as important in contributing to the component. Note that, the total contribution of a given variable, on explaining the variations retained by two principal components, say PC1 and PC2, is calculated as contrib = [(C1 * Eig1) + (C2 * Eig2)]/(Eig1 + Eig2), where C1 and C2 are the contributions of the variable on PC1 and PC2, respectively Eig1 and Eig2 are the eigenvalues of PC1 and PC2, respectively. Recall that eigenvalues measure the amount of variation retained by each PC. In this case, the expected average contribution (cutoff) is calculated as follow: As mentioned above, if the contributions of the 10 variables were uniform, the expected average contribution on a given PC would be 1/10 = 10%. The expected average contribution of a variable for PC1 and PC2 is : [(10* Eig1) + (10 * Eig2)]/(Eig1 + Eig2) It can be seen that the variables - X100m, Long.jump and Pole.vault - contribute the most to the dimensions 1 and 2. The most important (or, contributing) variables can be highlighted on the correlation plot as follow: fviz_pca_var(res.pca, col.var = ‚Äúcontrib‚Äù, gradient.cols = c(‚Äú#00AFBB‚Äù, ‚Äú#E7B800‚Äù, ‚Äú#FC4E07‚Äù) ) Note that, it‚Äôs also possible to change the transparency of variables according to their contrib values using the option alpha.var = ‚Äúcontrib‚Äù. For example, type this: "],["18-change-the-transparency-by-contrib-values.html", "18 Change the transparency by contrib values", " 18 Change the transparency by contrib values fviz_pca_var(res.pca, alpha.var = ‚Äúcontrib‚Äù) Color by a custom continuous variable In the previous sections, we showed how to color variables by their contributions and their cos2. Note that, it‚Äôs possible to color variables by any custom continuous variable. The coloring variable should have the same length as the number of active variables in the PCA (here n = 10). For example, type this: "],["19-create-a-random-continuous-variable-of-length-10.html", "19 Create a random continuous variable of length 10", " 19 Create a random continuous variable of length 10 set.seed(123) my.cont.var &lt;- rnorm(10) # Color variables by the continuous variable fviz_pca_var(res.pca, col.var = my.cont.var, gradient.cols = c(‚Äúblue‚Äù, ‚Äúyellow‚Äù, ‚Äúred‚Äù), legend.title = ‚ÄúCont.Var‚Äù) Color by groups It‚Äôs also possible to change the color of variables by groups defined by a qualitative/categorical variable, also called factor in R terminology. As we don‚Äôt have any grouping variable in our data sets for classifying variables, we‚Äôll create it. In the following demo example, we start by classifying the variables into 3 groups using the kmeans clustering algorithm. Next, we use the clusters returned by the kmeans algorithm to color variables. Note that, if you are interested in learning clustering, we previously published a book named ‚ÄúPractical Guide To Cluster Analysis in R‚Äù (https://goo.gl/DmJ5y5). "],["20-create-a-grouping-variable-using-kmeans.html", "20 Create a grouping variable using kmeans", " 20 Create a grouping variable using kmeans "],["21-create-3-groups-of-variables-centers-3.html", "21 Create 3 groups of variables (centers = 3)", " 21 Create 3 groups of variables (centers = 3) set.seed(123) res.km &lt;- kmeans(var\\(coord, centers = 3, nstart = 25) grp &lt;- as.factor(res.km\\)cluster) # Color variables by groups fviz_pca_var(res.pca, col.var = grp, palette = c(‚Äú#0073C2FF‚Äù, ‚Äú#EFC000FF‚Äù, ‚Äú#868686FF‚Äù), legend.title = ‚ÄúCluster‚Äù) Note that, to change the color of groups the argument palette should be used. To change gradient colors, the argument gradient.cols should be used. Dimension description In the section (???)(pca-variable-contributions), we described how to highlight variables according to their contributions to the principal components. Note also that, the function dimdesc() [in FactoMineR], for dimension description, can be used to identify the most significantly associated variables with a given principal component . It can be used as follow: res.desc &lt;- dimdesc(res.pca, axes = c(1,2), proba = 0.05) # Description of dimension 1 res.desc\\(Dim.1 # Description of dimension 2 res.desc\\)Dim.2 In the output above, $quanti means results for quantitative variables. Note that, variables are sorted by the p-value of the correlation. Graph of individuals Results The results, for individuals can be extracted using the function get_pca_ind() [factoextra package]. Similarly to the get_pca_var(), the function get_pca_ind() provides a list of matrices containing all the results for the individuals (coordinates, correlation between individuals and axes, squared cosine and contributions) ind &lt;- get_pca_ind(res.pca) ind "],["21.1-principal-component-analysis-results-for-individuals.html", "21.1 Principal Component Analysis Results for individuals", " 21.1 Principal Component Analysis Results for individuals "],["21.2-section.html", "21.2 ===================================================", " 21.2 =================================================== "],["21.3-name-description.html", "21.3 Name Description", " 21.3 Name Description "],["21.4-coord-coordinates-for-the-individuals-2-cos2-cos2-for-the-individuals.html", "21.4 1 ‚Äú\\(coord&quot; &quot;Coordinates for the individuals&quot; ## 2 &quot;\\)cos2‚Äù ‚ÄúCos2 for the individuals‚Äù", " 21.4 1 ‚Äú\\(coord&quot; &quot;Coordinates for the individuals&quot; ## 2 &quot;\\)cos2‚Äù ‚ÄúCos2 for the individuals‚Äù "],["21.5-contrib-contributions-of-the-individuals.html", "21.5 3 ‚Äú$contrib‚Äù ‚Äúcontributions of the individuals‚Äù", " 21.5 3 ‚Äú$contrib‚Äù ‚Äúcontributions of the individuals‚Äù To get access to the different components, use this: "],["22-coordinates-of-individuals.html", "22 Coordinates of individuals", " 22 Coordinates of individuals head(ind\\(coord) # Quality of individuals head(ind\\)cos2) # Contributions of individuals head(ind$contrib) Plots: quality and contribution The fviz_pca_ind() is used to produce the graph of individuals. To create a simple plot, type this: fviz_pca_ind(res.pca) Like variables, it‚Äôs also possible to color individuals by their cos2 values: fviz_pca_ind(res.pca, col.ind = ‚Äúcos2‚Äù, gradient.cols = c(‚Äú#00AFBB‚Äù, ‚Äú#E7B800‚Äù, ‚Äú#FC4E07‚Äù), repel = TRUE # Avoid text overlapping (slow if many points) ) Note that, individuals that are similar are grouped together on the plot. You can also change the point size according the cos2 of the corresponding individuals: fviz_pca_ind(res.pca, pointsize = ‚Äúcos2‚Äù, pointshape = 21, fill = ‚Äú#E7B800‚Äù, repel = TRUE # Avoid text overlapping (slow if many points) ) To change both point size and color by cos2, try this: fviz_pca_ind(res.pca, col.ind = ‚Äúcos2‚Äù, pointsize = ‚Äúcos2‚Äù, gradient.cols = c(‚Äú#00AFBB‚Äù, ‚Äú#E7B800‚Äù, ‚Äú#FC4E07‚Äù), repel = TRUE # Avoid text overlapping (slow if many points) ) To create a bar plot of the quality of representation (cos2) of individuals on the factor map, you can use the function fviz_cos2() as previously described for variables: fviz_cos2(res.pca, choice = ‚Äúind‚Äù) To visualize the contribution of individuals to the first two principal components, type this: "],["23-total-contribution-on-pc1-and-pc2.html", "23 Total contribution on PC1 and PC2", " 23 Total contribution on PC1 and PC2 fviz_contrib(res.pca, choice = ‚Äúind‚Äù, axes = 1:2) Color by a custom continuous variable As for variables, individuals can be colored by any custom continuous variable by specifying the argument col.ind. For example, type this: "],["24-create-a-random-continuous-variable-of-length-23.html", "24 Create a random continuous variable of length 23,", " 24 Create a random continuous variable of length 23, "],["25-same-length-as-the-number-of-active-individuals-in-the-pca.html", "25 Same length as the number of active individuals in the PCA", " 25 Same length as the number of active individuals in the PCA set.seed(123) my.cont.var &lt;- rnorm(23) # Color individuals by the continuous variable fviz_pca_ind(res.pca, col.ind = my.cont.var, gradient.cols = c(‚Äúblue‚Äù, ‚Äúyellow‚Äù, ‚Äúred‚Äù), legend.title = ‚ÄúCont.Var‚Äù) Color by groups Here, we describe how to color individuals by group. Additionally, we show how to add concentration ellipses and confidence ellipses by groups. For this, we‚Äôll use the iris data as demo data sets. Iris data sets look like this: head(iris, 3) "],["25.1-sepal.length-sepal.width-petal.length-petal.width-species.html", "25.1 Sepal.Length Sepal.Width Petal.Length Petal.Width Species", " 25.1 Sepal.Length Sepal.Width Petal.Length Petal.Width Species "],["25.2-setosa.html", "25.2 1 5.1 3.5 1.4 0.2 setosa", " 25.2 1 5.1 3.5 1.4 0.2 setosa "],["25.3-setosa-1.html", "25.3 2 4.9 3.0 1.4 0.2 setosa", " 25.3 2 4.9 3.0 1.4 0.2 setosa "],["25.4-setosa-2.html", "25.4 3 4.7 3.2 1.3 0.2 setosa", " 25.4 3 4.7 3.2 1.3 0.2 setosa The column ‚ÄúSpecies‚Äù will be used as grouping variable. We start by computing principal component analysis as follow: "],["26-the-variable-species-index-5-is-removed.html", "26 The variable Species (index = 5) is removed", " 26 The variable Species (index = 5) is removed "],["27-before-pca-analysis.html", "27 before PCA analysis", " 27 before PCA analysis iris.pca &lt;- PCA(iris[,-5], graph = FALSE) In the R code below: the argument habillage or col.ind can be used to specify the factor variable for coloring the individuals by groups. To add a concentration ellipse around each group, specify the argument addEllipses = TRUE. The argument palette can be used to change group colors. fviz_pca_ind(iris.pca, geom.ind = ‚Äúpoint‚Äù, # show points only (nbut not ‚Äútext‚Äù) col.ind = iris$Species, # color by groups palette = c(‚Äú#00AFBB‚Äù, ‚Äú#E7B800‚Äù, ‚Äú#FC4E07‚Äù), addEllipses = TRUE, # Concentration ellipses legend.title = ‚ÄúGroups‚Äù ) To remove the group mean point, specify the argument mean.point = FALSE. If you want confidence ellipses instead of concentration ellipses, use ellipse.type = ‚Äúconfidence‚Äù. "],["28-add-confidence-ellipses.html", "28 Add confidence ellipses", " 28 Add confidence ellipses fviz_pca_ind(iris.pca, geom.ind = ‚Äúpoint‚Äù, col.ind = iris$Species, palette = c(‚Äú#00AFBB‚Äù, ‚Äú#E7B800‚Äù, ‚Äú#FC4E07‚Äù), addEllipses = TRUE, ellipse.type = ‚Äúconfidence‚Äù, legend.title = ‚ÄúGroups‚Äù ) Note that, allowed values for palette include: ‚Äúgrey‚Äù for grey color palettes; brewer palettes e.g. ‚ÄúRdBu‚Äù, ‚ÄúBlues‚Äù, ‚Ä¶; To view all, type this in R: RColorBrewer::display.brewer.all(). custom color palette e.g. c(‚Äúblue‚Äù, ‚Äúred‚Äù); and scientific journal palettes from ggsci R package, e.g.: ‚Äúnpg‚Äù, ‚Äúaaas‚Äù, ‚Äúlancet‚Äù, ‚Äújco‚Äù, ‚Äúucscgb‚Äù, ‚Äúuchicago‚Äù, ‚Äúsimpsons‚Äù and ‚Äúrickandmorty‚Äù. For example, to use the jco (journal of clinical oncology) color palette, type this: fviz_pca_ind(iris.pca, label = ‚Äúnone‚Äù, # hide individual labels habillage = iris$Species, # color by groups addEllipses = TRUE, # Concentration ellipses palette = ‚Äújco‚Äù ) Graph customization Note that, fviz_pca_ind() and fviz_pca_var() and related functions are wrapper around the core function fviz() [in factoextra]. fviz() is a wrapper around the function ggscatter() [in ggpubr]. Therefore, further arguments, to be passed to the function fviz() and ggscatter(), can be specified in fviz_pca_ind() and fviz_pca_var(). Here, we present some of these additional arguments to customize the PCA graph of variables and individuals. Dimensions By default, variables/individuals are represented on dimensions 1 and 2. If you want to visualize them on dimensions 2 and 3, for example, you should specify the argument axes = c(2, 3). "],["29-variables-on-dimensions-2-and-3.html", "29 Variables on dimensions 2 and 3", " 29 Variables on dimensions 2 and 3 fviz_pca_var(res.pca, axes = c(2, 3)) # Individuals on dimensions 2 and 3 fviz_pca_ind(res.pca, axes = c(2, 3)) Plot elements: point, text, arrow The argument geom (for geometry) and derivatives are used to specify the geometry elements or graphical elements to be used for plotting. geom.var: a text specifying the geometry to be used for plotting variables. Allowed values are the combination of c(‚Äúpoint‚Äù, ‚Äúarrow‚Äù, ‚Äútext‚Äù). Use geom.var = &quot;point&quot;, to show only points; Use geom.var = &quot;text&quot; to show only text labels; Use geom.var = c(&quot;point&quot;, &quot;text&quot;) to show both points and text labels Use geom.var = c(&quot;arrow&quot;, &quot;text&quot;) to show arrows and labels (default). For example, type this: "],["30-show-variable-points-and-text-labels.html", "30 Show variable points and text labels", " 30 Show variable points and text labels fviz_pca_var(res.pca, geom.var = c(‚Äúpoint‚Äù, ‚Äútext‚Äù)) geom.ind: a text specifying the geometry to be used for plotting individuals. Allowed values are the combination of c(‚Äúpoint‚Äù, ‚Äútext‚Äù). Use geom.ind = &quot;point&quot;, to show only points; Use geom.ind = &quot;text&quot; to show only text labels; Use geom.ind = c(&quot;point&quot;, &quot;text&quot;) to show both point and text labels (default) For example, type this: "],["31-show-individuals-text-labels-only.html", "31 Show individuals text labels only", " 31 Show individuals text labels only fviz_pca_ind(res.pca, geom.ind = ‚Äútext‚Äù) Size and shape of plot elements labelsize: font size for the text labels, e.g.: labelsize = 4. pointsize: the size of points, e.g.: pointsize = 1.5. arrowsize: the size of arrows. Controls the thickness of arrows, e.g.: arrowsize = 0.5. pointshape: the shape of points, pointshape = 21. Type ggpubr::show_point_shapes() to see available point shapes. "],["32-change-the-size-of-arrows-an-labels.html", "32 Change the size of arrows an labels", " 32 Change the size of arrows an labels fviz_pca_var(res.pca, arrowsize = 1, labelsize = 5, repel = TRUE) # Change points size, shape and fill color # Change labelsize fviz_pca_ind(res.pca, pointsize = 3, pointshape = 21, fill = ‚Äúlightblue‚Äù, labelsize = 5, repel = TRUE) Ellipses As we described in the previous section (???)(color-ind-by-groups), when coloring individuals by groups, you can add point concentration ellipses using the argument addEllipses = TRUE. Note that, the argument ellipse.type can be used to change the type of ellipses. Possible values are: &quot;convex&quot;: plot convex hull of a set o points. &quot;confidence&quot;: plot confidence ellipses around group mean points as the function coord.ellipse() [in FactoMineR]. &quot;t&quot;: assumes a multivariate t-distribution. &quot;norm&quot;: assumes a multivariate normal distribution. &quot;euclid&quot;: draws a circle with the radius equal to level, representing the euclidean distance from the center. This ellipse probably won‚Äôt appear circular unless coord_fixed() is applied. The argument ellipse.level is also available to change the size of the concentration ellipse in normal probability. For example, specify ellipse.level = 0.95 or ellipse.level = 0.66. "],["33-add-confidence-ellipses-1.html", "33 Add confidence ellipses", " 33 Add confidence ellipses fviz_pca_ind(iris.pca, geom.ind = ‚Äúpoint‚Äù, col.ind = iris\\(Species, # color by groups palette = c(&quot;#00AFBB&quot;, &quot;#E7B800&quot;, &quot;#FC4E07&quot;), addEllipses = TRUE, ellipse.type = &quot;confidence&quot;, legend.title = &quot;Groups&quot; ) # Convex hull fviz_pca_ind(iris.pca, geom.ind = &quot;point&quot;, col.ind = iris\\)Species, # color by groups palette = c(‚Äú#00AFBB‚Äù, ‚Äú#E7B800‚Äù, ‚Äú#FC4E07‚Äù), addEllipses = TRUE, ellipse.type = ‚Äúconvex‚Äù, legend.title = ‚ÄúGroups‚Äù ) Group mean points When coloring individuals by groups (section (???)(color-ind-by-groups)), the mean points of groups (barycenters) are also displayed by default. To remove the mean points, use the argument mean.point = FALSE. fviz_pca_ind(iris.pca, geom.ind = ‚Äúpoint‚Äù, # show points only (but not ‚Äútext‚Äù) group.ind = iris$Species, # color by groups legend.title = ‚ÄúGroups‚Äù, mean.point = FALSE) Axis lines The argument axes.linetype can be used to specify the line type of axes. Default is ‚Äúdashed‚Äù. Allowed values include ‚Äúblank‚Äù, ‚Äúsolid‚Äù, ‚Äúdotted‚Äù, etc. To see all possible values type ggpubr::show_line_types() in R. To remove axis lines, use axes.linetype = ‚Äúblank‚Äù: fviz_pca_var(res.pca, axes.linetype = ‚Äúblank‚Äù) Graphical parameters To change easily the graphical of any ggplots, you can use the function ggpar() [ggpubr package] The graphical parameters that can be changed using ggpar() include: Main titles, axis labels and legend titles Legend position. Possible values: ‚Äútop‚Äù, ‚Äúbottom‚Äù, ‚Äúleft‚Äù, ‚Äúright‚Äù, ‚Äúnone‚Äù. Color palette. Themes. Allowed values include: theme_gray(), theme_bw(), theme_minimal(), theme_classic(), theme_void(). ind.p &lt;- fviz_pca_ind(iris.pca, geom = ‚Äúpoint‚Äù, col.ind = iris$Species) ggpubr::ggpar(ind.p, title = ‚ÄúPrincipal Component Analysis‚Äù, subtitle = ‚ÄúIris data set‚Äù, caption = ‚ÄúSource: factoextra‚Äù, xlab = ‚ÄúPC1‚Äù, ylab = ‚ÄúPC2‚Äù, legend.title = ‚ÄúSpecies‚Äù, legend.position = ‚Äútop‚Äù, ggtheme = theme_gray(), palette = ‚Äújco‚Äù ) Biplot To make a simple biplot of individuals and variables, type this: fviz_pca_biplot(res.pca, repel = TRUE, col.var = ‚Äú#2E9FDF‚Äù, # Variables color col.ind = ‚Äú#696969‚Äù # Individuals color ) Note that, the biplot might be only useful when there is a low number of variables and individuals in the data set; otherwise the final plot would be unreadable. Note also that, the coordinate of individuals and variables are not constructed on the same space. Therefore, in the biplot, you should mainly focus on the direction of variables but not on their absolute positions on the plot. Roughly speaking a biplot can be interpreted as follow: an individual that is on the same side of a given variable has a high value for this variable; an individual that is on the opposite side of a given variable has a low value for this variable. Now, using the iris.pca output, let‚Äôs : make a biplot of individuals and variables change the color of individuals by groups: col.ind = iris$Species show only the labels for variables: label = &quot;var&quot; or use geom.ind = &quot;point&quot; fviz_pca_biplot(iris.pca, col.ind = iris$Species, palette = ‚Äújco‚Äù, addEllipses = TRUE, label = ‚Äúvar‚Äù, col.var = ‚Äúblack‚Äù, repel = TRUE, legend.title = ‚ÄúSpecies‚Äù) In the following example, we want to color both individuals and variables by groups. The trick is to use pointshape = 21 for individual points. This particular point shape can be filled by a color using the argument fill.ind. The border line color of individual points is set to ‚Äúblack‚Äù using col.ind. To color variable by groups, the argument col.var will be used. To customize individuals and variable colors, we use the helper functions fill_palette() and color_palette() [in ggpubr package]. fviz_pca_biplot(iris.pca, # Fill individuals by groups geom.ind = ‚Äúpoint‚Äù, pointshape = 21, pointsize = 2.5, fill.ind = iris$Species, col.ind = ‚Äúblack‚Äù, # Color variable by groups col.var = factor(c(‚Äúsepal‚Äù, ‚Äúsepal‚Äù, ‚Äúpetal‚Äù, ‚Äúpetal‚Äù)), legend.title = list(fill = &quot;Species&quot;, color = &quot;Clusters&quot;), repel = TRUE # Avoid label overplotting )+ ggpubr::fill_palette(‚Äújco‚Äù)+ # Indiviual fill color ggpubr::color_palette(‚Äúnpg‚Äù) # Variable colors Another complex example is to color individuals by groups (discrete color) and variables by their contributions to the principal components (gradient colors). Additionally, we‚Äôll change the transparency of variables by their contributions using the argument alpha.var. fviz_pca_biplot(iris.pca, # Individuals geom.ind = ‚Äúpoint‚Äù, fill.ind = iris$Species, col.ind = ‚Äúblack‚Äù, pointshape = 21, pointsize = 2, palette = ‚Äújco‚Äù, addEllipses = TRUE, # Variables alpha.var =‚Äúcontrib‚Äù, col.var = ‚Äúcontrib‚Äù, gradient.cols = ‚ÄúRdYlBu‚Äù, legend.title = list(fill = &quot;Species&quot;, color = &quot;Contrib&quot;, alpha = &quot;Contrib&quot;) ) Supplementary elements Definition and types As described above (section (???)(pca-data-format)), the decathlon2 data sets contain supplementary continuous variables (quanti.sup, columns 11:12), supplementary qualitative variables (quali.sup, column 13) and supplementary individuals (ind.sup, rows 24:27). Supplementary variables and individuals are not used for the determination of the principal components. Their coordinates are predicted using only the information provided by the performed principal component analysis on active variables/individuals. Specification in PCA To specify supplementary individuals and variables, the function PCA() can be used as follow: PCA(X, ind.sup = NULL, quanti.sup = NULL, quali.sup = NULL, graph = TRUE) X : a data frame. Rows are individuals and columns are numeric variables. ind.sup : a numeric vector specifying the indexes of the supplementary individuals quanti.sup, quali.sup : a numeric vector specifying, respectively, the indexes of the quantitative and qualitative variables graph : a logical value. If TRUE a graph is displayed. For example, type this: res.pca &lt;- PCA(decathlon2, ind.sup = 24:27, quanti.sup = 11:12, quali.sup = 13, graph=FALSE) Quantitative variables Predicted results (coordinates, correlation and cos2) for the supplementary quantitative variables: res.pca$quanti.sup "],["33.1-coord.html", "33.1 $coord", " 33.1 $coord "],["33.2-dim.1-dim.2-dim.3-dim.4-dim.html", "33.2 Dim.1 Dim.2 Dim.3 Dim.4 Dim.5", " 33.2 Dim.1 Dim.2 Dim.3 Dim.4 Dim.5 "],["33.3-rank--0.701--0.2452--0.183-0.0558--0.html", "33.3 Rank -0.701 -0.2452 -0.183 0.0558 -0.0738", " 33.3 Rank -0.701 -0.2452 -0.183 0.0558 -0.0738 "],["33.4-points-0.964-0.0777-0.158--0.1662--0.html", "33.4 Points 0.964 0.0777 0.158 -0.1662 -0.0311", " 33.4 Points 0.964 0.0777 0.158 -0.1662 -0.0311 "],["33.5-section-1.html", "33.5 ", " 33.5 "],["33.6-cor.html", "33.6 $cor", " 33.6 $cor "],["33.7-dim.1-dim.2-dim.3-dim.4-dim.5-1.html", "33.7 Dim.1 Dim.2 Dim.3 Dim.4 Dim.5", " 33.7 Dim.1 Dim.2 Dim.3 Dim.4 Dim.5 "],["33.8-rank--0.701--0.2452--0.183-0.0558--0.0738-1.html", "33.8 Rank -0.701 -0.2452 -0.183 0.0558 -0.0738", " 33.8 Rank -0.701 -0.2452 -0.183 0.0558 -0.0738 "],["33.9-points-0.964-0.0777-0.158--0.1662--0.0311-1.html", "33.9 Points 0.964 0.0777 0.158 -0.1662 -0.0311", " 33.9 Points 0.964 0.0777 0.158 -0.1662 -0.0311 "],["33.10-section-2.html", "33.10 ", " 33.10 "],["33.11-cos2.html", "33.11 $cos2", " 33.11 $cos2 "],["33.12-dim.1-dim.2-dim.3-dim.4-dim.5-2.html", "33.12 Dim.1 Dim.2 Dim.3 Dim.4 Dim.5", " 33.12 Dim.1 Dim.2 Dim.3 Dim.4 Dim.5 "],["33.13-rank-0.492-0.06012-0.0336-0.00311-0.html", "33.13 Rank 0.492 0.06012 0.0336 0.00311 0.00545", " 33.13 Rank 0.492 0.06012 0.0336 0.00311 0.00545 "],["33.14-points-0.929-0.00603-0.0250-0.02763-0.html", "33.14 Points 0.929 0.00603 0.0250 0.02763 0.00097", " 33.14 Points 0.929 0.00603 0.0250 0.02763 0.00097 Visualize all variables (active and supplementary ones): fviz_pca_var(res.pca) Note that, by default, supplementary quantitative variables are shown in blue color and dashed lines. Further arguments to customize the plot: "],["34-change-color-of-variables.html", "34 Change color of variables", " 34 Change color of variables fviz_pca_var(res.pca, col.var = ‚Äúblack‚Äù, # Active variables col.quanti.sup = ‚Äúred‚Äù # Suppl. quantitative variables ) # Hide active variables on the plot, # show only supplementary variables fviz_pca_var(res.pca, invisible = ‚Äúvar‚Äù) # Hide supplementary variables fviz_pca_var(res.pca, invisible = ‚Äúquanti.sup‚Äù) Using the fviz_pca_var(), the quantitative supplementary variables are displayed automatically on the correlation circle plot. Note that, you can add the quanti.sup variables manually, using the fviz_add() function, for further customization. An example is shown below. "],["35-plot-of-active-variables.html", "35 Plot of active variables", " 35 Plot of active variables p &lt;- fviz_pca_var(res.pca, invisible = ‚Äúquanti.sup‚Äù) # Add supplementary active variables fviz_add(p, res.pca\\(quanti.sup\\)coord, geom = c(‚Äúarrow‚Äù, ‚Äútext‚Äù), color = ‚Äúred‚Äù) Individuals Predicted results for the supplementary individuals (ind.sup): res.pca$ind.sup Visualize all individuals (active and supplementary ones). On the graph, you can add also the supplementary qualitative variables (quali.sup), which coordinates is accessible using res.pca$quali.supp$coord. p &lt;- fviz_pca_ind(res.pca, col.ind.sup = ‚Äúblue‚Äù, repel = TRUE) p &lt;- fviz_add(p, res.pca\\(quali.sup\\)coord, color = ‚Äúred‚Äù) p Supplementary individuals are shown in blue. The levels of the supplementary qualitative variable are shown in red color. Qualitative variables In the previous section, we showed that you can add the supplementary qualitative variables on individuals plot using fviz_add(). Note that, the supplementary qualitative variables can be also used for coloring individuals by groups. This can help to interpret the data. The data sets decathlon2 contain a supplementary qualitative variable at columns 13 corresponding to the type of competitions. The results concerning the supplementary qualitative variable are: res.pca$quali To color individuals by a supplementary qualitative variable, the argument habillage is used to specify the index of the supplementary qualitative variable. Historically, this argument name comes from the FactoMineR package. It‚Äôs a french word meaning ‚Äúdressing‚Äù in english. To keep consistency between FactoMineR and factoextra, we decided to keep the same argument name fviz_pca_ind(res.pca, habillage = 13, addEllipses =TRUE, ellipse.type = ‚Äúconfidence‚Äù, palette = ‚Äújco‚Äù, repel = TRUE) Recall that, to remove the mean points of groups, specify the argument mean.point = FALSE. Filtering results If you have many individuals/variable, it‚Äôs possible to visualize only some of them using the arguments select.ind and select.var. select.ind, select.var: a selection of individuals/variable to be plotted. Allowed values are NULL or a list containing the arguments name, cos2 or contrib: name: is a character vector containing individuals/variable names to be plotted cos2: if cos2 is in [0, 1], ex: 0.6, then individuals/variables with a cos2 &gt; 0.6 are plotted if cos2 &gt; 1, ex: 5, then the top 5 active individuals/variables and top 5 supplementary columns/rows with the highest cos2 are plotted contrib: if contrib &gt; 1, ex: 5, then the top 5 individuals/variables with the highest contributions are plotted "],["36-visualize-variable-with-cos2-0.html", "36 Visualize variable with cos2 &gt;= 0.6", " 36 Visualize variable with cos2 &gt;= 0.6 fviz_pca_var(res.pca, select.var = list(cos2 = 0.6)) # Top 5 active variables with the highest cos2 fviz_pca_var(res.pca, select.var= list(cos2 = 5)) # Select by names name &lt;- list(name = c(‚ÄúLong.jump‚Äù, ‚ÄúHigh.jump‚Äù, ‚ÄúX100m‚Äù)) fviz_pca_var(res.pca, select.var = name) # top 5 contributing individuals and variable fviz_pca_biplot(res.pca, select.ind = list(contrib = 5), select.var = list(contrib = 5), ggtheme = theme_minimal()) When the selection is done according to the contribution values, supplementary individuals/variables are not shown because they don‚Äôt contribute to the construction of the axes. Exporting results Export plots to PDF/PNG files The factoextra package produces a ggplot2-based graphs. To save any ggplots, the standard R code is as follow: "],["37-print-the-plot-to-a-pdf-file.html", "37 Print the plot to a pdf file", " 37 Print the plot to a pdf file pdf(‚Äúmyplot.pdf‚Äù) print(myplot) dev.off() In the following examples, we‚Äôll show you how to save the different graphs into pdf or png files. The first step is to create the plots you want as an R object: "],["38-scree-plot.html", "38 Scree plot", " 38 Scree plot scree.plot &lt;- fviz_eig(res.pca) # Plot of individuals ind.plot &lt;- fviz_pca_ind(res.pca) # Plot of variables var.plot &lt;- fviz_pca_var(res.pca) Next, the plots can be exported into a single pdf file as follow: pdf(‚ÄúPCA.pdf‚Äù) # Create a new pdf device print(scree.plot) print(ind.plot) print(var.plot) dev.off() # Close the pdf device Note that, using the above R code will create the PDF file into your current working directory. To see the path of your current working directory, type getwd() in the R console. To print each plot to specific png file, the R code looks like this: "],["39-print-scree-plot-to-a-png-file.html", "39 Print scree plot to a png file", " 39 Print scree plot to a png file png(‚Äúpca-scree-plot.png‚Äù) print(scree.plot) dev.off() # Print individuals plot to a png file png(‚Äúpca-variables.png‚Äù) print(var.plot) dev.off() # Print variables plot to a png file png(‚Äúpca-individuals.png‚Äù) print(ind.plot) dev.off() Another alternative, to export ggplots, is to use the function ggexport() [in ggpubr package]. We like ggexport(), because it‚Äôs very simple. With one line R code, it allows us to export individual plots to a file (pdf, eps or png) (one plot per page). It can also arrange the plots (2 plot per page, for example) before exporting them. The examples below demonstrates how to export ggplots using ggexport(). Export individual plots to a pdf file (one plot per page): library(ggpubr) ggexport(plotlist = list(scree.plot, ind.plot, var.plot), filename = ‚ÄúPCA.pdf‚Äù) Arrange and export. Specify nrow and ncol to display multiple plots on the same page: ggexport(plotlist = list(scree.plot, ind.plot, var.plot), nrow = 2, ncol = 2, filename = ‚ÄúPCA.pdf‚Äù) Export plots to png files. If you specify a list of plots, then multiple png files will be automatically created to hold each plot. ggexport(plotlist = list(scree.plot, ind.plot, var.plot), filename = ‚ÄúPCA.png‚Äù) Export results to txt/csv files All the outputs of the PCA (individuals/variables coordinates, contributions, etc) can be exported at once, into a TXT/CSV file, using the function write.infile() [in FactoMineR] package: "],["40-export-into-a-txt-file.html", "40 Export into a TXT file", " 40 Export into a TXT file write.infile(res.pca, ‚Äúpca.txt‚Äù, sep = ‚Äú) # Export into a CSV file write.infile(res.pca,‚Äùpca.csv‚Äú, sep =‚Äù;\") Summary In conclusion, we described how to perform and interpret principal component analysis (PCA). We computed PCA using the PCA() function [FactoMineR]. Next, we used the factoextra R package to produce ggplot2-based visualization of the PCA results. There are other functions [packages] to compute PCA in R: Using prcomp() [stats] res.pca &lt;- prcomp(iris[, -5], scale. = TRUE) Read more: http://www.sthda.com/english/wiki/pca-using-prcomp-and-princomp Using princomp() [stats] res.pca &lt;- princomp(iris[, -5], cor = TRUE) Read more: http://www.sthda.com/english/wiki/pca-using-prcomp-and-princomp Using dudi.pca() [ade4] library(‚Äúade4‚Äù) res.pca &lt;- dudi.pca(iris[, -5], scannf = FALSE, nf = 5) Read more: http://www.sthda.com/english/wiki/pca-using-ade4-and-factoextra Using epPCA() [ExPosition] library(‚ÄúExPosition‚Äù) res.pca &lt;- epPCA(iris[, -5], graph = FALSE) No matter what functions you decide to use, in the list above, the factoextra package can handle the output for creating beautiful plots similar to what we described in the previous sections for FactoMineR: fviz_eig(res.pca) # Scree plot fviz_pca_ind(res.pca) # Graph of individuals fviz_pca_var(res.pca) # Graph of variables "],["r.html", "R", " R Need to write something about R We also use various methods for manipulating and visualising data frames using the üì¶ tidyverse (Wickham 2021) (including tidyr, dplyr, ggplot2 etc). You can get more details on their use can be found at in the Book R for Data Science (Wickham and Grolemund 2016) which is freely available as a bookdown website here. References "],["to-do-list.html", "To do list", " To do list simulate new unicorn data add more info about allEffects and plotting prediction of models convert all plots to ggplot convert data handling to tidyverse add therory in all chapters random regression practical description of most common distributions and their use in ecology with packages on how to fit them use git submodule for the data repos intro and preface add something about moving away from null hypothesis and think more about model competition (AIC) (start with null hypothesis and go to uncertainty evaluation) "],["40.1-potential-structure.html", "40.1 potential structure", " 40.1 potential structure Stats glm lmm Bayesian intro random regression multivariate models glmm OS tools github (maybe) and rmarkdown open data and code, preregistration, replication no culture of the great coding practice "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
